{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb661222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python scikit-learn scikit-image matplotlib spectral keras_tuner vis\n",
    "# !pip install tensorflow numpy pandas\n",
    "# !pip install spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b605089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "from math import inf as inf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/nitintyagi/wheat data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\mvl\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Constants\n",
    "TESTING = False\n",
    "\n",
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.90\n",
    "IMAGE_COUNT = int(800/4)\n",
    "NUM_VARIETIES = 4\n",
    "NUM_OF_BANDS = 15\n",
    "FIRST_BAND = 21\n",
    "LAST_BAND = 149\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30\n",
    "NUM_LAYERS_EACH_BLOCK = [1, 1]\n",
    "NUM_CHAN_PER_BLOCK = [[64,128,128],[128,256,256]]\n",
    "\n",
    "ACTIVATION_TYPE =  \"relu\"\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "\n",
    "LEARNING_RATE_BASE = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e32422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactPathHDR(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil.hdr\"\n",
    "\n",
    "def exactPathBIL(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10991a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROI(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    threshold = threshold_otsu(img_band)\n",
    "    roi=[]\n",
    "    for x in range(img_band.shape[0]):\n",
    "        a=[]\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if img_band[x][y]>threshold:\n",
    "                a.append(1)\n",
    "            else:\n",
    "                a.append(0)\n",
    "        roi.append(a)\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f92ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns range for x and y from where we have to crop images\n",
    "def getRangeXandY(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    roi = getROI(img,band_number)\n",
    "    xmin = inf\n",
    "    xmax = 0\n",
    "    ymin = inf\n",
    "    ymax = 0\n",
    "    for x in range(img_band.shape[0]):\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if roi[x][y]==1:\n",
    "                if x<xmin:\n",
    "                    xmin=x\n",
    "                if x>xmax:\n",
    "                    xmax=x\n",
    "                if y<ymin:\n",
    "                    ymin=y\n",
    "                if y>ymax:\n",
    "                    ymax=y\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09705166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedImage(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    new_img = img[xmin:xmax, ymin:ymax, :]\n",
    "    return new_img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97d1f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedROI(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    roi = np.array(getROI(img,band_number))\n",
    "    roi = roi[xmin:xmax, ymin:ymax]\n",
    "    return roi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "318efc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsefulImage(img,band_number):\n",
    "    crop_img = getCroppedImage(img,band_number)\n",
    "    crop_roi = getCroppedROI(img,band_number)\n",
    "    for x in range(crop_img.shape[2]):\n",
    "        band = crop_img[:,:,x]\n",
    "        crop_img[:,:,x] = band*crop_roi\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad2376a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    layers.RandomRotation(factor=(-0.1, 0.1)),\n",
    "    layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1,0.1)),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=None)\n",
    "])\n",
    "\n",
    "def getAugumentedImage(img,band_number):\n",
    "    new_img = getUsefulImage(img,band_number)\n",
    "    augmented_image = data_augmentation(new_img) \n",
    "    return augmented_image\n",
    "\n",
    "def checkAugumentedImage(augmented_image):\n",
    "    aug_band = augmented_image[:,:,0]\n",
    "    filled_area_ratio = (np.count_nonzero(aug_band))/(aug_band.shape[0]*aug_band.shape[1])\n",
    "    if filled_area_ratio > FILLED_AREA_RATIO :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad47ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensional Reduction Method\n",
    "def DL_Method(HSI, numComponents = NUM_OF_BANDS):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    n_batches = 10\n",
    "    inc_pca = IncrementalPCA(n_components=numComponents)\n",
    "    for X_batch in np.array_split(RHSI, n_batches):\n",
    "        inc_pca.partial_fit(X_batch)\n",
    "    X_ipca = inc_pca.transform(RHSI)\n",
    "    RHSI = np.reshape(X_ipca, (HSI.shape[0],HSI.shape[1], numComponents))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b64642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for all file names in varities\n",
    "FILES = []\n",
    "MAX_FILE_NUM = 4\n",
    "for x in range(1,MAX_FILE_NUM+1):\n",
    "    FILES.append(\"B_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a072b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all images\n",
    "images = []\n",
    "images_label = []\n",
    "for v in VARIETIES:\n",
    "    for f in FILES:\n",
    "        try:\n",
    "            img = envi.open(exactPathHDR(v,f),exactPathBIL(v,f))\n",
    "            images.append(img)\n",
    "            images_label.append(v)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2493d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "train_dataset_label = []\n",
    "test_dataset = []\n",
    "test_dataset_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c910c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Testing time (s) = 6375.020547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "for index, img in enumerate(images):\n",
    "    count = 0\n",
    "    label = images_label[index]\n",
    "    while count<IMAGE_COUNT:\n",
    "        aug_img = getAugumentedImage(img,BAND_NUMBER)\n",
    "        \n",
    "        if checkAugumentedImage(aug_img):\n",
    "            aug_img = DL_Method(aug_img[:,:,FIRST_BAND:LAST_BAND+1])\n",
    "            if count%5 == 0:\n",
    "                test_dataset.append(aug_img)\n",
    "                test_dataset_label.append(label)\n",
    "            else:\n",
    "                train_dataset.append(aug_img)\n",
    "                train_dataset_label.append(label)\n",
    "            count+=1  \n",
    "            \n",
    "    if TESTING:\n",
    "        break\n",
    "        \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb9af0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.array(train_dataset)\n",
    "train_dataset_label = np.array([VARIETIES_CODE[label] for label in train_dataset_label])\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array([VARIETIES_CODE[label] for label in test_dataset_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import math, sys, pdb, os\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from keras import activations\n",
    "import vis\n",
    "# from vis.visualization import visualize_saliency, overlay\n",
    "# from vis.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd4a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.clim(0,sum(cm[0,:]))\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d67d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_K_classification_accuracy(y_predicted, y_true, K=1):\n",
    "\n",
    "    num_samples = y_predicted.shape[0]\n",
    "    num_classes = y_predicted.shape[1]\n",
    "\n",
    "    if K > num_classes:\n",
    "        sys.exit(1)\n",
    "\n",
    "    temp = np.zeros((num_samples,))\n",
    "\n",
    "    for idx in range(num_samples):\n",
    "        curr_predicted = np.argsort(y_predicted[idx,:])\n",
    "        curr_predicted = curr_predicted[::-1] # descending\n",
    "\n",
    "        if y_true[idx] in curr_predicted[:K]:\n",
    "            temp[idx] = 1\n",
    "\n",
    "    return 100.0 * np.sum(temp)/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c3599b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_conv_block(x, kernel_size=3, activation_type='relu', num_filters=128,use_bias=False):\n",
    "    # Batch norm\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(num_filters, kernel_size, activation=None, use_bias=use_bias, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "351725d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D=[32,64,128]):\n",
    "\n",
    "    x = single_conv_block(x,1,activation_type,num_filters_first_conv1D[0])\n",
    "\n",
    "    x = single_conv_block(x,kernel_size,activation_type,num_filters_first_conv1D[1],use_bias=True)\n",
    "\n",
    "    x = single_conv_block(x,1,activation_type,num_filters_first_conv1D[2])\n",
    "\n",
    "    # Dropout\n",
    "    return Dropout(dropout_rate)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0731a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBlock_ResNet2D(x, num_layers, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    for idx_layer in range(num_layers):\n",
    "        x = conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45bd16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet2D_classifier(data_num_rows, data_num_cols, num_classes, kernel_size=3, num_layers_each_block=[],\n",
    "                        num_chan_per_block=[], activation_type='relu', dropout_rate=0.0, num_input_chans=1, num_nodes_fc=64):\n",
    "\n",
    "    input_data = Input(shape=(data_num_rows, data_num_cols, num_input_chans))\n",
    "\n",
    "    # Input layer: Conv2D -> activation\n",
    "    x = Conv2D(num_chan_per_block[0][0], kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(input_data)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "\n",
    "    #  Blocks & Downsampling Layers\n",
    "    for idx_block in range(len(num_layers_each_block)):\n",
    "        x = createBlock_ResNet2D(x, num_layers_each_block[idx_block], kernel_size, activation_type, dropout_rate,\n",
    "                                 num_chan_per_block[idx_block])\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if idx_block != len(num_layers_each_block)-1:\n",
    "            x = Conv2D(num_chan_per_block[idx_block][1]*2, kernel_size, strides = 2, activation=None, use_bias=True, padding='valid',\n",
    "                   kernel_initializer='truncated_normal')(x)\n",
    "        else:\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(units=num_nodes_fc, activation=None, kernel_initializer='truncated_normal')(x)\n",
    "    x = Dense(units=128, activation=None, kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    output_data = Dense(units=num_classes, activation='softmax', kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    return Model(inputs=input_data, outputs=output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f40895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataset,dataset_label,normalization_type):\n",
    "    print(\"--------------Make Predictions--------------\")    \n",
    "    x = np.array(dataset)\n",
    "    labels = np.array(dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x = normalizeDataWholeSeed(x,normalization_type=normalization_type)\n",
    "    \n",
    "    num = x.shape[0]\n",
    "\n",
    "    tic = start_timer()\n",
    "    labels_predicted = model.predict(x)\n",
    "    toc = end_timer()\n",
    "    show_time(tic,toc)\n",
    "    \n",
    "    print(labels_predicted)\n",
    "    print(\"--------\")\n",
    "    # Classification accuracy\n",
    "    labels_integer_format = labels\n",
    "    labels_predicted_integer_format = np.argmax(labels_predicted, axis=1)\n",
    "\n",
    "    acc_top2 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=2)\n",
    "    acc_top1 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=1)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "    print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e4c541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,normalization_type):\n",
    "    evaluate(model,train_dataset,train_dataset_label,normalization_type)\n",
    "    \n",
    "    evaluate(model,test_dataset,test_dataset_label,normalization_type)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6797662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndTrainResNetB():\n",
    "    \n",
    "    learning_rate_base = LEARNING_RATE_BASE\n",
    "    kernel_size = 3\n",
    "    dropout_rate = 0.15 \n",
    "    activation_type = ACTIVATION_TYPE\n",
    "    num_nodes_fc = 512\n",
    "    wheat_types =  VARIETIES\n",
    "    normalization_type = 'max'\n",
    "    num_layers_each_block = NUM_LAYERS_EACH_BLOCK\n",
    "    num_chan_per_block = NUM_CHAN_PER_BLOCK\n",
    "    N_classes = len(wheat_types)\n",
    "    \n",
    "    ############ Load data ############\n",
    "    print(\"--------------Load Data--------------\")\n",
    "\n",
    "    # Load training data and their corresponding labels\n",
    "    x_training = np.array(train_dataset)\n",
    "    labels_training = np.array(train_dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_training = normalizeDataWholeSeed(x_training,normalization_type=normalization_type)\n",
    "    \n",
    "    # Extract some information\n",
    "    num_training = x_training.shape[0]\n",
    "    N_spatial = x_training.shape[1:3]\n",
    "    N_bands = x_training.shape[3]\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "    \n",
    "    ############ Create a model ############\n",
    "    print(\"--------------Create a model--------------\")\n",
    "    \n",
    "    # Generate a model\n",
    "    model = ResNet2D_classifier(data_num_rows = N_spatial[0], \n",
    "                                data_num_cols = N_spatial[1], \n",
    "                                num_classes = N_classes,\n",
    "                                kernel_size = kernel_size, \n",
    "                                num_layers_each_block = num_layers_each_block,\n",
    "                                num_chan_per_block = num_chan_per_block, \n",
    "                                activation_type = activation_type,\n",
    "                                dropout_rate = dropout_rate, \n",
    "                                num_input_chans = N_bands, \n",
    "                                num_nodes_fc = num_nodes_fc)\n",
    "\n",
    "    # Compile the model\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "    print(\"---------Completed---------\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72a8706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n",
      "---------Completed---------\n"
     ]
    }
   ],
   "source": [
    "model = createAndTrainResNetB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b02f2301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From epochs:  1  to  20\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "256/256 - 48s - loss: 0.8445 - accuracy: 0.6826 - val_loss: 2.8978 - val_accuracy: 0.0439 - 48s/epoch - 187ms/step\n",
      "Epoch 2/20\n",
      "256/256 - 49s - loss: 0.8673 - accuracy: 0.6680 - val_loss: 2.8116 - val_accuracy: 0.0488 - 49s/epoch - 190ms/step\n",
      "Epoch 3/20\n",
      "256/256 - 49s - loss: 0.8430 - accuracy: 0.6748 - val_loss: 2.7552 - val_accuracy: 0.0469 - 49s/epoch - 192ms/step\n",
      "Epoch 4/20\n",
      "256/256 - 49s - loss: 0.8258 - accuracy: 0.6885 - val_loss: 2.8243 - val_accuracy: 0.0420 - 49s/epoch - 191ms/step\n",
      "Epoch 5/20\n",
      "256/256 - 48s - loss: 0.8532 - accuracy: 0.6812 - val_loss: 2.7179 - val_accuracy: 0.0469 - 48s/epoch - 187ms/step\n",
      "Epoch 6/20\n",
      "256/256 - 52s - loss: 0.8377 - accuracy: 0.6870 - val_loss: 2.6315 - val_accuracy: 0.0488 - 52s/epoch - 204ms/step\n",
      "Epoch 7/20\n",
      "256/256 - 49s - loss: 0.8343 - accuracy: 0.6904 - val_loss: 2.6079 - val_accuracy: 0.0479 - 49s/epoch - 192ms/step\n",
      "Epoch 8/20\n",
      "256/256 - 48s - loss: 0.8495 - accuracy: 0.6772 - val_loss: 2.5444 - val_accuracy: 0.0488 - 48s/epoch - 188ms/step\n",
      "Epoch 9/20\n",
      "256/256 - 48s - loss: 0.8360 - accuracy: 0.6826 - val_loss: 2.4207 - val_accuracy: 0.0557 - 48s/epoch - 187ms/step\n",
      "Epoch 10/20\n",
      "256/256 - 49s - loss: 0.8107 - accuracy: 0.6982 - val_loss: 2.4063 - val_accuracy: 0.0566 - 49s/epoch - 193ms/step\n",
      "Epoch 11/20\n",
      "256/256 - 48s - loss: 0.8276 - accuracy: 0.6841 - val_loss: 2.3043 - val_accuracy: 0.0596 - 48s/epoch - 188ms/step\n",
      "Epoch 12/20\n",
      "256/256 - 48s - loss: 0.8456 - accuracy: 0.6875 - val_loss: 2.3472 - val_accuracy: 0.0566 - 48s/epoch - 186ms/step\n",
      "Epoch 13/20\n",
      "256/256 - 49s - loss: 0.8260 - accuracy: 0.6851 - val_loss: 2.2569 - val_accuracy: 0.0596 - 49s/epoch - 191ms/step\n",
      "Epoch 14/20\n",
      "256/256 - 50s - loss: 0.8058 - accuracy: 0.6953 - val_loss: 2.2001 - val_accuracy: 0.0615 - 50s/epoch - 194ms/step\n",
      "Epoch 15/20\n",
      "256/256 - 49s - loss: 0.8206 - accuracy: 0.6948 - val_loss: 2.1745 - val_accuracy: 0.0615 - 49s/epoch - 190ms/step\n",
      "Epoch 16/20\n",
      "256/256 - 47s - loss: 0.8055 - accuracy: 0.6997 - val_loss: 2.1411 - val_accuracy: 0.0645 - 47s/epoch - 185ms/step\n",
      "Epoch 17/20\n",
      "256/256 - 48s - loss: 0.8177 - accuracy: 0.6860 - val_loss: 2.0620 - val_accuracy: 0.0713 - 48s/epoch - 188ms/step\n",
      "Epoch 18/20\n",
      "256/256 - 49s - loss: 0.7949 - accuracy: 0.7041 - val_loss: 2.1181 - val_accuracy: 0.0645 - 49s/epoch - 191ms/step\n",
      "Epoch 19/20\n",
      "256/256 - 49s - loss: 0.7854 - accuracy: 0.7051 - val_loss: 2.0281 - val_accuracy: 0.0742 - 49s/epoch - 191ms/step\n",
      "Epoch 20/20\n",
      "256/256 - 48s - loss: 0.8024 - accuracy: 0.6943 - val_loss: 2.0285 - val_accuracy: 0.0752 - 48s/epoch - 189ms/step\n",
      "<keras.callbacks.History object at 0x000001CC58FEA9D0>\n",
      "Testing time (s) = 974.5210898000005\n",
      "\n",
      "for testing\n",
      "20/20 [==============================] - 3s 137ms/step - loss: 2.4425 - accuracy: 0.3109\n",
      "[2.4424502849578857, 0.3109374940395355]\n",
      "for training\n",
      "80/80 [==============================] - 11s 137ms/step - loss: 2.3826 - accuracy: 0.3102\n",
      "[2.3825817108154297, 0.3101562559604645]\n",
      "From epochs:  21  to  40\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "256/256 - 46s - loss: 0.8171 - accuracy: 0.6904 - val_loss: 1.8023 - val_accuracy: 0.0254 - 46s/epoch - 178ms/step\n",
      "Epoch 2/20\n",
      "256/256 - 45s - loss: 0.8113 - accuracy: 0.6895 - val_loss: 1.8011 - val_accuracy: 0.0254 - 45s/epoch - 176ms/step\n",
      "Epoch 3/20\n",
      "256/256 - 46s - loss: 0.8074 - accuracy: 0.6914 - val_loss: 1.7036 - val_accuracy: 0.0312 - 46s/epoch - 178ms/step\n",
      "Epoch 4/20\n",
      "256/256 - 45s - loss: 0.7951 - accuracy: 0.7026 - val_loss: 1.6824 - val_accuracy: 0.0352 - 45s/epoch - 177ms/step\n",
      "Epoch 5/20\n",
      "256/256 - 46s - loss: 0.7911 - accuracy: 0.7139 - val_loss: 1.6773 - val_accuracy: 0.0410 - 46s/epoch - 180ms/step\n",
      "Epoch 6/20\n",
      "256/256 - 46s - loss: 0.7818 - accuracy: 0.7002 - val_loss: 1.6388 - val_accuracy: 0.0527 - 46s/epoch - 180ms/step\n",
      "Epoch 7/20\n",
      "256/256 - 46s - loss: 0.7783 - accuracy: 0.7100 - val_loss: 1.6250 - val_accuracy: 0.0508 - 46s/epoch - 180ms/step\n",
      "Epoch 8/20\n",
      "256/256 - 46s - loss: 0.7922 - accuracy: 0.7021 - val_loss: 1.5737 - val_accuracy: 0.0605 - 46s/epoch - 179ms/step\n",
      "Epoch 9/20\n",
      "256/256 - 47s - loss: 0.7861 - accuracy: 0.7031 - val_loss: 1.5711 - val_accuracy: 0.0605 - 47s/epoch - 184ms/step\n",
      "Epoch 10/20\n",
      "256/256 - 46s - loss: 0.7757 - accuracy: 0.7183 - val_loss: 1.5057 - val_accuracy: 0.0781 - 46s/epoch - 180ms/step\n",
      "Epoch 11/20\n",
      "256/256 - 46s - loss: 0.8143 - accuracy: 0.6846 - val_loss: 1.4784 - val_accuracy: 0.0879 - 46s/epoch - 179ms/step\n",
      "Epoch 12/20\n",
      "256/256 - 46s - loss: 0.7885 - accuracy: 0.7075 - val_loss: 1.4586 - val_accuracy: 0.0957 - 46s/epoch - 178ms/step\n",
      "Epoch 13/20\n",
      "256/256 - 46s - loss: 0.7703 - accuracy: 0.7080 - val_loss: 1.4714 - val_accuracy: 0.0918 - 46s/epoch - 179ms/step\n",
      "Epoch 14/20\n",
      "256/256 - 46s - loss: 0.7825 - accuracy: 0.7012 - val_loss: 1.4499 - val_accuracy: 0.0977 - 46s/epoch - 180ms/step\n",
      "Epoch 15/20\n",
      "256/256 - 50s - loss: 0.7846 - accuracy: 0.7188 - val_loss: 1.3815 - val_accuracy: 0.1211 - 50s/epoch - 194ms/step\n",
      "Epoch 16/20\n",
      "256/256 - 47s - loss: 0.7766 - accuracy: 0.7168 - val_loss: 1.3678 - val_accuracy: 0.1191 - 47s/epoch - 183ms/step\n",
      "Epoch 17/20\n",
      "256/256 - 48s - loss: 0.8025 - accuracy: 0.7036 - val_loss: 1.3442 - val_accuracy: 0.1250 - 48s/epoch - 188ms/step\n",
      "Epoch 18/20\n",
      "256/256 - 47s - loss: 0.7929 - accuracy: 0.6934 - val_loss: 1.2860 - val_accuracy: 0.1484 - 47s/epoch - 185ms/step\n",
      "Epoch 19/20\n",
      "256/256 - 46s - loss: 0.7592 - accuracy: 0.7168 - val_loss: 1.2455 - val_accuracy: 0.1680 - 46s/epoch - 181ms/step\n",
      "Epoch 20/20\n",
      "256/256 - 46s - loss: 0.7637 - accuracy: 0.7065 - val_loss: 1.2269 - val_accuracy: 0.1719 - 46s/epoch - 181ms/step\n",
      "<keras.callbacks.History object at 0x000001CC3FE8CE50>\n",
      "Testing time (s) = 927.0809432999995\n",
      "\n",
      "for testing\n",
      "20/20 [==============================] - 3s 140ms/step - loss: 2.2286 - accuracy: 0.3625\n",
      "[2.228621006011963, 0.36250001192092896]\n",
      "for training\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 2.1518 - accuracy: 0.3684\n",
      "[2.151838779449463, 0.36835938692092896]\n",
      "From epochs:  41  to  60\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "256/256 - 49s - loss: 0.7950 - accuracy: 0.7046 - val_loss: 1.2798 - val_accuracy: 0.1621 - 49s/epoch - 190ms/step\n",
      "Epoch 2/20\n",
      "256/256 - 46s - loss: 0.7743 - accuracy: 0.7129 - val_loss: 1.2385 - val_accuracy: 0.1816 - 46s/epoch - 180ms/step\n",
      "Epoch 3/20\n",
      "256/256 - 46s - loss: 0.7765 - accuracy: 0.7065 - val_loss: 1.2071 - val_accuracy: 0.1973 - 46s/epoch - 181ms/step\n",
      "Epoch 4/20\n",
      "256/256 - 47s - loss: 0.7740 - accuracy: 0.7139 - val_loss: 1.2030 - val_accuracy: 0.2031 - 47s/epoch - 184ms/step\n",
      "Epoch 5/20\n",
      "256/256 - 46s - loss: 0.7803 - accuracy: 0.7065 - val_loss: 1.1993 - val_accuracy: 0.2031 - 46s/epoch - 181ms/step\n",
      "Epoch 6/20\n",
      "256/256 - 46s - loss: 0.7760 - accuracy: 0.7012 - val_loss: 1.1125 - val_accuracy: 0.2617 - 46s/epoch - 179ms/step\n",
      "Epoch 7/20\n",
      "256/256 - 46s - loss: 0.7788 - accuracy: 0.7109 - val_loss: 1.1011 - val_accuracy: 0.2754 - 46s/epoch - 179ms/step\n",
      "Epoch 8/20\n",
      "256/256 - 47s - loss: 0.7971 - accuracy: 0.6963 - val_loss: 1.1240 - val_accuracy: 0.2617 - 47s/epoch - 183ms/step\n",
      "Epoch 9/20\n",
      "256/256 - 46s - loss: 0.7745 - accuracy: 0.7061 - val_loss: 1.1411 - val_accuracy: 0.2500 - 46s/epoch - 180ms/step\n",
      "Epoch 10/20\n",
      "256/256 - 46s - loss: 0.7695 - accuracy: 0.7085 - val_loss: 1.0964 - val_accuracy: 0.2852 - 46s/epoch - 180ms/step\n",
      "Epoch 11/20\n",
      "256/256 - 46s - loss: 0.7800 - accuracy: 0.7046 - val_loss: 1.0929 - val_accuracy: 0.2891 - 46s/epoch - 178ms/step\n",
      "Epoch 12/20\n",
      "256/256 - 46s - loss: 0.7572 - accuracy: 0.7222 - val_loss: 1.0145 - val_accuracy: 0.3379 - 46s/epoch - 181ms/step\n",
      "Epoch 13/20\n",
      "256/256 - 46s - loss: 0.7788 - accuracy: 0.6963 - val_loss: 1.0532 - val_accuracy: 0.3223 - 46s/epoch - 180ms/step\n",
      "Epoch 14/20\n",
      "256/256 - 47s - loss: 0.7660 - accuracy: 0.7153 - val_loss: 1.0617 - val_accuracy: 0.3164 - 47s/epoch - 182ms/step\n",
      "Epoch 15/20\n",
      "256/256 - 46s - loss: 0.7844 - accuracy: 0.7070 - val_loss: 1.0371 - val_accuracy: 0.3242 - 46s/epoch - 178ms/step\n",
      "Epoch 16/20\n",
      "256/256 - 46s - loss: 0.7542 - accuracy: 0.7251 - val_loss: 1.0144 - val_accuracy: 0.3477 - 46s/epoch - 180ms/step\n",
      "Epoch 17/20\n",
      "256/256 - 49s - loss: 0.7630 - accuracy: 0.7139 - val_loss: 1.0204 - val_accuracy: 0.3457 - 49s/epoch - 191ms/step\n",
      "Epoch 18/20\n",
      "256/256 - 46s - loss: 0.7817 - accuracy: 0.7090 - val_loss: 1.0101 - val_accuracy: 0.3438 - 46s/epoch - 180ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "256/256 - 45s - loss: 0.7861 - accuracy: 0.7104 - val_loss: 0.9788 - val_accuracy: 0.3633 - 45s/epoch - 177ms/step\n",
      "Epoch 20/20\n",
      "256/256 - 46s - loss: 0.7756 - accuracy: 0.7041 - val_loss: 0.9809 - val_accuracy: 0.3652 - 46s/epoch - 180ms/step\n",
      "<keras.callbacks.History object at 0x000001CC58E383A0>\n",
      "Testing time (s) = 928.0472721999995\n",
      "\n",
      "for testing\n",
      "20/20 [==============================] - 3s 140ms/step - loss: 2.1919 - accuracy: 0.4234\n",
      "[2.191910743713379, 0.4234375059604645]\n",
      "for training\n",
      "80/80 [==============================] - 11s 142ms/step - loss: 2.1079 - accuracy: 0.4156\n",
      "[2.1079118251800537, 0.4156250059604645]\n",
      "From epochs:  61  to  80\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "256/256 - 46s - loss: 0.7643 - accuracy: 0.7153 - val_loss: 0.9893 - val_accuracy: 0.3633 - 46s/epoch - 181ms/step\n",
      "Epoch 2/20\n",
      "256/256 - 46s - loss: 0.7496 - accuracy: 0.7202 - val_loss: 0.9732 - val_accuracy: 0.3750 - 46s/epoch - 179ms/step\n",
      "Epoch 3/20\n",
      "256/256 - 46s - loss: 0.7800 - accuracy: 0.7124 - val_loss: 0.9257 - val_accuracy: 0.4102 - 46s/epoch - 179ms/step\n",
      "Epoch 4/20\n",
      "256/256 - 47s - loss: 0.7868 - accuracy: 0.7012 - val_loss: 0.9351 - val_accuracy: 0.3926 - 47s/epoch - 183ms/step\n",
      "Epoch 5/20\n",
      "256/256 - 46s - loss: 0.7804 - accuracy: 0.7031 - val_loss: 0.9287 - val_accuracy: 0.4082 - 46s/epoch - 181ms/step\n",
      "Epoch 6/20\n",
      "256/256 - 46s - loss: 0.7711 - accuracy: 0.7197 - val_loss: 0.9139 - val_accuracy: 0.4199 - 46s/epoch - 181ms/step\n",
      "Epoch 7/20\n",
      "256/256 - 47s - loss: 0.7614 - accuracy: 0.7173 - val_loss: 0.8989 - val_accuracy: 0.4414 - 47s/epoch - 183ms/step\n",
      "Epoch 8/20\n",
      "256/256 - 46s - loss: 0.7543 - accuracy: 0.7217 - val_loss: 0.8934 - val_accuracy: 0.4492 - 46s/epoch - 180ms/step\n",
      "Epoch 9/20\n",
      "256/256 - 46s - loss: 0.7681 - accuracy: 0.7202 - val_loss: 0.8353 - val_accuracy: 0.5137 - 46s/epoch - 179ms/step\n",
      "Epoch 10/20\n",
      "256/256 - 45s - loss: 0.7528 - accuracy: 0.7119 - val_loss: 0.8652 - val_accuracy: 0.4785 - 45s/epoch - 178ms/step\n",
      "Epoch 11/20\n",
      "256/256 - 46s - loss: 0.7548 - accuracy: 0.7236 - val_loss: 0.8521 - val_accuracy: 0.5000 - 46s/epoch - 178ms/step\n",
      "Epoch 12/20\n",
      "256/256 - 46s - loss: 0.7576 - accuracy: 0.7178 - val_loss: 0.8477 - val_accuracy: 0.5059 - 46s/epoch - 180ms/step\n",
      "Epoch 13/20\n",
      "256/256 - 46s - loss: 0.7523 - accuracy: 0.7202 - val_loss: 0.8644 - val_accuracy: 0.4824 - 46s/epoch - 179ms/step\n",
      "Epoch 14/20\n",
      "256/256 - 45s - loss: 0.7699 - accuracy: 0.7144 - val_loss: 0.8752 - val_accuracy: 0.4707 - 45s/epoch - 176ms/step\n",
      "Epoch 15/20\n",
      "256/256 - 45s - loss: 0.7323 - accuracy: 0.7397 - val_loss: 0.8135 - val_accuracy: 0.5566 - 45s/epoch - 178ms/step\n",
      "Epoch 16/20\n",
      "256/256 - 46s - loss: 0.7423 - accuracy: 0.7271 - val_loss: 0.8056 - val_accuracy: 0.5488 - 46s/epoch - 181ms/step\n",
      "Epoch 17/20\n",
      "256/256 - 46s - loss: 0.7441 - accuracy: 0.7319 - val_loss: 0.8063 - val_accuracy: 0.5371 - 46s/epoch - 178ms/step\n",
      "Epoch 18/20\n",
      "256/256 - 45s - loss: 0.7610 - accuracy: 0.7129 - val_loss: 0.7834 - val_accuracy: 0.5801 - 45s/epoch - 177ms/step\n",
      "Epoch 19/20\n",
      "256/256 - 46s - loss: 0.7304 - accuracy: 0.7300 - val_loss: 0.8046 - val_accuracy: 0.5605 - 46s/epoch - 180ms/step\n",
      "Epoch 20/20\n",
      "256/256 - 45s - loss: 0.7526 - accuracy: 0.7202 - val_loss: 0.8071 - val_accuracy: 0.5566 - 45s/epoch - 177ms/step\n",
      "<keras.callbacks.History object at 0x000001CC3FEDD8E0>\n",
      "Testing time (s) = 919.0477039999987\n",
      "\n",
      "for testing\n",
      "20/20 [==============================] - 3s 132ms/step - loss: 2.1326 - accuracy: 0.4625\n",
      "[2.132603168487549, 0.4625000059604645]\n",
      "for training\n",
      "80/80 [==============================] - 11s 136ms/step - loss: 2.0380 - accuracy: 0.4695\n",
      "[2.037994861602783, 0.46953123807907104]\n"
     ]
    }
   ],
   "source": [
    "for x in range(4):\n",
    "    print(\"From epochs: \",20*x+1,\" to \",20+20*x)\n",
    "    tic = start_timer()\n",
    "    print(model.fit(x=train_dataset,y=train_dataset_label,batch_size=BATCH_SIZE, epochs=20, initial_epoch = 0, verbose=2,validation_split=0.20,shuffle=True))\n",
    "    toc = end_timer()\n",
    "    show_time(tic,toc)\n",
    "    print(\"for testing\")\n",
    "    print(model.evaluate(test_dataset,test_dataset_label))\n",
    "    print(\"for training\")\n",
    "    print(model.evaluate(train_dataset,train_dataset_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e37a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
