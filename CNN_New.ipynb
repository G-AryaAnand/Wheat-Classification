{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb661222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python scikit-learn scikit-image matplotlib spectral keras_tuner vis\n",
    "# !pip install tensorflow numpy pandas\n",
    "# !pip install spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b605089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "from math import inf as inf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/nitintyagi/wheat data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\mvl\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Constants\n",
    "TESTING = False\n",
    "\n",
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.50\n",
    "IMAGE_COUNT = int(8/4)\n",
    "NUM_VARIETIES = 2\n",
    "NUM_OF_BANDS = 15\n",
    "FIRST_BAND = 21\n",
    "LAST_BAND = 149\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "ACTIVATION_TYPE =  [\"relu\", \"tanh\",\"sigmoid\"]\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "\n",
    "LEARNING_RATE_BASE = 0.0001\n",
    "MIN_LEARNING_RATE_BASE = LEARNING_RATE_BASE/10\n",
    "\n",
    "FACTOR = 3\n",
    "NUM_MODELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "479b1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_file_name():\n",
    "    return \"NumVar_\"+str(NUM_VARIETIES)+\"_ImageCount_\"+str(IMAGE_COUNT)+\"_Factor_\"+str(FACTOR)+\"_MinLR_\"+str(MIN_LEARNING_RATE_BASE)+\"_LR_\"+str(LEARNING_RATE_BASE)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_BatchSize_\"+str(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5e32422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactPathHDR(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil.hdr\"\n",
    "\n",
    "def exactPathBIL(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10991a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROI(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    threshold = threshold_otsu(img_band)\n",
    "    roi=[]\n",
    "    for x in range(img_band.shape[0]):\n",
    "        a=[]\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if img_band[x][y]>threshold:\n",
    "                a.append(1)\n",
    "            else:\n",
    "                a.append(0)\n",
    "        roi.append(a)\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f92ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns range for x and y from where we have to crop images\n",
    "def getRangeXandY(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    roi = getROI(img,band_number)\n",
    "    xmin = inf\n",
    "    xmax = 0\n",
    "    ymin = inf\n",
    "    ymax = 0\n",
    "    for x in range(img_band.shape[0]):\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if roi[x][y]==1:\n",
    "                if x<xmin:\n",
    "                    xmin=x\n",
    "                if x>xmax:\n",
    "                    xmax=x\n",
    "                if y<ymin:\n",
    "                    ymin=y\n",
    "                if y>ymax:\n",
    "                    ymax=y\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09705166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedImage(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    new_img = img[xmin:xmax, ymin:ymax, :]\n",
    "    return new_img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97d1f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedROI(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    roi = np.array(getROI(img,band_number))\n",
    "    roi = roi[xmin:xmax, ymin:ymax]\n",
    "    return roi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "318efc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsefulImage(img,band_number):\n",
    "    crop_img = getCroppedImage(img,band_number)\n",
    "    crop_roi = getCroppedROI(img,band_number)\n",
    "    for x in range(crop_img.shape[2]):\n",
    "        band = crop_img[:,:,x]\n",
    "        crop_img[:,:,x] = band*crop_roi\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad2376a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    layers.RandomRotation(factor=(-0.1, 0.1)),\n",
    "    layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1,0.1)),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=None)\n",
    "])\n",
    "\n",
    "def getAugumentedImage(img,band_number):\n",
    "    new_img = getUsefulImage(img,band_number)\n",
    "    augmented_image = data_augmentation(new_img) \n",
    "    return augmented_image\n",
    "\n",
    "def checkAugumentedImage(augmented_image):\n",
    "    aug_band = augmented_image[:,:,0]\n",
    "    filled_area_ratio = (np.count_nonzero(aug_band))/(aug_band.shape[0]*aug_band.shape[1])\n",
    "    if filled_area_ratio > FILLED_AREA_RATIO :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad47ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensional Reduction Method\n",
    "def DL_Method(HSI, numComponents = NUM_OF_BANDS):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    n_batches = 10\n",
    "    inc_pca = IncrementalPCA(n_components=numComponents)\n",
    "    for X_batch in np.array_split(RHSI, n_batches):\n",
    "        inc_pca.partial_fit(X_batch)\n",
    "    X_ipca = inc_pca.transform(RHSI)\n",
    "    RHSI = np.reshape(X_ipca, (HSI.shape[0],HSI.shape[1], numComponents))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20b64642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for all file names in varities\n",
    "FILES = []\n",
    "MAX_FILE_NUM = 4\n",
    "for x in range(1,MAX_FILE_NUM+1):\n",
    "    FILES.append(\"B_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a072b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all images\n",
    "images = []\n",
    "images_label = []\n",
    "for v in VARIETIES:\n",
    "    for f in FILES:\n",
    "        try:\n",
    "            img = envi.open(exactPathHDR(v,f),exactPathBIL(v,f))\n",
    "            images.append(img)\n",
    "            images_label.append(v)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2493d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "train_dataset_label = []\n",
    "test_dataset = []\n",
    "test_dataset_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c910c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Testing time (s) = 29.49391120002838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "for index, img in enumerate(images):\n",
    "    count = 0\n",
    "    label = images_label[index]\n",
    "    while count<IMAGE_COUNT:\n",
    "        aug_img = getAugumentedImage(img,BAND_NUMBER)\n",
    "        \n",
    "        if checkAugumentedImage(aug_img):\n",
    "            aug_img = DL_Method(aug_img[:,:,FIRST_BAND:LAST_BAND+1])\n",
    "            if count%5 == 0:\n",
    "                test_dataset.append(aug_img)\n",
    "                test_dataset_label.append(label)\n",
    "            else:\n",
    "                train_dataset.append(aug_img)\n",
    "                train_dataset_label.append(label)\n",
    "            count+=1  \n",
    "            \n",
    "    if TESTING:\n",
    "        break\n",
    "        \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb9af0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.array(train_dataset)\n",
    "train_dataset_label = np.array([VARIETIES_CODE[label] for label in train_dataset_label])\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array([VARIETIES_CODE[label] for label in test_dataset_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c1f17e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import math, sys, pdb, os\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from keras import activations\n",
    "import vis\n",
    "# from vis.visualization import visualize_saliency, overlay\n",
    "# from vis.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1fd4a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.clim(0,sum(cm[0,:]))\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d67d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_K_classification_accuracy(y_predicted, y_true, K=1):\n",
    "\n",
    "    num_samples = y_predicted.shape[0]\n",
    "    num_classes = y_predicted.shape[1]\n",
    "\n",
    "    if K > num_classes:\n",
    "        sys.exit(1)\n",
    "\n",
    "    temp = np.zeros((num_samples,))\n",
    "\n",
    "    for idx in range(num_samples):\n",
    "        curr_predicted = np.argsort(y_predicted[idx,:])\n",
    "        curr_predicted = curr_predicted[::-1] # descending\n",
    "\n",
    "        if y_true[idx] in curr_predicted[:K]:\n",
    "            temp[idx] = 1\n",
    "\n",
    "    return 100.0 * np.sum(temp)/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fa1225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_conv_block(x, kernel_size=3, activation_type='relu', num_filters=128,use_bias=False):\n",
    "    # Batch norm\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(num_filters, kernel_size, activation=None, use_bias=use_bias, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "351725d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D=[32,64,128]):\n",
    "\n",
    "    x = single_conv_block(x,1,activation_type,num_filters_first_conv1D[0])\n",
    "\n",
    "    x = single_conv_block(x,kernel_size,activation_type,num_filters_first_conv1D[1],use_bias=True)\n",
    "\n",
    "    x = single_conv_block(x,1,activation_type,num_filters_first_conv1D[2])\n",
    "\n",
    "    # Dropout\n",
    "    return Dropout(dropout_rate)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0731a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBlock_ResNet2D(x, num_layers, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    for idx_layer in range(num_layers):\n",
    "        x = conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "45bd16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet2D_classifier(data_num_rows, data_num_cols, num_classes, kernel_size=3, num_layers_each_block=[],\n",
    "                        num_chan_per_block=[], activation_type='relu', dropout_rate=0.0, num_input_chans=1, num_nodes_fc=64):\n",
    "\n",
    "    input_data = Input(shape=(data_num_rows, data_num_cols, num_input_chans))\n",
    "\n",
    "    # Input layer: Conv2D -> activation\n",
    "    x = Conv2D(num_chan_per_block[0][0], kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(input_data)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "\n",
    "    #  Blocks & Downsampling Layers\n",
    "    for idx_block in range(len(num_layers_each_block)):\n",
    "        x = createBlock_ResNet2D(x, num_layers_each_block[idx_block], kernel_size, activation_type, dropout_rate,\n",
    "                                 num_chan_per_block[idx_block])\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if idx_block != len(num_layers_each_block)-1:\n",
    "            x = Conv2D(num_chan_per_block[idx_block][1]*2, kernel_size, strides = 2, activation=None, use_bias=True, padding='valid',\n",
    "                   kernel_initializer='truncated_normal')(x)\n",
    "        else:\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(units=num_nodes_fc, activation=None, kernel_initializer='truncated_normal')(x)\n",
    "#     x = Dense(units=32, activation=None, kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    output_data = Dense(units=num_classes, activation='softmax', kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    return Model(inputs=input_data, outputs=output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f40895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataset,dataset_label,normalization_type):\n",
    "    print(\"--------------Make Predictions--------------\")    \n",
    "    x = np.array(dataset)\n",
    "    labels = np.array(dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x = normalizeDataWholeSeed(x,normalization_type=normalization_type)\n",
    "    \n",
    "    num = x.shape[0]\n",
    "\n",
    "    tic = start_timer()\n",
    "    labels_predicted = model.predict(x)\n",
    "    toc = end_timer()\n",
    "    show_time(tic,toc)\n",
    "    \n",
    "    print(labels_predicted)\n",
    "    print(\"--------\")\n",
    "    # Classification accuracy\n",
    "    labels_integer_format = labels\n",
    "    labels_predicted_integer_format = np.argmax(labels_predicted, axis=1)\n",
    "\n",
    "    acc_top2 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=2)\n",
    "    acc_top1 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=1)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "    print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e4c541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,normalization_type):\n",
    "    evaluate(model,train_dataset,train_dataset_label,normalization_type)\n",
    "    \n",
    "    evaluate(model,test_dataset,test_dataset_label,normalization_type)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6797662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndTrainResNetB():\n",
    "    \n",
    "    learning_rate_base = LEARNING_RATE_BASE\n",
    "    kernel_size = 3\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    batch_size = BATCH_SIZE\n",
    "    dropout_rate = 0.15 \n",
    "    activation_type = 'relu'\n",
    "    num_nodes_fc = 256\n",
    "    wheat_types =  VARIETIES\n",
    "    normalization_type = 'max'\n",
    "    num_layers_each_block = [1, 1]\n",
    "    num_chan_per_block = [[64,128,128],[128,128,256]]\n",
    "    N_classes = len(wheat_types)\n",
    "    \n",
    "    ############ Load data ############\n",
    "    print(\"--------------Load Data--------------\")\n",
    "\n",
    "    # Load training data and their corresponding labels\n",
    "    x_training = np.array(train_dataset)\n",
    "    labels_training = np.array(train_dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_training = normalizeDataWholeSeed(x_training,normalization_type=normalization_type)\n",
    "    \n",
    "    # Extract some information\n",
    "    num_training = x_training.shape[0]\n",
    "    N_spatial = x_training.shape[1:3]\n",
    "    N_bands = x_training.shape[3]\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "    \n",
    "    ############ Create a model ############\n",
    "    print(\"--------------Create a model--------------\")\n",
    "    \n",
    "    # Generate a model\n",
    "    model = ResNet2D_classifier(data_num_rows = N_spatial[0], \n",
    "                                data_num_cols = N_spatial[1], \n",
    "                                num_classes = N_classes,\n",
    "                                kernel_size = kernel_size, \n",
    "                                num_layers_each_block = num_layers_each_block,\n",
    "                                num_chan_per_block = num_chan_per_block, \n",
    "                                activation_type = activation_type,\n",
    "                                dropout_rate = dropout_rate, \n",
    "                                num_input_chans = N_bands, \n",
    "                                num_nodes_fc = num_nodes_fc)\n",
    "\n",
    "    # Compile the model\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "    print(\"---------Completed \")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72a8706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n"
     ]
    }
   ],
   "source": [
    "model = createAndTrainResNetB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36cc067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From epochs:  1  to  20\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "1/1 - 7s - loss: 0.9014 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.0000e+00 - 7s/epoch - 7s/step\n",
      "Epoch 2/20\n",
      "1/1 - 0s - loss: 0.7059 - accuracy: 0.7500 - val_loss: 0.6944 - val_accuracy: 0.0000e+00 - 225ms/epoch - 225ms/step\n",
      "Epoch 3/20\n",
      "1/1 - 0s - loss: 0.7046 - accuracy: 0.5000 - val_loss: 0.6948 - val_accuracy: 0.0000e+00 - 220ms/epoch - 220ms/step\n",
      "Epoch 4/20\n",
      "1/1 - 0s - loss: 0.7589 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.0000e+00 - 212ms/epoch - 212ms/step\n",
      "Epoch 5/20\n",
      "1/1 - 0s - loss: 0.7262 - accuracy: 0.2500 - val_loss: 0.6942 - val_accuracy: 0.0000e+00 - 217ms/epoch - 217ms/step\n",
      "Epoch 6/20\n",
      "1/1 - 0s - loss: 0.7023 - accuracy: 0.7500 - val_loss: 0.6936 - val_accuracy: 0.0000e+00 - 213ms/epoch - 213ms/step\n",
      "Epoch 7/20\n",
      "1/1 - 0s - loss: 0.7101 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.0000e+00 - 216ms/epoch - 216ms/step\n",
      "Epoch 8/20\n",
      "1/1 - 0s - loss: 0.7195 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.0000e+00 - 246ms/epoch - 246ms/step\n",
      "Epoch 9/20\n",
      "1/1 - 0s - loss: 0.7420 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.0000e+00 - 202ms/epoch - 202ms/step\n",
      "Epoch 10/20\n",
      "1/1 - 0s - loss: 0.7087 - accuracy: 0.7500 - val_loss: 0.6936 - val_accuracy: 0.0000e+00 - 206ms/epoch - 206ms/step\n",
      "Epoch 11/20\n",
      "1/1 - 0s - loss: 0.7329 - accuracy: 0.2500 - val_loss: 0.6937 - val_accuracy: 0.0000e+00 - 217ms/epoch - 217ms/step\n",
      "Epoch 12/20\n",
      "1/1 - 0s - loss: 0.7343 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.0000e+00 - 203ms/epoch - 203ms/step\n",
      "Epoch 13/20\n",
      "1/1 - 0s - loss: 0.7046 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.7500 - 204ms/epoch - 204ms/step\n",
      "Epoch 14/20\n",
      "1/1 - 0s - loss: 0.7632 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.0000e+00 - 209ms/epoch - 209ms/step\n",
      "Epoch 15/20\n",
      "1/1 - 0s - loss: 0.6882 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.0000e+00 - 222ms/epoch - 222ms/step\n",
      "Epoch 16/20\n",
      "1/1 - 0s - loss: 0.7900 - accuracy: 0.7500 - val_loss: 0.6952 - val_accuracy: 0.0000e+00 - 220ms/epoch - 220ms/step\n",
      "Epoch 17/20\n",
      "1/1 - 0s - loss: 0.7094 - accuracy: 0.7500 - val_loss: 0.6945 - val_accuracy: 0.0000e+00 - 206ms/epoch - 206ms/step\n",
      "Epoch 18/20\n",
      "1/1 - 0s - loss: 0.7049 - accuracy: 0.5000 - val_loss: 0.6947 - val_accuracy: 0.0000e+00 - 209ms/epoch - 209ms/step\n",
      "Epoch 19/20\n",
      "1/1 - 0s - loss: 0.7566 - accuracy: 0.5000 - val_loss: 0.6950 - val_accuracy: 0.0000e+00 - 210ms/epoch - 210ms/step\n",
      "Epoch 20/20\n",
      "1/1 - 0s - loss: 0.6959 - accuracy: 0.5000 - val_loss: 0.6954 - val_accuracy: 0.0000e+00 - 217ms/epoch - 217ms/step\n",
      "<keras.callbacks.History object at 0x000002070027DF60>\n",
      "Testing time (s) = 10.849788299994543\n",
      "\n",
      "for testing\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "[0.693224310874939, 0.5]\n",
      "for training\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "[0.6930594444274902, 0.5]\n",
      "From epochs:  21  to  40\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "1/1 - 0s - loss: 0.7449 - accuracy: 0.5000 - val_loss: 0.6952 - val_accuracy: 0.0000e+00 - 281ms/epoch - 281ms/step\n",
      "Epoch 2/20\n",
      "1/1 - 0s - loss: 0.6833 - accuracy: 0.5000 - val_loss: 0.6955 - val_accuracy: 0.0000e+00 - 197ms/epoch - 197ms/step\n",
      "Epoch 3/20\n",
      "1/1 - 0s - loss: 0.7087 - accuracy: 0.2500 - val_loss: 0.6960 - val_accuracy: 0.0000e+00 - 237ms/epoch - 237ms/step\n",
      "Epoch 4/20\n",
      "1/1 - 0s - loss: 0.6902 - accuracy: 0.5000 - val_loss: 0.6960 - val_accuracy: 0.0000e+00 - 214ms/epoch - 214ms/step\n",
      "Epoch 5/20\n",
      "1/1 - 0s - loss: 0.6926 - accuracy: 0.5000 - val_loss: 0.6962 - val_accuracy: 0.0000e+00 - 217ms/epoch - 217ms/step\n",
      "Epoch 6/20\n",
      "1/1 - 0s - loss: 0.7217 - accuracy: 0.5000 - val_loss: 0.6964 - val_accuracy: 0.0000e+00 - 209ms/epoch - 209ms/step\n",
      "Epoch 7/20\n",
      "1/1 - 0s - loss: 0.7034 - accuracy: 0.5000 - val_loss: 0.6966 - val_accuracy: 0.0000e+00 - 213ms/epoch - 213ms/step\n",
      "Epoch 8/20\n",
      "1/1 - 0s - loss: 0.7489 - accuracy: 0.5000 - val_loss: 0.6964 - val_accuracy: 0.0000e+00 - 218ms/epoch - 218ms/step\n",
      "Epoch 9/20\n",
      "1/1 - 0s - loss: 0.7033 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.0000e+00 - 228ms/epoch - 228ms/step\n",
      "Epoch 10/20\n",
      "1/1 - 0s - loss: 0.6990 - accuracy: 0.5000 - val_loss: 0.6973 - val_accuracy: 0.0000e+00 - 211ms/epoch - 211ms/step\n",
      "Epoch 11/20\n",
      "1/1 - 0s - loss: 0.6796 - accuracy: 0.7500 - val_loss: 0.6971 - val_accuracy: 0.0000e+00 - 209ms/epoch - 209ms/step\n",
      "Epoch 12/20\n",
      "1/1 - 0s - loss: 0.7150 - accuracy: 0.5000 - val_loss: 0.6977 - val_accuracy: 0.0000e+00 - 204ms/epoch - 204ms/step\n",
      "Epoch 13/20\n",
      "1/1 - 0s - loss: 0.7173 - accuracy: 0.5000 - val_loss: 0.6980 - val_accuracy: 0.0000e+00 - 225ms/epoch - 225ms/step\n",
      "Epoch 14/20\n",
      "1/1 - 0s - loss: 0.6727 - accuracy: 0.7500 - val_loss: 0.6985 - val_accuracy: 0.0000e+00 - 211ms/epoch - 211ms/step\n",
      "Epoch 15/20\n",
      "1/1 - 0s - loss: 0.6828 - accuracy: 0.7500 - val_loss: 0.6988 - val_accuracy: 0.0000e+00 - 223ms/epoch - 223ms/step\n",
      "Epoch 16/20\n",
      "1/1 - 0s - loss: 0.7303 - accuracy: 0.7500 - val_loss: 0.6993 - val_accuracy: 0.0000e+00 - 223ms/epoch - 223ms/step\n",
      "Epoch 17/20\n",
      "1/1 - 0s - loss: 0.7288 - accuracy: 0.5000 - val_loss: 0.7003 - val_accuracy: 0.0000e+00 - 209ms/epoch - 209ms/step\n",
      "Epoch 18/20\n",
      "1/1 - 0s - loss: 0.6731 - accuracy: 0.7500 - val_loss: 0.7008 - val_accuracy: 0.0000e+00 - 212ms/epoch - 212ms/step\n",
      "Epoch 19/20\n",
      "1/1 - 0s - loss: 0.6935 - accuracy: 0.7500 - val_loss: 0.7016 - val_accuracy: 0.0000e+00 - 202ms/epoch - 202ms/step\n",
      "Epoch 20/20\n",
      "1/1 - 0s - loss: 0.6939 - accuracy: 0.2500 - val_loss: 0.7019 - val_accuracy: 0.0000e+00 - 208ms/epoch - 208ms/step\n",
      "<keras.callbacks.History object at 0x00000207006F10C0>\n",
      "Testing time (s) = 4.545333300018683\n",
      "\n",
      "for testing\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6933 - accuracy: 0.5000\n",
      "[0.6933074593544006, 0.5]\n",
      "for training\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6930 - accuracy: 0.5000\n",
      "[0.6930145621299744, 0.5]\n",
      "From epochs:  41  to  60\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "1/1 - 0s - loss: 0.7229 - accuracy: 0.5000 - val_loss: 0.7012 - val_accuracy: 0.0000e+00 - 271ms/epoch - 271ms/step\n",
      "Epoch 2/20\n",
      "1/1 - 0s - loss: 0.6932 - accuracy: 0.2500 - val_loss: 0.7016 - val_accuracy: 0.0000e+00 - 196ms/epoch - 196ms/step\n",
      "Epoch 3/20\n",
      "1/1 - 0s - loss: 0.6913 - accuracy: 0.7500 - val_loss: 0.7016 - val_accuracy: 0.0000e+00 - 211ms/epoch - 211ms/step\n",
      "Epoch 4/20\n",
      "1/1 - 0s - loss: 0.6901 - accuracy: 0.7500 - val_loss: 0.7020 - val_accuracy: 0.0000e+00 - 217ms/epoch - 217ms/step\n",
      "Epoch 5/20\n",
      "1/1 - 0s - loss: 0.7630 - accuracy: 0.2500 - val_loss: 0.7021 - val_accuracy: 0.0000e+00 - 202ms/epoch - 202ms/step\n",
      "Epoch 6/20\n",
      "1/1 - 0s - loss: 0.7184 - accuracy: 0.5000 - val_loss: 0.7022 - val_accuracy: 0.0000e+00 - 214ms/epoch - 214ms/step\n",
      "Epoch 7/20\n",
      "1/1 - 0s - loss: 0.7059 - accuracy: 0.7500 - val_loss: 0.7032 - val_accuracy: 0.0000e+00 - 219ms/epoch - 219ms/step\n",
      "Epoch 8/20\n",
      "1/1 - 0s - loss: 0.6879 - accuracy: 0.5000 - val_loss: 0.7024 - val_accuracy: 0.0000e+00 - 201ms/epoch - 201ms/step\n",
      "Epoch 9/20\n",
      "1/1 - 0s - loss: 0.6804 - accuracy: 0.5000 - val_loss: 0.7022 - val_accuracy: 0.0000e+00 - 262ms/epoch - 262ms/step\n",
      "Epoch 10/20\n",
      "1/1 - 0s - loss: 0.7056 - accuracy: 0.5000 - val_loss: 0.7024 - val_accuracy: 0.0000e+00 - 217ms/epoch - 217ms/step\n",
      "Epoch 11/20\n",
      "1/1 - 0s - loss: 0.6735 - accuracy: 0.7500 - val_loss: 0.7023 - val_accuracy: 0.0000e+00 - 171ms/epoch - 171ms/step\n",
      "Epoch 12/20\n",
      "1/1 - 0s - loss: 0.7328 - accuracy: 0.7500 - val_loss: 0.7029 - val_accuracy: 0.0000e+00 - 207ms/epoch - 207ms/step\n",
      "Epoch 13/20\n",
      "1/1 - 0s - loss: 0.6683 - accuracy: 0.7500 - val_loss: 0.7032 - val_accuracy: 0.0000e+00 - 189ms/epoch - 189ms/step\n",
      "Epoch 14/20\n",
      "1/1 - 0s - loss: 0.6685 - accuracy: 0.5000 - val_loss: 0.7032 - val_accuracy: 0.0000e+00 - 213ms/epoch - 213ms/step\n",
      "Epoch 15/20\n",
      "1/1 - 0s - loss: 0.6797 - accuracy: 0.2500 - val_loss: 0.7029 - val_accuracy: 0.0000e+00 - 227ms/epoch - 227ms/step\n",
      "Epoch 16/20\n",
      "1/1 - 0s - loss: 0.6703 - accuracy: 0.2500 - val_loss: 0.7034 - val_accuracy: 0.0000e+00 - 201ms/epoch - 201ms/step\n",
      "Epoch 17/20\n",
      "1/1 - 0s - loss: 0.6686 - accuracy: 0.5000 - val_loss: 0.7037 - val_accuracy: 0.0000e+00 - 184ms/epoch - 184ms/step\n",
      "Epoch 18/20\n",
      "1/1 - 0s - loss: 0.6802 - accuracy: 0.5000 - val_loss: 0.7037 - val_accuracy: 0.0000e+00 - 200ms/epoch - 200ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "1/1 - 0s - loss: 0.6860 - accuracy: 0.5000 - val_loss: 0.7041 - val_accuracy: 0.0000e+00 - 205ms/epoch - 205ms/step\n",
      "Epoch 20/20\n",
      "1/1 - 0s - loss: 0.6752 - accuracy: 0.7500 - val_loss: 0.7045 - val_accuracy: 0.0000e+00 - 214ms/epoch - 214ms/step\n",
      "<keras.callbacks.History object at 0x000002070064EAA0>\n",
      "Testing time (s) = 4.412202499981504\n",
      "\n",
      "for testing\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6933 - accuracy: 0.5000\n",
      "[0.6933435201644897, 0.5]\n",
      "for training\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6930 - accuracy: 0.5000\n",
      "[0.6929892897605896, 0.5]\n",
      "From epochs:  61  to  80\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "1/1 - 0s - loss: 0.6644 - accuracy: 0.7500 - val_loss: 0.7047 - val_accuracy: 0.0000e+00 - 272ms/epoch - 272ms/step\n",
      "Epoch 2/20\n",
      "1/1 - 0s - loss: 0.6802 - accuracy: 0.5000 - val_loss: 0.7048 - val_accuracy: 0.0000e+00 - 191ms/epoch - 191ms/step\n",
      "Epoch 3/20\n",
      "1/1 - 0s - loss: 0.6838 - accuracy: 0.7500 - val_loss: 0.7041 - val_accuracy: 0.0000e+00 - 196ms/epoch - 196ms/step\n",
      "Epoch 4/20\n",
      "1/1 - 0s - loss: 0.6801 - accuracy: 0.5000 - val_loss: 0.7037 - val_accuracy: 0.0000e+00 - 194ms/epoch - 194ms/step\n",
      "Epoch 5/20\n",
      "1/1 - 0s - loss: 0.6864 - accuracy: 0.2500 - val_loss: 0.7034 - val_accuracy: 0.0000e+00 - 192ms/epoch - 192ms/step\n",
      "Epoch 6/20\n",
      "1/1 - 0s - loss: 0.6575 - accuracy: 0.7500 - val_loss: 0.7027 - val_accuracy: 0.0000e+00 - 203ms/epoch - 203ms/step\n",
      "Epoch 7/20\n",
      "1/1 - 0s - loss: 0.6781 - accuracy: 0.5000 - val_loss: 0.7022 - val_accuracy: 0.0000e+00 - 210ms/epoch - 210ms/step\n",
      "Epoch 8/20\n",
      "1/1 - 0s - loss: 0.6707 - accuracy: 0.7500 - val_loss: 0.7015 - val_accuracy: 0.0000e+00 - 208ms/epoch - 208ms/step\n",
      "Epoch 9/20\n",
      "1/1 - 0s - loss: 0.7207 - accuracy: 0.5000 - val_loss: 0.7014 - val_accuracy: 0.0000e+00 - 210ms/epoch - 210ms/step\n",
      "Epoch 10/20\n",
      "1/1 - 0s - loss: 0.6570 - accuracy: 0.5000 - val_loss: 0.7013 - val_accuracy: 0.0000e+00 - 194ms/epoch - 194ms/step\n",
      "Epoch 11/20\n",
      "1/1 - 0s - loss: 0.6655 - accuracy: 0.7500 - val_loss: 0.7012 - val_accuracy: 0.0000e+00 - 197ms/epoch - 197ms/step\n",
      "Epoch 12/20\n",
      "1/1 - 0s - loss: 0.6965 - accuracy: 0.7500 - val_loss: 0.7018 - val_accuracy: 0.0000e+00 - 213ms/epoch - 213ms/step\n",
      "Epoch 13/20\n",
      "1/1 - 0s - loss: 0.6758 - accuracy: 0.7500 - val_loss: 0.7024 - val_accuracy: 0.0000e+00 - 200ms/epoch - 200ms/step\n",
      "Epoch 14/20\n",
      "1/1 - 0s - loss: 0.7165 - accuracy: 0.7500 - val_loss: 0.7022 - val_accuracy: 0.0000e+00 - 216ms/epoch - 216ms/step\n",
      "Epoch 15/20\n",
      "1/1 - 0s - loss: 0.7162 - accuracy: 0.2500 - val_loss: 0.7023 - val_accuracy: 0.0000e+00 - 206ms/epoch - 206ms/step\n",
      "Epoch 16/20\n",
      "1/1 - 0s - loss: 0.6589 - accuracy: 0.5000 - val_loss: 0.7022 - val_accuracy: 0.0000e+00 - 204ms/epoch - 204ms/step\n",
      "Epoch 17/20\n",
      "1/1 - 0s - loss: 0.6595 - accuracy: 0.7500 - val_loss: 0.7019 - val_accuracy: 0.0000e+00 - 200ms/epoch - 200ms/step\n",
      "Epoch 18/20\n",
      "1/1 - 0s - loss: 0.6751 - accuracy: 0.5000 - val_loss: 0.7023 - val_accuracy: 0.0000e+00 - 225ms/epoch - 225ms/step\n",
      "Epoch 19/20\n",
      "1/1 - 0s - loss: 0.6637 - accuracy: 0.5000 - val_loss: 0.7028 - val_accuracy: 0.0000e+00 - 202ms/epoch - 202ms/step\n",
      "Epoch 20/20\n",
      "1/1 - 0s - loss: 0.6763 - accuracy: 0.5000 - val_loss: 0.7027 - val_accuracy: 0.0000e+00 - 203ms/epoch - 203ms/step\n",
      "<keras.callbacks.History object at 0x0000020703BEFA30>\n",
      "Testing time (s) = 4.330953099997714\n",
      "\n",
      "for testing\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6933 - accuracy: 0.5000\n",
      "[0.6933249235153198, 0.5]\n",
      "for training\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6928 - accuracy: 0.5000\n",
      "[0.6928286552429199, 0.5]\n"
     ]
    }
   ],
   "source": [
    "for x in range(4):\n",
    "    print(\"From epochs: \",20*x+1,\" to \",20+20*x)\n",
    "    tic = start_timer()\n",
    "    print(model.fit(x=train_dataset,y=train_dataset_label,batch_size=BATCH_SIZE, epochs=20, initial_epoch = 0, verbose=2,validation_split=0.40,shuffle=True))\n",
    "    toc = end_timer()\n",
    "    show_time(tic,toc)\n",
    "    print(\"for testing\")\n",
    "    print(model.evaluate(test_dataset,test_dataset_label))\n",
    "    print(\"for training\")\n",
    "    print(model.evaluate(train_dataset,train_dataset_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f64e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
