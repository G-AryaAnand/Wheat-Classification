{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b605089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "from math import inf as inf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Constants\n",
    "TESTING = False\n",
    "\n",
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.7\n",
    "IMAGE_COUNT = 5\n",
    "DATA_DIRECTORY = \"D:\\mvl\\wheat\\data\\BULK\\\\\"\n",
    "NUM_VARIETIES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if len(VARIETIES)>NUM_VARIETIES:\n",
    "        break\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20b64642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for all file names in varities\n",
    "FILES = []\n",
    "MAX_FILE_NUM = 4\n",
    "for x in range(1,MAX_FILE_NUM+1):\n",
    "    FILES.append(\"B_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5e32422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactPathHDR(variety,file):\n",
    "    return DATA_DIRECTORY+variety+\"\\\\\"+file+\".bil.hdr\"\n",
    "\n",
    "def exactPathBIL(variety,file):\n",
    "    return DATA_DIRECTORY+variety+\"\\\\\"+file+\".bil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a072b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all images\n",
    "images = []\n",
    "images_label = []\n",
    "for v in VARIETIES:\n",
    "    for f in FILES:\n",
    "        try:\n",
    "            img = envi.open(exactPathHDR(v,f),exactPathBIL(v,f))\n",
    "            images.append(img)\n",
    "            images_label.append(v)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10991a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROI(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    threshold = threshold_otsu(img_band)\n",
    "    roi=[]\n",
    "    for x in range(img_band.shape[0]):\n",
    "        a=[]\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if img_band[x][y]>threshold:\n",
    "                a.append(1)\n",
    "            else:\n",
    "                a.append(0)\n",
    "        roi.append(a)\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f92ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns range for x and y from where we have to crop images\n",
    "def getRangeXandY(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    roi = getROI(img,band_number)\n",
    "    xmin = inf\n",
    "    xmax = 0\n",
    "    ymin = inf\n",
    "    ymax = 0\n",
    "    for x in range(img_band.shape[0]):\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if roi[x][y]==1:\n",
    "                if x<xmin:\n",
    "                    xmin=x\n",
    "                if x>xmax:\n",
    "                    xmax=x\n",
    "                if y<ymin:\n",
    "                    ymin=y\n",
    "                if y>ymax:\n",
    "                    ymax=y\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09705166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedImage(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    new_img = img[xmin:xmax, ymin:ymax, :]\n",
    "    return new_img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97d1f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedROI(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    roi = np.array(getROI(img,band_number))\n",
    "    roi = roi[xmin:xmax, ymin:ymax]\n",
    "    return roi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "318efc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsefulImage(img,band_number):\n",
    "    crop_img = getCroppedImage(img,band_number)\n",
    "    crop_roi = getCroppedROI(img,band_number)\n",
    "    for x in range(crop_img.shape[2]):\n",
    "        band = crop_img[:,:,x]\n",
    "        crop_img[:,:,x] = band*crop_roi\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad2376a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomCrop(height=40, width=40),\n",
    "    layers.RandomRotation(factor=(-0.1, 0.1)),\n",
    "    layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1,0.1)),\n",
    "])\n",
    "\n",
    "def getAugumentedImage(img,band_number):\n",
    "    new_img = getUsefulImage(img,band_number)\n",
    "    augmented_image = data_augmentation(new_img) \n",
    "    return augmented_image\n",
    "\n",
    "def checkAugumentedImage(augmented_image):\n",
    "    aug_band = augmented_image[:,:,0]\n",
    "    filled_area_ratio = (np.count_nonzero(aug_band))/(aug_band.shape[0]*aug_band.shape[1])\n",
    "    if filled_area_ratio > FILLED_AREA_RATIO :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad47ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensional Reduction Method\n",
    "def DL_Method(HSI, numComponents = 75):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    n_batches = 10\n",
    "    inc_pca = IncrementalPCA(n_components=numComponents)\n",
    "    for X_batch in np.array_split(RHSI, n_batches):\n",
    "        inc_pca.partial_fit(X_batch)\n",
    "    X_ipca = inc_pca.transform(RHSI)\n",
    "    RHSI = np.reshape(X_ipca, (HSI.shape[0],HSI.shape[1], numComponents))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "train_dataset_label = []\n",
    "test_dataset = []\n",
    "test_dataset_label = []\n",
    "\n",
    "for index, img in enumerate(images):\n",
    "    count = 0\n",
    "    label = images_label[index]\n",
    "    while count<IMAGE_COUNT:\n",
    "        aug_img = getAugumentedImage(img,BAND_NUMBER)\n",
    "        \n",
    "        if checkAugumentedImage(aug_img):\n",
    "            aug_img = DL_Method(aug_img[:,:,21:150])\n",
    "            if count%5 == 0:\n",
    "                test_dataset.append(aug_img)\n",
    "                test_dataset_label.append(label)\n",
    "            else:\n",
    "                train_dataset.append(aug_img)\n",
    "                train_dataset_label.append(label)\n",
    "            count+=1  \n",
    "            \n",
    "    if TESTING:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,data in enumerate(test_dataset):\n",
    "    imshow(data)\n",
    "    print(test_dataset_label[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc54f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,data in enumerate(train_dataset):\n",
    "    imshow(data)\n",
    "    print(train_dataset_label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import math, sys, pdb, os\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from keras import activations\n",
    "import vis\n",
    "# from vis.visualization import visualize_saliency, overlay\n",
    "# from vis.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ce22266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hyperparam_string(USE_DATA_AUG, learning_rate_base, batch_size, kernel_size, dropout_rate, num_training,\n",
    "                           num_nodes_fc, activation_type):\n",
    "    hparam = \"\"\n",
    "\n",
    "    # Hyper-parameters\n",
    "    if USE_DATA_AUG:\n",
    "        hparam += \"AUG_\"\n",
    "\n",
    "    hparam += str(num_nodes_fc) + \"nodes_\" + str(learning_rate_base) + \"lr_\" + str(batch_size) + \"batch_\" + str(\n",
    "        kernel_size) + \"kernel_\" + str(dropout_rate) + \"drop_\" + str(\n",
    "        num_training) + \"train_\" + activation_type\n",
    "\n",
    "    return hparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fd4a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.clim(0,sum(cm[0,:]))\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d67d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_K_classification_accuracy(y_predicted, y_true, K=1):\n",
    "\n",
    "    num_samples = y_predicted.shape[0]\n",
    "    num_classes = y_predicted.shape[1]\n",
    "\n",
    "    if K > num_classes:\n",
    "        sys.exit(1)\n",
    "\n",
    "    temp = np.zeros((num_samples,))\n",
    "\n",
    "    for idx in range(num_samples):\n",
    "        curr_predicted = np.argsort(y_predicted[idx,:])\n",
    "        curr_predicted = curr_predicted[::-1] # descending\n",
    "\n",
    "        if y_true[idx] in curr_predicted[:K]:\n",
    "            temp[idx] = 1\n",
    "\n",
    "    return 100.0 * np.sum(temp)/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "351725d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    x_orig = x\n",
    "\n",
    "    # Batch norm\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 1x1 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D, kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    if activation_type == 'LeakyReLU':\n",
    "        x = LeakyReLU()(x)\n",
    "    elif activation_type == 'PReLU':\n",
    "        x = PReLU()(x)\n",
    "    else:\n",
    "        x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 3x3 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D, kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    if activation_type == 'LeakyReLU':\n",
    "        x = LeakyReLU()(x)\n",
    "    elif activation_type == 'PReLU':\n",
    "        x = PReLU()(x)\n",
    "    else:\n",
    "        x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 1x1 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D*4, kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Skip connection\n",
    "    if int(x.shape[3]) != int(x_orig.shape[3]):\n",
    "        x_orig = Conv2D(int(x.shape[3]), kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x_orig)\n",
    "\n",
    "    # Activation\n",
    "    if activation_type == 'LeakyReLU':\n",
    "        x = LeakyReLU()(x)\n",
    "    elif activation_type == 'PReLU':\n",
    "        x = PReLU()(x)\n",
    "    else:\n",
    "        x = Activation(activation_type)(x)\n",
    "\n",
    "    x = Add()([x, x_orig])\n",
    "\n",
    "    # Dropout\n",
    "    return Dropout(dropout_rate)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0731a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBlock_ResNet2D(x, num_layers, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    for idx_layer in range(num_layers):\n",
    "\n",
    "        x = conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45bd16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth_rate: number of filters for each normal convolution ('k' in the paper)\n",
    "def ResNet2D_classifier(data_num_rows, data_num_cols, num_classes, kernel_size=3, num_layers_each_block=[6, 12, 24, 16],\n",
    "                        num_chan_per_block = [64,128,256,512], activation_type='swish', dropout_rate=0.0, num_input_chans=1, num_nodes_fc=64):\n",
    "\n",
    "    input_data = Input(shape=(data_num_rows, data_num_cols, num_input_chans))\n",
    "\n",
    "    # Input layer: Conv2D -> activation\n",
    "    x = Conv2D(num_chan_per_block[0], kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(input_data)\n",
    "\n",
    "    # Activation\n",
    "    if activation_type == 'LeakyReLU':\n",
    "        x = LeakyReLU()(x)\n",
    "    elif activation_type == 'PReLU':\n",
    "        x = PReLU()(x)\n",
    "    else:\n",
    "        x = Activation(activation_type)(x)\n",
    "\n",
    "    #  Blocks & Downsampling Layers\n",
    "    for idx_block in range(len(num_layers_each_block)):\n",
    "        x = createBlock_ResNet2D(x, num_layers_each_block[idx_block], kernel_size, activation_type, dropout_rate,\n",
    "                                 num_chan_per_block[idx_block])\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if idx_block != len(num_layers_each_block)-1:\n",
    "            x = Conv2D(num_chan_per_block[idx_block]*2, kernel_size, strides = 2, activation=None, use_bias=True, padding='valid',\n",
    "                   kernel_initializer='truncated_normal')(x)\n",
    "        else:\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(units=num_nodes_fc, activation=None, kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    if activation_type == 'LeakyReLU':\n",
    "        x = LeakyReLU()(x)\n",
    "    elif activation_type == 'PReLU':\n",
    "        x = PReLU()(x)\n",
    "    else:\n",
    "        x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    output_data = Dense(units=num_classes, activation='softmax', kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    return Model(inputs=input_data, outputs=output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6797662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndTrainResNetB(params):\n",
    "                                        \n",
    "    ############ Extract params ############\n",
    "    USE_DATA_AUG = params['USE_DATA_AUG']\n",
    "    learning_rate_base = params['learning_rate_base']\n",
    "    kernel_size = params['kernel_size']\n",
    "    num_epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    activation_type = params['activation_type']\n",
    "    num_nodes_fc = params['num_nodes_fc']\n",
    "    wheat_types = params['wheat_types']\n",
    "    normalization_type = params['normalization_type']\n",
    "    num_layers_each_block = params['num_layers_each_block']\n",
    "    num_chan_per_block = params['num_chan_per_block']\n",
    "    N_classes = len(wheat_types)\n",
    "    \n",
    "    \n",
    "    ############ Load data ############\n",
    "    print(\"--------------Load Data--------------\")\n",
    "\n",
    "    # Load training data and their corresponding labels\n",
    "    x_training = np.array(train_dataset)\n",
    "    labels_training = np.array(train_dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_training = normalizeDataWholeSeed(x_training,normalization_type=normalization_type)\n",
    "    \n",
    "    # Extract some information\n",
    "    num_training = x_training.shape[0]\n",
    "    N_spatial = x_training.shape[1:3]\n",
    "    N_bands = x_training.shape[3]\n",
    "    num_batch_per_epoch = int(num_training/batch_size)\n",
    "    \n",
    "    print('#training = %d' %(num_training))\n",
    "    print('#batches per epoch = %d' %(num_batch_per_epoch))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "    \n",
    "    \n",
    "    ############ Prepare the path for saving the models/stats ############\n",
    "    print(\"--------------Prepare a path for saving the models/stats--------------\")\n",
    "    \n",
    "    hparams = make_hyperparam_string(USE_DATA_AUG, learning_rate_base, batch_size, kernel_size, dropout_rate,\n",
    "                                     num_training, num_nodes_fc, activation_type)\n",
    "    print('Saving the model to...')\n",
    "    \n",
    "    results_dir = os.path.join(params['results_base_directory'],hparams)\n",
    "    \n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    print(results_dir)\n",
    "\n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Create a model ############\n",
    "    print(\"--------------Create a model--------------\")\n",
    "    \n",
    "    # Generate a model\n",
    "    model = ResNet2D_classifier(data_num_rows=N_spatial[0], data_num_cols=N_spatial[1], num_classes=N_classes,\n",
    "                                kernel_size=kernel_size, num_layers_each_block=num_layers_each_block,\n",
    "                                num_chan_per_block=num_chan_per_block, activation_type=activation_type,\n",
    "                                dropout_rate=dropout_rate, num_input_chans=N_bands, num_nodes_fc=num_nodes_fc)\n",
    "\n",
    "    # Compile the model\n",
    "    adam_opt = Adam(lr=learning_rate_base / batch_size, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam_opt, metrics=['acc'])\n",
    "\n",
    "    # Create a Tensorboard callback\n",
    "    tbCallBack = TensorBoard(log_dir=results_dir, histogram_freq=0, write_graph=False, write_images=False)\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Train the model ############\n",
    "    print(\"--------------Begin training the model--------------\")\n",
    "\n",
    "    # Possibly perform data augmentation\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    \n",
    "    if USE_DATA_AUG:\n",
    "        width_shift_range = 0.04\n",
    "        height_shift_range = 0.04\n",
    "        HORIZONTAL_FLIP = True\n",
    "        VERTICAL_FLIP = True\n",
    "        data_gen_args = dict(\n",
    "            rotation_range=0.,\n",
    "            width_shift_range=width_shift_range,\n",
    "            height_shift_range=height_shift_range,\n",
    "            horizontal_flip=HORIZONTAL_FLIP,\n",
    "            vertical_flip=VERTICAL_FLIP,\n",
    "            fill_mode = 'wrap')\n",
    "\n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    else:\n",
    "        image_datagen = ImageDataGenerator()\n",
    "\n",
    "    # Define a data generator to generate random batches\n",
    "    def myGenerator(batch_size):\n",
    "        for x_batch, y_batch in image_datagen.flow(x_training, labels_training, batch_size=batch_size, shuffle = True):\n",
    "            yield (x_batch, y_batch)\n",
    "\n",
    "    my_generator = myGenerator(batch_size)\n",
    "\n",
    "    tic = timeit.default_timer()\n",
    "    \n",
    "    # Train the model\n",
    "    hist = model.fit_generator(my_generator, steps_per_epoch=num_batch_per_epoch, epochs = num_epochs, initial_epoch = 0, verbose=2, callbacks = [tbCallBack])\n",
    "\n",
    "    toc = timeit.default_timer()\n",
    "    training_time = toc-tic\n",
    "    print(\"Total training time = \" + str(training_time))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    print(\"--------------Make Predictions--------------\")\n",
    "    # In this example script, we use the training data as the test data\n",
    "    x_test = x_training\n",
    "    labels_test = labels_training\n",
    "    num_test = num_training\n",
    "\n",
    "    tic = timeit.default_timer()\n",
    "    labels_predicted_test = model.predict(x_test)\n",
    "    toc = timeit.default_timer()\n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')\n",
    "\n",
    "    ### Evaluation metrics\n",
    "\n",
    "    # Classification accuracy\n",
    "    labels_test_integer_format = np.argmax(labels_test, axis=1)\n",
    "    labels_predicted_test_integer_format = np.argmax(labels_predicted_test, axis=1)\n",
    "\n",
    "    acc_top2 = top_K_classification_accuracy(labels_predicted_test, labels_test_integer_format, K=2)\n",
    "    acc_top1 = top_K_classification_accuracy(labels_predicted_test, labels_test_integer_format, K=1)\n",
    "\n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_test_integer_format, labels_predicted_test_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "#     macro_avg = np.asarray(\n",
    "#         precision_recall_fscore_support(labels_test_integer_format, labels_predicted_test_integer_format,\n",
    "#                                         average='macro'))\n",
    "#     macro_avg_precision = macro_avg[0]\n",
    "#     macro_avg_recall = macro_avg[1]\n",
    "#     macro_avg_fscore = macro_avg[2]\n",
    "\n",
    "#     print('Top-1 accuracy (%) = ' + str(acc_top1) + '\\n')\n",
    "#     print('Top-2 accuracy (%) = ' + str(acc_top2) + '\\n')\n",
    "#     print('Macro-avg precision = ' + str(macro_avg_precision) + '\\n')\n",
    "#     print('Macro-avg recall = ' + str(macro_avg_recall) + '\\n')\n",
    "#     print('Macro-avg f-score = ' + str(macro_avg_fscore) + '\\n')\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Compute Saliency Maps--------------\")\n",
    "#     results_test_dir = os.path.join(results_dir, 'test')\n",
    "#     if not os.path.exists(results_test_dir):\n",
    "#         os.makedirs(results_test_dir)\n",
    "\n",
    "#     # Swap softmax with linear\n",
    "#     model.layers[-1].activation = activations.linear\n",
    "#     model = utils.apply_modifications(model)\n",
    "\n",
    "#     for idx_wheat in range(num_test):\n",
    "\n",
    "#         grads = visualize_saliency(model, layer_idx=-1, filter_indices=np.argmax(labels_test[idx_wheat, :], axis=0),\n",
    "#                                    seed_input=x_test[idx_wheat], backprop_modifier=None)\n",
    "\n",
    "#         ss_img = np.sqrt(np.sum(abs(x_test[idx_wheat, :, :, :]) ** 2, axis=2))\n",
    "#         ss_img /= np.max(ss_img)\n",
    "\n",
    "#         plt.figure(1)\n",
    "#         plt.subplot(3, 1, 1)\n",
    "#         plt.imshow(ss_img, cmap='gray')\n",
    "#         plt.clim(0, 1)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         plt.subplot(3, 1, 2)\n",
    "#         plt.imshow((grads * np.uint8(255)).astype('uint8'), cmap='jet')\n",
    "#         plt.clim(0, 255)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * np.uint8(255))\n",
    "\n",
    "#         plt.subplot(3, 1, 3)\n",
    "#         ss_img = cv2.cvtColor((ss_img * np.uint8(255)).astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "#         plt.imshow(overlay(jet_heatmap, ss_img, alpha=0.3))\n",
    "#         plt.clim(0, 255)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         plt.savefig(os.path.join(results_test_dir, str(idx_wheat+1) + '.png'))\n",
    "#         plt.clf()\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Save the information--------------\")\n",
    "\n",
    "#     # Write some information to files\n",
    "#     f = open(os.path.join(results_test_dir, 'testing_info.txt'), 'w')\n",
    "#     f.write(\"Wheat types = \" + str(wheat_types) + \"\\n\")\n",
    "#     f.write(\"Confusion matrix \\n\")\n",
    "#     f.write(str(confusion_matrix_results) + \"\\n\")\n",
    "#     f.write(\"Normalization type = \" + str(normalization_type) + \"\\n\")\n",
    "#     f.write(\"# test samples = %d \\n\" % (num_test))\n",
    "#     f.write(\"Top-1 test accuracy = %f \\n\" % (acc_top1))\n",
    "#     f.write(\"Top-2 test accuracy = %f \\n\" % (acc_top2))\n",
    "#     f.write(\"Macro-avg precision = %f \\n\" % (macro_avg_precision))\n",
    "#     f.write(\"Macro-avg recall = %f \\n\" % (macro_avg_recall))\n",
    "#     f.write(\"Macro-avg f-score = %f \\n\" % (macro_avg_fscore))\n",
    "#     f.write(\"Test time (s) = \" + str(test_time) + \"\\n\")\n",
    "#     f.close()\n",
    "\n",
    "#     # Save confusion matrices\n",
    "#     plt.figure(1)\n",
    "#     plot_confusion_matrix(confusion_matrix_results, classes=wheat_types, normalize=False, title='Confusion matrix')\n",
    "#     plt.savefig(os.path.join(results_test_dir,'confusionMatrix.png'))\n",
    "#     plt.clf()\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Save the information for the training phase--------------\")\n",
    "    \n",
    "#     import pandas as pd\n",
    "    \n",
    "#     # Save the trained model\n",
    "#     model.save_weights(os.path.join(results_dir, 'trainedResNetB_weights.h5'))\n",
    "    \n",
    "#     # Extract the training loss   \n",
    "#     training_loss = hist.history['loss']\n",
    "\n",
    "#     # Save the training loss\n",
    "#     df = pd.DataFrame(data={'training loss': training_loss},index=np.arange(num_epochs)+1)\n",
    "#     df.to_csv(os.path.join(results_dir,'training_loss.csv'))\n",
    "    \n",
    "#     # Save the training loss as a figure\n",
    "#     plt.figure(1)\n",
    "#     plt.title('Loss')\n",
    "#     plt.plot(training_loss, color='b',label='Training')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.savefig(os.path.join(results_dir,'training_loss.png'))\n",
    "#     plt.clf()   \n",
    "    \n",
    "#     # Write a file with general information\n",
    "#     f = open(os.path.join(results_dir,'training_info.txt'),'w')\n",
    "#     f.write(hparams + '\\n')\n",
    "#     f.write('Wheat types = ' + str(wheat_types)+'\\n')\n",
    "#     f.write('Training time (s) = %f \\n' %(training_time))\n",
    "#     f.write('Normalization type = ' + str(normalization_type)+ '\\n')\n",
    "#     f.write('# epochs = ' + str(num_epochs) + '\\n')\n",
    "#     f.write('# training samples = %d \\n' %(num_training))\n",
    "#     f.close()\n",
    "    \n",
    "#     print(\"--------------Done--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f8da36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (mostly determined using validation datasets)\n",
    "params = dict()\n",
    "params['normalization_type'] = 'max'                    # Data normalization type\n",
    "params['wheat_types'] = VARIETIES\n",
    "params['num_epochs'] = 400                              # Number of epochs\n",
    "params['kernel_size'] = 3                               # Kernel size\n",
    "params['dropout_rate'] = 0.0                            # Dropout rate\n",
    "params['num_nodes_fc'] = 512                            # Number of  nodes in the fully-connected layers\n",
    "params['num_layers_each_block'] = [8, 8, 12, 8]         # Number of layers per block\n",
    "params['num_chan_per_block'] = [128, 128, 256, 256]     # Number of filters in the conv layers\n",
    "params['results_base_directory'] = './results/'  # Directory of saving results\n",
    "\n",
    "# In our experiment where we have the full training set, we set\n",
    "# USE_DATA_AUG = True, learning_rate_base = 0.005, and batch_size = 4.\n",
    "# However, in this example script, we modified them to simplify our training process on this\n",
    "# example dataset\n",
    "params['batch_size'] = 5                    # Batch size\n",
    "params['USE_DATA_AUG'] = False              # Use data augmentation (In the paper, we set it to True)\n",
    "params['learning_rate_base'] = 0.00001      # Initial learning rate (In the paper, we set it to 0.005)\n",
    "\n",
    "# Add 'swish' activation\n",
    "if params['activation_type'] == 'swish':\n",
    "\n",
    "    from keras.utils.generic_utils import get_custom_objects\n",
    "    import keras.backend as K\n",
    "\n",
    "    # Taken from https://github.com/dataplayer12/swish-activation/blob/master/MNIST/activations.ipynb\n",
    "    def swish(x):\n",
    "        beta = tf.Variable(initial_value=1.0,trainable=True)\n",
    "        return x*tf.nn.sigmoid(beta*x)\n",
    "\n",
    "    get_custom_objects().update({'swish': swish})\n",
    "\n",
    "#uncomment this to train the model\n",
    "createAndTrainResNetB(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13981ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
