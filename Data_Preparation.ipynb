{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b605089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from math import inf as inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/nitintyagi/wheat data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\mvl\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.5\n",
    "TOTAL_IMAGE_COUNT = 8\n",
    "IMAGE_COUNT = int(TOTAL_IMAGE_COUNT/4)\n",
    "NUM_VARIETIES = 4\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30\n",
    "\n",
    "FILTER = \"snv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82eeade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    " \n",
    "class feature_extraction_method(Enum):\n",
    "    none = 0\n",
    "    pca_loading = 1\n",
    "    lda = 2\n",
    "    ipca = 3\n",
    "\n",
    "FEATURE_EXTRACTION = feature_extraction_method(3).name\n",
    "\n",
    "NUM_OF_BANDS = 3\n",
    "if FEATURE_EXTRACTION == \"pca_loading\" or FEATURE_EXTRACTION == \"ipca\":\n",
    "    NUM_OF_BANDS = 8\n",
    "elif FEATURE_EXTRACTION == \"lda\":\n",
    "    NUM_OF_BANDS = 3\n",
    "    assert NUM_OF_BANDS <= min(NUM_VARIETIES-1,168),\"NUM_OF_BANDS is greater.\"\n",
    "\n",
    "\n",
    "REMOVE_NOISY_BANDS = False\n",
    "FIRST_BAND = 21\n",
    "LAST_BAND = 149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e32422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactPathHDR(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil.hdr\"\n",
    "\n",
    "def exactPathBIL(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10991a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROI(img, band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    threshold = threshold_otsu(img_band)\n",
    "    roi=[]\n",
    "    for x in range(img_band.shape[0]):\n",
    "        a=[]\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if img_band[x][y]>threshold:\n",
    "                a.append(1)\n",
    "            else:\n",
    "                a.append(0)\n",
    "        roi.append(a)\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f92ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns range for x and y from where we have to crop images\n",
    "def getRangeXandY(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    roi = getROI(img,band_number)\n",
    "    xmin = inf\n",
    "    xmax = 0\n",
    "    ymin = inf\n",
    "    ymax = 0\n",
    "    for x in range(img_band.shape[0]):\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if roi[x][y]==1:\n",
    "                if x<xmin:\n",
    "                    xmin=x\n",
    "                if x>xmax:\n",
    "                    xmax=x\n",
    "                if y<ymin:\n",
    "                    ymin=y\n",
    "                if y>ymax:\n",
    "                    ymax=y\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09705166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedImage(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    new_img = img[xmin:xmax, ymin:ymax, :]\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97d1f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedROI(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    roi = np.array(getROI(img,band_number))\n",
    "    roi = roi[xmin:xmax, ymin:ymax]\n",
    "    return roi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "318efc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsefulImage(img,band_number):\n",
    "    crop_img = getCroppedImage(img,band_number)\n",
    "    crop_roi = getCroppedROI(img,band_number)\n",
    "    for x in range(crop_img.shape[2]):\n",
    "        band = crop_img[:,:,x]\n",
    "        crop_img[:,:,x] = band*crop_roi\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b7e5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessHSI(img, band_number):\n",
    "    img = getUsefulImage(img, band_number)\n",
    "#     preprocessing to be done before data augmentation\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad2376a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    layers.RandomRotation(factor=(-0.1, 0.1)),\n",
    "    layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1,0.1)),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=None)\n",
    "])\n",
    "\n",
    "def getAugumentedImage(img):\n",
    "    augmented_image = data_augmentation(img) \n",
    "    return augmented_image\n",
    "\n",
    "def checkAugumentedImage(img):\n",
    "    aug_band = img[:,:,0]\n",
    "    filled_area_ratio = (np.count_nonzero(aug_band))/(aug_band.shape[0]*aug_band.shape[1])\n",
    "    if filled_area_ratio > FILLED_AREA_RATIO :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b64642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for all file names in varities\n",
    "FILES = []\n",
    "MAX_FILE_NUM = 4\n",
    "for x in range(1,MAX_FILE_NUM+1):\n",
    "    FILES.append(\"B_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a072b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractRawImages(v):\n",
    "    #List of all images\n",
    "    images = []\n",
    "    for f in FILES:\n",
    "        try:\n",
    "            img = envi.open(exactPathHDR(v,f),exactPathBIL(v,f))\n",
    "            img = preprocessHSI(img, BAND_NUMBER)\n",
    "            images.append(img)\n",
    "        except:\n",
    "            pass\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c910c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ) Label:  PBW 291  Index:  15  Count:  2\n",
      "Testing time (s) = 8.469696099999993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def createDataset(images, label):\n",
    "    train_dataset = []\n",
    "    train_dataset_label = []\n",
    "    test_dataset = []\n",
    "    test_dataset_label = []\n",
    "    tic = start_timer()\n",
    "    for index, img in enumerate(images):\n",
    "        count = 0\n",
    "        while count<IMAGE_COUNT:\n",
    "            aug_img = getAugumentedImage(img)\n",
    "            if checkAugumentedImage(aug_img):\n",
    "                if count%5 == 0:\n",
    "                    test_dataset.append(aug_img)\n",
    "                    test_dataset_label.append(label)\n",
    "                else:\n",
    "                    train_dataset.append(aug_img)\n",
    "                    train_dataset_label.append(label)\n",
    "                count+=1 \n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print(int(index/4+1),\") Label: \",label,\" Index: \",index,\" Count: \",count)\n",
    "    toc = end_timer()\n",
    "    show_time(tic,toc)\n",
    "    \n",
    "    train_dataset = np.array(train_dataset)\n",
    "    train_dataset_label = np.array([VARIETIES_CODE[label] for label in train_dataset_label])\n",
    "    test_dataset = np.array(test_dataset)\n",
    "    test_dataset_label = np.array([VARIETIES_CODE[label] for label in test_dataset_label])\n",
    "    \n",
    "    return train_dataset,train_dataset_label,test_dataset,test_dataset_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in VARIETIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7deebbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REMOVE_NOISY_BANDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22084\\1167643640.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mREMOVE_NOISY_BANDS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFIRST_BAND\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mLAST_BAND\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFIRST_BAND\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mLAST_BAND\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'REMOVE_NOISY_BANDS' is not defined"
     ]
    }
   ],
   "source": [
    "if REMOVE_NOISY_BANDS:\n",
    "    train_dataset = train_dataset[:,:,:,FIRST_BAND:LAST_BAND+1]\n",
    "    test_dataset = test_dataset[:,:,:,FIRST_BAND:LAST_BAND+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd9ea6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snv(input_data):\n",
    "    \"\"\"\n",
    "        :snv: A correction technique which is done on each\n",
    "        individual spectrum, a reference spectrum is not\n",
    "        required        :param input_data: Array of spectral data\n",
    "        :type input_data: DataFrame\n",
    "\n",
    "        :returns: data_snv (ndarray): Scatter corrected spectra\n",
    "    \"\"\"\n",
    "\n",
    "    input_data = np.asarray(input_data)\n",
    "\n",
    "    # Define a new array and populate it with the corrected data  \n",
    "    data_snv = np.zeros_like(input_data)\n",
    "    for i in range(data_snv.shape[0]):    # Apply correction\n",
    "        data_snv[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
    "    return (data_snv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49cac533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msc(input_data, reference=None):\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e493dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(input_data, reference=None):\n",
    "    if FILTER == \"snv\":\n",
    "        return snv(input_data)\n",
    "    elif FILTER == \"msc\":\n",
    "        return msc(input_data, reference)\n",
    "    else:\n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87f0f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = apply_filters(train_dataset)\n",
    "test_dataset = apply_filters(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4afcc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def lda(X_train,Y_train,X_test, numComponents = NUM_OF_BANDS):\n",
    "    \n",
    "    assert numComponents <= min(NUM_VARIETIES-1,X_train.shape[3]),\"NUM_OF_BANDS is greater.\"\n",
    "    \n",
    "    RX_train = np.reshape(X_train, (-1, X_train.shape[3]))\n",
    "    RX_test = np.reshape(X_test, (-1, X_test.shape[3]))\n",
    "    RY_train = []\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        for x in range(X_train.shape[1]*X_train.shape[2]):\n",
    "            RY_train.append(Y_train[i])\n",
    "    RY_train = np.array(RY_train)\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis(n_components=numComponents)\n",
    "    RX_train = lda.fit_transform(RX_train, RY_train)\n",
    "    RX_test = lda.transform(RX_test)\n",
    "    \n",
    "    X_train = np.reshape(RX_train, (-1,X_train.shape[1],X_train.shape[2], numComponents))\n",
    "    X_test = np.reshape(RX_test, (-1,X_test.shape[1],X_test.shape[2], numComponents))\n",
    "    \n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2650db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_loading(inp,numComponents = NUM_OF_BANDS):\n",
    "    t = inp.reshape(-1, inp.shape[2])\n",
    "    pca = PCA(n_components = numComponents)\n",
    "    dt = pca.fit_transform(t)\n",
    "    dt = dt.reshape(inp.shape[0],inp.shape[1],-1)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6d66676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#just for checking the number of bands to take into account. 99.97% is good enough to consider.\n",
    "def check_pca_bands(inp):\n",
    "    t = inp.reshape(-1, inp.shape[2])\n",
    "    pca = PCA(n_components = 75)\n",
    "    principalComponents = pca.fit_transform(t)\n",
    "    ev=pca.explained_variance_ratio_\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(np.cumsum(ev))\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Cumulative explained variance')\n",
    "    plt.show()\n",
    "    \n",
    "    return np.cumsum(ev)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0583d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensional Reduction Method\n",
    "def ipca(HSI, numComponents = NUM_OF_BANDS):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    n_batches = 10\n",
    "    inc_pca = IncrementalPCA(n_components=numComponents)\n",
    "    for X_batch in np.array_split(RHSI, n_batches):\n",
    "        inc_pca.partial_fit(X_batch)\n",
    "    X_ipca = inc_pca.transform(RHSI)\n",
    "    RHSI = np.reshape(X_ipca, (HSI.shape[0],HSI.shape[1], numComponents))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ffd8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(X_train,Y_train,X_test,Y_test,method=\"none\"):\n",
    "    if method==\"none\":\n",
    "        pass\n",
    "    elif method == \"pca_loading\":\n",
    "        X_train = np.array([pca_loading(inp) for inp in X_train])\n",
    "        X_test = np.array([pca_loading(inp) for inp in X_test])\n",
    "    elif method == \"lda\":\n",
    "        X_train,X_test = lda(X_train,Y_train,X_test)\n",
    "    elif method == \"ipca\":\n",
    "        X_train = np.array([ipca(inp) for inp in X_train])\n",
    "        X_test = np.array([ipca(inp) for inp in X_test])\n",
    "    \n",
    "    return X_train,Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20295b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train,X_test,Y_test = feature_extraction(train_dataset,train_dataset_label,test_dataset,test_dataset_label,FEATURE_EXTRACTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28a9b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join('./dataset')\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8dfbb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name():\n",
    "    return \"./dataset/V\"+str(NUM_VARIETIES).zfill(3)+\"_IC_\"+str(TOTAL_IMAGE_COUNT).zfill(5)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_FILTER_\"+str(FILTER)+\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d86b1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE_NAME = dataset_file_name()\n",
    "np.save(DATASET_FILE_NAME+\"_train_dataset.npy\",train_dataset)\n",
    "np.save(DATASET_FILE_NAME+\"_train_dataset_label.npy\",train_dataset_label)\n",
    "np.save(DATASET_FILE_NAME+\"_test_dataset.npy\",test_dataset)\n",
    "np.save(DATASET_FILE_NAME+\"_test_dataset_label.npy\",test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1d3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
