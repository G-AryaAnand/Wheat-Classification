{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb661222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python scikit-learn scikit-image matplotlib spectral keras_tuner vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b605089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "from math import inf as inf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/nitintyagi/wheat data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\mvl\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Constants\n",
    "TESTING = False\n",
    "\n",
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.90\n",
    "IMAGE_COUNT = int(200/4)\n",
    "NUM_VARIETIES = 4\n",
    "NUM_OF_BANDS = 20\n",
    "FIRST_BAND = 21\n",
    "LAST_BAND = 149\n",
    "\n",
    "IMAGE_WIDTH = 20\n",
    "IMAGE_HEIGHT = 20\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "ACTIVATION_TYPE =  [\"relu\", \"tanh\",\"sigmoid\"]\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "\n",
    "LEARNING_RATE_BASE = 0.0001\n",
    "MIN_LEARNING_RATE_BASE = LEARNING_RATE_BASE/10\n",
    "\n",
    "FACTOR = 3\n",
    "NUM_MODELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "479b1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_file_name():\n",
    "    return \"NumVar_\"+str(NUM_VARIETIES)+\"_ImageCount_\"+str(IMAGE_COUNT)+\"_Factor_\"+str(FACTOR)+\"_MinLR_\"+str(MIN_LEARNING_RATE_BASE)+\"_LR_\"+str(LEARNING_RATE_BASE)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_BatchSize_\"+str(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5e32422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactPathHDR(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil.hdr\"\n",
    "\n",
    "def exactPathBIL(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10991a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROI(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    threshold = threshold_otsu(img_band)\n",
    "    roi=[]\n",
    "    for x in range(img_band.shape[0]):\n",
    "        a=[]\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if img_band[x][y]>threshold:\n",
    "                a.append(1)\n",
    "            else:\n",
    "                a.append(0)\n",
    "        roi.append(a)\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f92ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns range for x and y from where we have to crop images\n",
    "def getRangeXandY(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    roi = getROI(img,band_number)\n",
    "    xmin = inf\n",
    "    xmax = 0\n",
    "    ymin = inf\n",
    "    ymax = 0\n",
    "    for x in range(img_band.shape[0]):\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if roi[x][y]==1:\n",
    "                if x<xmin:\n",
    "                    xmin=x\n",
    "                if x>xmax:\n",
    "                    xmax=x\n",
    "                if y<ymin:\n",
    "                    ymin=y\n",
    "                if y>ymax:\n",
    "                    ymax=y\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09705166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedImage(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    new_img = img[xmin:xmax, ymin:ymax, :]\n",
    "    return new_img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97d1f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedROI(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    roi = np.array(getROI(img,band_number))\n",
    "    roi = roi[xmin:xmax, ymin:ymax]\n",
    "    return roi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "318efc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsefulImage(img,band_number):\n",
    "    crop_img = getCroppedImage(img,band_number)\n",
    "    crop_roi = getCroppedROI(img,band_number)\n",
    "    for x in range(crop_img.shape[2]):\n",
    "        band = crop_img[:,:,x]\n",
    "        crop_img[:,:,x] = band*crop_roi\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad2376a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    layers.RandomRotation(factor=(-0.1, 0.1)),\n",
    "    layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1,0.1)),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=None)\n",
    "])\n",
    "\n",
    "def getAugumentedImage(img,band_number):\n",
    "    new_img = getUsefulImage(img,band_number)\n",
    "    augmented_image = data_augmentation(new_img) \n",
    "    return augmented_image\n",
    "\n",
    "def checkAugumentedImage(augmented_image):\n",
    "    aug_band = augmented_image[:,:,0]\n",
    "    filled_area_ratio = (np.count_nonzero(aug_band))/(aug_band.shape[0]*aug_band.shape[1])\n",
    "    if filled_area_ratio > FILLED_AREA_RATIO :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad47ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensional Reduction Method\n",
    "def DL_Method(HSI, numComponents = NUM_OF_BANDS):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    n_batches = 10\n",
    "    inc_pca = IncrementalPCA(n_components=numComponents)\n",
    "    for X_batch in np.array_split(RHSI, n_batches):\n",
    "        inc_pca.partial_fit(X_batch)\n",
    "    X_ipca = inc_pca.transform(RHSI)\n",
    "    RHSI = np.reshape(X_ipca, (HSI.shape[0],HSI.shape[1], numComponents))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20b64642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for all file names in varities\n",
    "FILES = []\n",
    "MAX_FILE_NUM = 4\n",
    "for x in range(1,MAX_FILE_NUM+1):\n",
    "    FILES.append(\"B_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a072b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all images\n",
    "images = []\n",
    "images_label = []\n",
    "for v in VARIETIES:\n",
    "    for f in FILES:\n",
    "        try:\n",
    "            img = envi.open(exactPathHDR(v,f),exactPathBIL(v,f))\n",
    "            images.append(img)\n",
    "            images_label.append(v)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2493d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "train_dataset_label = []\n",
    "test_dataset = []\n",
    "test_dataset_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c910c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Testing time (s) = 1547.94772679999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "for index, img in enumerate(images):\n",
    "    count = 0\n",
    "    label = images_label[index]\n",
    "    while count<IMAGE_COUNT:\n",
    "        aug_img = getAugumentedImage(img,BAND_NUMBER)\n",
    "        \n",
    "        if checkAugumentedImage(aug_img):\n",
    "            aug_img = DL_Method(aug_img[:,:,FIRST_BAND:LAST_BAND+1])\n",
    "            if count%5 == 0:\n",
    "                test_dataset.append(aug_img)\n",
    "                test_dataset_label.append(label)\n",
    "            else:\n",
    "                train_dataset.append(aug_img)\n",
    "                train_dataset_label.append(label)\n",
    "            count+=1  \n",
    "            \n",
    "    if TESTING:\n",
    "        break\n",
    "        \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb9af0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.array(train_dataset)\n",
    "train_dataset_label = np.array([VARIETIES_CODE[label] for label in train_dataset_label])\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array([VARIETIES_CODE[label] for label in test_dataset_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d65e88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for index,data in enumerate(test_dataset):\n",
    "#     imshow(data)\n",
    "    print(test_dataset_label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fc54f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for index,data in enumerate(train_dataset):\n",
    "#     imshow(data)\n",
    "    print(train_dataset_label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import math, sys, pdb, os\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from keras import activations\n",
    "import vis\n",
    "# from vis.visualization import visualize_saliency, overlay\n",
    "# from vis.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ce22266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hyperparam_string(learning_rate_base, batch_size, kernel_size, dropout_rate, num_training,\n",
    "                           num_nodes_fc, activation_type):\n",
    "    hparam = \"\"\n",
    "    hparam += str(num_nodes_fc) + \"nodes_\" + str(learning_rate_base) + \"lr_\" + str(batch_size) + \"batch_\" + str(\n",
    "        kernel_size) + \"kernel_\" + str(dropout_rate) + \"drop_\" + str(\n",
    "        num_training) + \"train_\" + activation_type\n",
    "\n",
    "    return hparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fd4a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.clim(0,sum(cm[0,:]))\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d67d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_K_classification_accuracy(y_predicted, y_true, K=1):\n",
    "\n",
    "    num_samples = y_predicted.shape[0]\n",
    "    num_classes = y_predicted.shape[1]\n",
    "\n",
    "    if K > num_classes:\n",
    "        sys.exit(1)\n",
    "\n",
    "    temp = np.zeros((num_samples,))\n",
    "\n",
    "    for idx in range(num_samples):\n",
    "        curr_predicted = np.argsort(y_predicted[idx,:])\n",
    "        curr_predicted = curr_predicted[::-1] # descending\n",
    "\n",
    "        if y_true[idx] in curr_predicted[:K]:\n",
    "            temp[idx] = 1\n",
    "\n",
    "    return 100.0 * np.sum(temp)/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "351725d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    x_orig = x\n",
    "\n",
    "    # Batch norm\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 1x1 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D, kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 3x3 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D, kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation       \n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 1x1 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D*4, kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Skip connection\n",
    "#     if int(x.shape[3]) != int(x_orig.shape[3]):\n",
    "#         x_orig = Conv2D(int(x.shape[3]), kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "#                kernel_initializer='truncated_normal')(x_orig)\n",
    "\n",
    "    # Activation      \n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "#     x = Add()([x, x_orig])\n",
    "\n",
    "    # Dropout\n",
    "    return Dropout(dropout_rate)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0731a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBlock_ResNet2D(x, num_layers, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    for idx_layer in range(num_layers):\n",
    "        x = conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45bd16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth_rate: number of filters for each normal convolution ('k' in the paper)\n",
    "def ResNet2D_classifier(data_num_rows, data_num_cols, num_classes, kernel_size=3, num_layers_each_block=[6, 12, 24, 16],\n",
    "                        num_chan_per_block = [64,128,256,512], activation_type=['relu'], dropout_rate=0.0, num_input_chans=1, num_nodes_fc=64):\n",
    "\n",
    "    input_data = Input(shape=(data_num_rows, data_num_cols, num_input_chans))\n",
    "\n",
    "    # Input layer: Conv2D -> activation\n",
    "    x = Conv2D(num_chan_per_block[0], kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(input_data)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "\n",
    "    #  Blocks & Downsampling Layers\n",
    "    for idx_block in range(len(num_layers_each_block)):\n",
    "        x = createBlock_ResNet2D(x, num_layers_each_block[idx_block], kernel_size, activation_type, dropout_rate,\n",
    "                                 num_chan_per_block[idx_block])\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if idx_block != len(num_layers_each_block)-1:\n",
    "            x = Conv2D(num_chan_per_block[idx_block]*2, kernel_size, strides = 2, activation=None, use_bias=True, padding='valid',\n",
    "                   kernel_initializer='truncated_normal')(x)\n",
    "        else:\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(units=num_nodes_fc, activation=None, kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    output_data = Dense(units=num_classes, activation='softmax', kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    return Model(inputs=input_data, outputs=output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f40895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataset,dataset_label,normalization_type):\n",
    "    print(\"--------------Make Predictions--------------\")    \n",
    "    x = np.array(dataset)\n",
    "    labels = np.array(dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x = normalizeDataWholeSeed(x,normalization_type=normalization_type)\n",
    "    \n",
    "    num = x.shape[0]\n",
    "\n",
    "    tic = start_timer()\n",
    "    labels_predicted = model.predict(x)\n",
    "    toc = end_timer()\n",
    "    show_time(tic,toc)\n",
    "    \n",
    "    print(labels_predicted)\n",
    "    print(\"--------\")\n",
    "    # Classification accuracy\n",
    "    labels_integer_format = labels\n",
    "    labels_predicted_integer_format = np.argmax(labels_predicted, axis=1)\n",
    "\n",
    "    acc_top2 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=2)\n",
    "    acc_top1 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=1)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "    print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e4c541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,normalization_type):\n",
    "    evaluate(model,train_dataset,train_dataset_label,normalization_type)\n",
    "    \n",
    "    evaluate(model,test_dataset,test_dataset_label,normalization_type)\n",
    "    \n",
    "    \n",
    "    # Precision, Recall, F1\n",
    "#     macro_avg = np.asarray(\n",
    "#         precision_recall_fscore_support(labels_test_integer_format, labels_predicted_test_integer_format,\n",
    "#                                         average='macro'))\n",
    "#     macro_avg_precision = macro_avg[0]\n",
    "#     macro_avg_recall = macro_avg[1]\n",
    "#     macro_avg_fscore = macro_avg[2]\n",
    "\n",
    "#     print('Top-1 accuracy (%) = ' + str(acc_top1) + '\\n')\n",
    "#     print('Top-2 accuracy (%) = ' + str(acc_top2) + '\\n')\n",
    "#     print('Macro-avg precision = ' + str(macro_avg_precision) + '\\n')\n",
    "#     print('Macro-avg recall = ' + str(macro_avg_recall) + '\\n')\n",
    "#     print('Macro-avg f-score = ' + str(macro_avg_fscore) + '\\n')\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Compute Saliency Maps--------------\")\n",
    "#     results_test_dir = os.path.join(results_dir, 'test')\n",
    "#     if not os.path.exists(results_test_dir):\n",
    "#         os.makedirs(results_test_dir)\n",
    "\n",
    "#     # Swap softmax with linear\n",
    "#     model.layers[-1].activation = activations.linear\n",
    "#     model = utils.apply_modifications(model)\n",
    "\n",
    "#     for idx_wheat in range(num_test):\n",
    "\n",
    "#         grads = visualize_saliency(model, layer_idx=-1, filter_indices=np.argmax(labels_test[idx_wheat, :], axis=0),\n",
    "#                                    seed_input=x_test[idx_wheat], backprop_modifier=None)\n",
    "\n",
    "#         ss_img = np.sqrt(np.sum(abs(x_test[idx_wheat, :, :, :]) ** 2, axis=2))\n",
    "#         ss_img /= np.max(ss_img)\n",
    "\n",
    "#         plt.figure(1)\n",
    "#         plt.subplot(3, 1, 1)\n",
    "#         plt.imshow(ss_img, cmap='gray')\n",
    "#         plt.clim(0, 1)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         plt.subplot(3, 1, 2)\n",
    "#         plt.imshow((grads * np.uint8(255)).astype('uint8'), cmap='jet')\n",
    "#         plt.clim(0, 255)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * np.uint8(255))\n",
    "\n",
    "#         plt.subplot(3, 1, 3)\n",
    "#         ss_img = cv2.cvtColor((ss_img * np.uint8(255)).astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "#         plt.imshow(overlay(jet_heatmap, ss_img, alpha=0.3))\n",
    "#         plt.clim(0, 255)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         plt.savefig(os.path.join(results_test_dir, str(idx_wheat+1) + '.png'))\n",
    "#         plt.clf()\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Save the information--------------\")\n",
    "\n",
    "#     # Write some information to files\n",
    "#     f = open(os.path.join(results_test_dir, 'testing_info.txt'), 'w')\n",
    "#     f.write(\"Wheat types = \" + str(wheat_types) + \"\\n\")\n",
    "#     f.write(\"Confusion matrix \\n\")\n",
    "#     f.write(str(confusion_matrix_results) + \"\\n\")\n",
    "#     f.write(\"Normalization type = \" + str(normalization_type) + \"\\n\")\n",
    "#     f.write(\"# test samples = %d \\n\" % (num_test))\n",
    "#     f.write(\"Top-1 test accuracy = %f \\n\" % (acc_top1))\n",
    "#     f.write(\"Top-2 test accuracy = %f \\n\" % (acc_top2))\n",
    "#     f.write(\"Macro-avg precision = %f \\n\" % (macro_avg_precision))\n",
    "#     f.write(\"Macro-avg recall = %f \\n\" % (macro_avg_recall))\n",
    "#     f.write(\"Macro-avg f-score = %f \\n\" % (macro_avg_fscore))\n",
    "#     f.write(\"Test time (s) = \" + str(test_time) + \"\\n\")\n",
    "#     f.close()\n",
    "\n",
    "#     # Save confusion matrices\n",
    "#     plt.figure(1)\n",
    "#     plot_confusion_matrix(confusion_matrix_results, classes=wheat_types, normalize=False, title='Confusion matrix')\n",
    "#     plt.savefig(os.path.join(results_test_dir,'confusionMatrix.png'))\n",
    "#     plt.clf()\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Save the information for the training phase--------------\")\n",
    "    \n",
    "#     import pandas as pd\n",
    "    \n",
    "#     # Save the trained model\n",
    "#     model.save_weights(os.path.join(results_dir, 'trainedResNetB_weights.h5'))\n",
    "    \n",
    "#     # Extract the training loss   \n",
    "#     training_loss = hist.history['loss']\n",
    "\n",
    "#     # Save the training loss\n",
    "#     df = pd.DataFrame(data={'training loss': training_loss},index=np.arange(num_epochs)+1)\n",
    "#     df.to_csv(os.path.join(results_dir,'training_loss.csv'))\n",
    "    \n",
    "#     # Save the training loss as a figure\n",
    "#     plt.figure(1)\n",
    "#     plt.title('Loss')\n",
    "#     plt.plot(training_loss, color='b',label='Training')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.savefig(os.path.join(results_dir,'training_loss.png'))\n",
    "#     plt.clf()   \n",
    "    \n",
    "#     # Write a file with general information\n",
    "#     f = open(os.path.join(results_dir,'training_info.txt'),'w')\n",
    "#     f.write(hparams + '\\n')\n",
    "#     f.write('Wheat types = ' + str(wheat_types)+'\\n')\n",
    "#     f.write('Training time (s) = %f \\n' %(training_time))\n",
    "#     f.write('Normalization type = ' + str(normalization_type)+ '\\n')\n",
    "#     f.write('# epochs = ' + str(num_epochs) + '\\n')\n",
    "#     f.write('# training samples = %d \\n' %(num_training))\n",
    "#     f.close()\n",
    "    \n",
    "#     print(\"--------------Done--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6797662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndTrainResNetB():\n",
    "    \n",
    "    learning_rate_base = LEARNING_RATE_BASE\n",
    "    kernel_size = 3\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    batch_size = BATCH_SIZE\n",
    "    dropout_rate = 0.15 \n",
    "    activation_type = 'relu'\n",
    "    num_nodes_fc = 256\n",
    "    wheat_types =  VARIETIES\n",
    "    normalization_type = 'max'\n",
    "    num_layers_each_block = [1, 0, 0, 0]\n",
    "    num_chan_per_block = [128, 128, 256, 256]\n",
    "    N_classes = len(wheat_types)\n",
    "    \n",
    "    ############ Load data ############\n",
    "    print(\"--------------Load Data--------------\")\n",
    "\n",
    "    # Load training data and their corresponding labels\n",
    "    x_training = np.array(train_dataset)\n",
    "    labels_training = np.array(train_dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_training = normalizeDataWholeSeed(x_training,normalization_type=normalization_type)\n",
    "    \n",
    "    # Extract some information\n",
    "    num_training = x_training.shape[0]\n",
    "    N_spatial = x_training.shape[1:3]\n",
    "    N_bands = x_training.shape[3]\n",
    "    \n",
    "    print('#training = %d' %(num_training))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "    \n",
    "    \n",
    "    ############ Prepare the path for saving the models/stats ############\n",
    "#     print(\"--------------Prepare a path for saving the models/stats--------------\")\n",
    "    \n",
    "#     hparams = make_hyperparam_string(learning_rate_base, batch_size, kernel_size, dropout_rate,\n",
    "#                                      num_training, num_nodes_fc, activation_type)\n",
    "#     print('Saving the model to...')\n",
    "    \n",
    "#     results_dir = os.path.join('./results/',hparams)\n",
    "    \n",
    "#     if not os.path.exists(results_dir):\n",
    "#         os.makedirs(results_dir)\n",
    "#     print(results_dir)\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Create a model ############\n",
    "    print(\"--------------Create a model--------------\")\n",
    "    \n",
    "    # Generate a model\n",
    "    model = ResNet2D_classifier(data_num_rows=N_spatial[0], data_num_cols=N_spatial[1], num_classes=N_classes,\n",
    "                                kernel_size=kernel_size, num_layers_each_block=num_layers_each_block,\n",
    "                                num_chan_per_block=num_chan_per_block, activation_type=activation_type,\n",
    "                                dropout_rate=dropout_rate, num_input_chans=N_bands, num_nodes_fc=num_nodes_fc)\n",
    "\n",
    "    # Compile the model\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "\n",
    "    # Create a Tensorboard callback\n",
    "#     tbCallBack = TensorBoard(log_dir=results_dir, histogram_freq=0, write_graph=False, write_images=False)\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Train the model ############\n",
    "    print(\"--------------Begin training the model--------------\")\n",
    "\n",
    "#     tic = timeit.default_timer()\n",
    "    \n",
    "    # Train the model\n",
    "#     hist = model.fit(x=x_training,y=labels_training,batch_size=batch_size,  epochs = num_epochs, initial_epoch = 0, verbose=2, callbacks = [tbCallBack],validation_split=0.15,shuffle=True)\n",
    "\n",
    "#     toc = timeit.default_timer()\n",
    "#     training_time = toc-tic\n",
    "#     print(\"Total training time = \" + str(training_time))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72a8706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "#training = 640\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n",
      "--------------Done--------------\n",
      "--------------Begin training the model--------------\n",
      "--------------Done--------------\n"
     ]
    }
   ],
   "source": [
    "model = createAndTrainResNetB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e61e02cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Epoch 1/20\n",
      "48/48 - 13s - loss: 1.5024 - accuracy: 0.2839 - val_loss: 1.4151 - val_accuracy: 0.0000e+00 - 13s/epoch - 270ms/step\n",
      "Epoch 2/20\n",
      "48/48 - 11s - loss: 1.2626 - accuracy: 0.4323 - val_loss: 1.3439 - val_accuracy: 0.0156 - 11s/epoch - 222ms/step\n",
      "Epoch 3/20\n",
      "48/48 - 11s - loss: 1.2117 - accuracy: 0.4661 - val_loss: 1.3251 - val_accuracy: 0.0547 - 11s/epoch - 227ms/step\n",
      "Epoch 4/20\n",
      "48/48 - 11s - loss: 1.1247 - accuracy: 0.5156 - val_loss: 1.3453 - val_accuracy: 0.0430 - 11s/epoch - 235ms/step\n",
      "Epoch 5/20\n",
      "48/48 - 11s - loss: 1.0098 - accuracy: 0.6198 - val_loss: 1.3382 - val_accuracy: 0.0781 - 11s/epoch - 235ms/step\n",
      "Epoch 6/20\n",
      "48/48 - 11s - loss: 0.9302 - accuracy: 0.6745 - val_loss: 1.3593 - val_accuracy: 0.0938 - 11s/epoch - 235ms/step\n",
      "Epoch 7/20\n",
      "48/48 - 12s - loss: 0.9067 - accuracy: 0.6849 - val_loss: 1.3972 - val_accuracy: 0.0977 - 12s/epoch - 243ms/step\n",
      "Epoch 8/20\n",
      "48/48 - 12s - loss: 0.9118 - accuracy: 0.6641 - val_loss: 1.4084 - val_accuracy: 0.1367 - 12s/epoch - 242ms/step\n",
      "Epoch 9/20\n",
      "48/48 - 11s - loss: 0.8695 - accuracy: 0.7057 - val_loss: 1.4215 - val_accuracy: 0.1797 - 11s/epoch - 234ms/step\n",
      "Epoch 10/20\n",
      "48/48 - 12s - loss: 0.7933 - accuracy: 0.7396 - val_loss: 1.4461 - val_accuracy: 0.1719 - 12s/epoch - 240ms/step\n",
      "Epoch 11/20\n",
      "48/48 - 11s - loss: 0.7800 - accuracy: 0.7604 - val_loss: 1.4771 - val_accuracy: 0.1758 - 11s/epoch - 235ms/step\n",
      "Epoch 12/20\n",
      "48/48 - 11s - loss: 0.7606 - accuracy: 0.7630 - val_loss: 1.4883 - val_accuracy: 0.1914 - 11s/epoch - 234ms/step\n",
      "Epoch 13/20\n",
      "48/48 - 11s - loss: 0.6842 - accuracy: 0.8307 - val_loss: 1.4957 - val_accuracy: 0.2070 - 11s/epoch - 234ms/step\n",
      "Epoch 14/20\n",
      "48/48 - 11s - loss: 0.7110 - accuracy: 0.8099 - val_loss: 1.5111 - val_accuracy: 0.1914 - 11s/epoch - 234ms/step\n",
      "Epoch 15/20\n",
      "48/48 - 11s - loss: 0.6957 - accuracy: 0.7917 - val_loss: 1.5198 - val_accuracy: 0.1797 - 11s/epoch - 234ms/step\n",
      "Epoch 16/20\n",
      "48/48 - 11s - loss: 0.6405 - accuracy: 0.8229 - val_loss: 1.5223 - val_accuracy: 0.1797 - 11s/epoch - 235ms/step\n",
      "Epoch 17/20\n",
      "48/48 - 11s - loss: 0.6255 - accuracy: 0.8464 - val_loss: 1.5346 - val_accuracy: 0.1836 - 11s/epoch - 235ms/step\n",
      "Epoch 18/20\n",
      "48/48 - 11s - loss: 0.6173 - accuracy: 0.8411 - val_loss: 1.5495 - val_accuracy: 0.1797 - 11s/epoch - 234ms/step\n",
      "Epoch 19/20\n",
      "48/48 - 11s - loss: 0.5790 - accuracy: 0.8542 - val_loss: 1.5612 - val_accuracy: 0.1719 - 11s/epoch - 235ms/step\n",
      "Epoch 20/20\n",
      "48/48 - 11s - loss: 0.5885 - accuracy: 0.8724 - val_loss: 1.5767 - val_accuracy: 0.1719 - 11s/epoch - 237ms/step\n",
      "Testing time (s) = 227.4702276000171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "model.fit(x=train_dataset,y=train_dataset_label,batch_size=BATCH_SIZE, epochs=20, initial_epoch = 0, verbose=2,validation_split=0.40,shuffle=True)\n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9faf1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 140ms/step - loss: 1.4963 - accuracy: 0.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.496333360671997, 0.3125]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset,test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eea3d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 141ms/step - loss: 0.8659 - accuracy: 0.6625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8658636808395386, 0.6625000238418579]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_dataset,train_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b161d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "#training = 640\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n",
      "--------------Done--------------\n",
      "--------------Begin training the model--------------\n",
      "--------------Done--------------\n"
     ]
    }
   ],
   "source": [
    "model = createAndTrainResNetB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fc49294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Epoch 1/40\n",
      "48/48 - 13s - loss: 1.5571 - accuracy: 0.2578 - val_loss: 1.3996 - val_accuracy: 0.4609 - 13s/epoch - 273ms/step\n",
      "Epoch 2/40\n",
      "48/48 - 11s - loss: 1.2975 - accuracy: 0.4036 - val_loss: 1.4221 - val_accuracy: 0.0508 - 11s/epoch - 237ms/step\n",
      "Epoch 3/40\n",
      "48/48 - 11s - loss: 1.1985 - accuracy: 0.4870 - val_loss: 1.4567 - val_accuracy: 0.0117 - 11s/epoch - 237ms/step\n",
      "Epoch 4/40\n",
      "48/48 - 11s - loss: 1.0985 - accuracy: 0.5469 - val_loss: 1.4762 - val_accuracy: 0.0078 - 11s/epoch - 236ms/step\n",
      "Epoch 5/40\n",
      "48/48 - 11s - loss: 1.0326 - accuracy: 0.6094 - val_loss: 1.5060 - val_accuracy: 0.0000e+00 - 11s/epoch - 236ms/step\n",
      "Epoch 6/40\n",
      "48/48 - 11s - loss: 0.9560 - accuracy: 0.6615 - val_loss: 1.5311 - val_accuracy: 0.0039 - 11s/epoch - 237ms/step\n",
      "Epoch 7/40\n",
      "48/48 - 11s - loss: 0.9295 - accuracy: 0.6849 - val_loss: 1.5605 - val_accuracy: 0.0078 - 11s/epoch - 235ms/step\n",
      "Epoch 8/40\n",
      "48/48 - 11s - loss: 0.8848 - accuracy: 0.7005 - val_loss: 1.5756 - val_accuracy: 0.0117 - 11s/epoch - 237ms/step\n",
      "Epoch 9/40\n",
      "48/48 - 11s - loss: 0.8676 - accuracy: 0.7240 - val_loss: 1.5807 - val_accuracy: 0.0586 - 11s/epoch - 237ms/step\n",
      "Epoch 10/40\n",
      "48/48 - 11s - loss: 0.7706 - accuracy: 0.7734 - val_loss: 1.5912 - val_accuracy: 0.0820 - 11s/epoch - 238ms/step\n",
      "Epoch 11/40\n",
      "48/48 - 11s - loss: 0.7478 - accuracy: 0.7604 - val_loss: 1.6100 - val_accuracy: 0.1133 - 11s/epoch - 237ms/step\n",
      "Epoch 12/40\n",
      "48/48 - 11s - loss: 0.7439 - accuracy: 0.7786 - val_loss: 1.6032 - val_accuracy: 0.1367 - 11s/epoch - 236ms/step\n",
      "Epoch 13/40\n",
      "48/48 - 12s - loss: 0.6939 - accuracy: 0.8125 - val_loss: 1.6182 - val_accuracy: 0.1406 - 12s/epoch - 244ms/step\n",
      "Epoch 14/40\n",
      "48/48 - 11s - loss: 0.6994 - accuracy: 0.8125 - val_loss: 1.6439 - val_accuracy: 0.1406 - 11s/epoch - 237ms/step\n",
      "Epoch 15/40\n",
      "48/48 - 11s - loss: 0.6895 - accuracy: 0.8099 - val_loss: 1.6535 - val_accuracy: 0.1406 - 11s/epoch - 237ms/step\n",
      "Epoch 16/40\n",
      "48/48 - 11s - loss: 0.6966 - accuracy: 0.8099 - val_loss: 1.6741 - val_accuracy: 0.1328 - 11s/epoch - 237ms/step\n",
      "Epoch 17/40\n",
      "48/48 - 11s - loss: 0.6760 - accuracy: 0.8021 - val_loss: 1.6835 - val_accuracy: 0.1328 - 11s/epoch - 235ms/step\n",
      "Epoch 18/40\n",
      "48/48 - 11s - loss: 0.6671 - accuracy: 0.8203 - val_loss: 1.6993 - val_accuracy: 0.1367 - 11s/epoch - 236ms/step\n",
      "Epoch 19/40\n",
      "48/48 - 11s - loss: 0.6038 - accuracy: 0.8385 - val_loss: 1.6895 - val_accuracy: 0.1445 - 11s/epoch - 237ms/step\n",
      "Epoch 20/40\n",
      "48/48 - 11s - loss: 0.5871 - accuracy: 0.8359 - val_loss: 1.7042 - val_accuracy: 0.1328 - 11s/epoch - 236ms/step\n",
      "Epoch 21/40\n",
      "48/48 - 11s - loss: 0.5789 - accuracy: 0.8594 - val_loss: 1.7128 - val_accuracy: 0.1328 - 11s/epoch - 238ms/step\n",
      "Epoch 22/40\n",
      "48/48 - 11s - loss: 0.5523 - accuracy: 0.8672 - val_loss: 1.7236 - val_accuracy: 0.1367 - 11s/epoch - 237ms/step\n",
      "Epoch 23/40\n",
      "48/48 - 11s - loss: 0.5456 - accuracy: 0.8750 - val_loss: 1.7257 - val_accuracy: 0.1445 - 11s/epoch - 237ms/step\n",
      "Epoch 24/40\n",
      "48/48 - 11s - loss: 0.5352 - accuracy: 0.8620 - val_loss: 1.7517 - val_accuracy: 0.1406 - 11s/epoch - 236ms/step\n",
      "Epoch 25/40\n",
      "48/48 - 11s - loss: 0.5613 - accuracy: 0.8698 - val_loss: 1.7476 - val_accuracy: 0.1367 - 11s/epoch - 236ms/step\n",
      "Epoch 26/40\n",
      "48/48 - 11s - loss: 0.5249 - accuracy: 0.8724 - val_loss: 1.7538 - val_accuracy: 0.1250 - 11s/epoch - 237ms/step\n",
      "Epoch 27/40\n",
      "48/48 - 11s - loss: 0.5307 - accuracy: 0.8672 - val_loss: 1.7633 - val_accuracy: 0.1289 - 11s/epoch - 236ms/step\n",
      "Epoch 28/40\n",
      "48/48 - 11s - loss: 0.5331 - accuracy: 0.8776 - val_loss: 1.7789 - val_accuracy: 0.1094 - 11s/epoch - 236ms/step\n",
      "Epoch 29/40\n",
      "48/48 - 11s - loss: 0.5071 - accuracy: 0.8906 - val_loss: 1.7742 - val_accuracy: 0.1211 - 11s/epoch - 236ms/step\n",
      "Epoch 30/40\n",
      "48/48 - 11s - loss: 0.5047 - accuracy: 0.8776 - val_loss: 1.7684 - val_accuracy: 0.1328 - 11s/epoch - 236ms/step\n",
      "Epoch 31/40\n",
      "48/48 - 11s - loss: 0.5085 - accuracy: 0.8828 - val_loss: 1.7689 - val_accuracy: 0.1328 - 11s/epoch - 238ms/step\n",
      "Epoch 32/40\n",
      "48/48 - 11s - loss: 0.4967 - accuracy: 0.8828 - val_loss: 1.7851 - val_accuracy: 0.1250 - 11s/epoch - 239ms/step\n",
      "Epoch 33/40\n",
      "48/48 - 11s - loss: 0.4710 - accuracy: 0.8958 - val_loss: 1.7864 - val_accuracy: 0.1211 - 11s/epoch - 235ms/step\n",
      "Epoch 34/40\n",
      "48/48 - 11s - loss: 0.4464 - accuracy: 0.9010 - val_loss: 1.8032 - val_accuracy: 0.1172 - 11s/epoch - 236ms/step\n",
      "Epoch 35/40\n",
      "48/48 - 11s - loss: 0.4261 - accuracy: 0.9089 - val_loss: 1.8062 - val_accuracy: 0.1211 - 11s/epoch - 236ms/step\n",
      "Epoch 36/40\n",
      "48/48 - 11s - loss: 0.4542 - accuracy: 0.9062 - val_loss: 1.8220 - val_accuracy: 0.1211 - 11s/epoch - 237ms/step\n",
      "Epoch 37/40\n",
      "48/48 - 11s - loss: 0.4336 - accuracy: 0.9089 - val_loss: 1.8268 - val_accuracy: 0.1211 - 11s/epoch - 236ms/step\n",
      "Epoch 38/40\n",
      "48/48 - 11s - loss: 0.4812 - accuracy: 0.8802 - val_loss: 1.8443 - val_accuracy: 0.1016 - 11s/epoch - 236ms/step\n",
      "Epoch 39/40\n",
      "48/48 - 12s - loss: 0.4218 - accuracy: 0.9167 - val_loss: 1.8425 - val_accuracy: 0.1055 - 12s/epoch - 248ms/step\n",
      "Epoch 40/40\n",
      "48/48 - 12s - loss: 0.4324 - accuracy: 0.9010 - val_loss: 1.8461 - val_accuracy: 0.1094 - 12s/epoch - 244ms/step\n",
      "Testing time (s) = 457.53009769995697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "model.fit(x=train_dataset,y=train_dataset_label,batch_size=BATCH_SIZE, epochs=40, initial_epoch = 0, verbose=2,validation_split=0.40,shuffle=True)\n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1080cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 141ms/step - loss: 1.5441 - accuracy: 0.3187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.544090986251831, 0.3187499940395355]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset,test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d2e2785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 144ms/step - loss: 0.8465 - accuracy: 0.6438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8465191721916199, 0.643750011920929]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_dataset,train_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "beb7c306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf3e0bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20, 20, 20)]      0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 20, 20, 128)       23168     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 20, 20, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 20, 20, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 20, 20, 128)       16384     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 20, 20, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 20, 20, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 20, 20, 128)       147584    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 20, 20, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 20, 20, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 20, 20, 512)       65536     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 20, 20, 512)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 20, 20, 512)       0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 20, 20, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 9, 9, 256)         1179904   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 9, 9, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 9, 9, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 4, 4, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 1, 512)         1180160   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1, 1, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,345,924\n",
      "Trainable params: 3,340,548\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59d76079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndTrainResNetB1():\n",
    "    \n",
    "    learning_rate_base = LEARNING_RATE_BASE\n",
    "    kernel_size = 3\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    batch_size = BATCH_SIZE\n",
    "    dropout_rate = 0.15 \n",
    "    activation_type = 'relu'\n",
    "    num_nodes_fc = 64\n",
    "    wheat_types =  VARIETIES\n",
    "    normalization_type = 'max'\n",
    "    num_layers_each_block = [1, 0, 0, 0]\n",
    "    num_chan_per_block = [32, 128, 256, 256]\n",
    "    N_classes = len(wheat_types)\n",
    "    \n",
    "    ############ Load data ############\n",
    "    print(\"--------------Load Data--------------\")\n",
    "\n",
    "    # Load training data and their corresponding labels\n",
    "    x_training = np.array(train_dataset)\n",
    "    labels_training = np.array(train_dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_training = normalizeDataWholeSeed(x_training,normalization_type=normalization_type)\n",
    "    \n",
    "    # Extract some information\n",
    "    num_training = x_training.shape[0]\n",
    "    N_spatial = x_training.shape[1:3]\n",
    "    N_bands = x_training.shape[3]\n",
    "    \n",
    "    print('#training = %d' %(num_training))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "    \n",
    "    \n",
    "    ############ Prepare the path for saving the models/stats ############\n",
    "#     print(\"--------------Prepare a path for saving the models/stats--------------\")\n",
    "    \n",
    "#     hparams = make_hyperparam_string(learning_rate_base, batch_size, kernel_size, dropout_rate,\n",
    "#                                      num_training, num_nodes_fc, activation_type)\n",
    "#     print('Saving the model to...')\n",
    "    \n",
    "#     results_dir = os.path.join('./results/',hparams)\n",
    "    \n",
    "#     if not os.path.exists(results_dir):\n",
    "#         os.makedirs(results_dir)\n",
    "#     print(results_dir)\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Create a model ############\n",
    "    print(\"--------------Create a model--------------\")\n",
    "    \n",
    "    # Generate a model\n",
    "    model = ResNet2D_classifier(data_num_rows=N_spatial[0], data_num_cols=N_spatial[1], num_classes=N_classes,\n",
    "                                kernel_size=kernel_size, num_layers_each_block=num_layers_each_block,\n",
    "                                num_chan_per_block=num_chan_per_block, activation_type=activation_type,\n",
    "                                dropout_rate=dropout_rate, num_input_chans=N_bands, num_nodes_fc=num_nodes_fc)\n",
    "\n",
    "    # Compile the model\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "\n",
    "    # Create a Tensorboard callback\n",
    "#     tbCallBack = TensorBoard(log_dir=results_dir, histogram_freq=0, write_graph=False, write_images=False)\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Train the model ############\n",
    "    print(\"--------------Begin training the model--------------\")\n",
    "\n",
    "#     tic = timeit.default_timer()\n",
    "    \n",
    "    # Train the model\n",
    "#     hist = model.fit(x=x_training,y=labels_training,batch_size=batch_size,  epochs = num_epochs, initial_epoch = 0, verbose=2, callbacks = [tbCallBack],validation_split=0.15,shuffle=True)\n",
    "\n",
    "#     toc = timeit.default_timer()\n",
    "#     training_time = toc-tic\n",
    "#     print(\"Total training time = \" + str(training_time))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bcba3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "#training = 640\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n",
      "--------------Done--------------\n",
      "--------------Begin training the model--------------\n",
      "--------------Done--------------\n"
     ]
    }
   ],
   "source": [
    "model1 = createAndTrainResNetB1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27123e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Epoch 1/20\n",
      "48/48 - 5s - loss: 1.2590 - accuracy: 0.4557 - val_loss: 1.4654 - val_accuracy: 0.0703 - 5s/epoch - 102ms/step\n",
      "Epoch 2/20\n",
      "48/48 - 5s - loss: 1.2556 - accuracy: 0.4714 - val_loss: 1.4692 - val_accuracy: 0.0508 - 5s/epoch - 102ms/step\n",
      "Epoch 3/20\n",
      "48/48 - 5s - loss: 1.2270 - accuracy: 0.5182 - val_loss: 1.4764 - val_accuracy: 0.0742 - 5s/epoch - 103ms/step\n",
      "Epoch 4/20\n",
      "48/48 - 5s - loss: 1.1877 - accuracy: 0.5443 - val_loss: 1.4760 - val_accuracy: 0.0898 - 5s/epoch - 102ms/step\n",
      "Epoch 5/20\n",
      "48/48 - 5s - loss: 1.1800 - accuracy: 0.5703 - val_loss: 1.4830 - val_accuracy: 0.0664 - 5s/epoch - 100ms/step\n",
      "Epoch 6/20\n",
      "48/48 - 5s - loss: 1.1706 - accuracy: 0.5573 - val_loss: 1.4885 - val_accuracy: 0.0898 - 5s/epoch - 102ms/step\n",
      "Epoch 7/20\n",
      "48/48 - 5s - loss: 1.1487 - accuracy: 0.5911 - val_loss: 1.4938 - val_accuracy: 0.0977 - 5s/epoch - 107ms/step\n",
      "Epoch 8/20\n",
      "48/48 - 5s - loss: 1.1483 - accuracy: 0.5964 - val_loss: 1.4997 - val_accuracy: 0.1016 - 5s/epoch - 106ms/step\n",
      "Epoch 9/20\n",
      "48/48 - 5s - loss: 1.1254 - accuracy: 0.5703 - val_loss: 1.5052 - val_accuracy: 0.1055 - 5s/epoch - 107ms/step\n",
      "Epoch 10/20\n",
      "48/48 - 5s - loss: 1.1006 - accuracy: 0.6276 - val_loss: 1.5077 - val_accuracy: 0.1133 - 5s/epoch - 106ms/step\n",
      "Epoch 11/20\n",
      "48/48 - 5s - loss: 1.1072 - accuracy: 0.6146 - val_loss: 1.5094 - val_accuracy: 0.1289 - 5s/epoch - 106ms/step\n",
      "Epoch 12/20\n",
      "48/48 - 5s - loss: 1.0661 - accuracy: 0.6849 - val_loss: 1.5106 - val_accuracy: 0.1172 - 5s/epoch - 106ms/step\n",
      "Epoch 13/20\n",
      "48/48 - 5s - loss: 1.0833 - accuracy: 0.6120 - val_loss: 1.5101 - val_accuracy: 0.1211 - 5s/epoch - 104ms/step\n",
      "Epoch 14/20\n",
      "48/48 - 5s - loss: 1.0861 - accuracy: 0.6380 - val_loss: 1.5139 - val_accuracy: 0.1211 - 5s/epoch - 106ms/step\n",
      "Epoch 15/20\n",
      "48/48 - 5s - loss: 1.0889 - accuracy: 0.6380 - val_loss: 1.5182 - val_accuracy: 0.1133 - 5s/epoch - 106ms/step\n",
      "Epoch 16/20\n",
      "48/48 - 5s - loss: 1.0469 - accuracy: 0.6875 - val_loss: 1.5235 - val_accuracy: 0.1133 - 5s/epoch - 107ms/step\n",
      "Epoch 17/20\n",
      "48/48 - 5s - loss: 1.0418 - accuracy: 0.6823 - val_loss: 1.5288 - val_accuracy: 0.1211 - 5s/epoch - 98ms/step\n",
      "Epoch 18/20\n",
      "48/48 - 5s - loss: 1.0671 - accuracy: 0.6380 - val_loss: 1.5294 - val_accuracy: 0.1133 - 5s/epoch - 98ms/step\n",
      "Epoch 19/20\n",
      "48/48 - 5s - loss: 1.0588 - accuracy: 0.6641 - val_loss: 1.5314 - val_accuracy: 0.1094 - 5s/epoch - 106ms/step\n",
      "Epoch 20/20\n",
      "48/48 - 5s - loss: 1.0065 - accuracy: 0.7135 - val_loss: 1.5330 - val_accuracy: 0.1094 - 5s/epoch - 100ms/step\n",
      "Testing time (s) = 99.67554319999181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "model1.fit(x=train_dataset,y=train_dataset_label,batch_size=BATCH_SIZE, epochs=20, initial_epoch = 0, verbose=2,validation_split=0.40,shuffle=True)\n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e179a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 223ms/step - loss: 1.5441 - accuracy: 0.3187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.544090986251831, 0.3187499940395355]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset,test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a99b57b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Epoch 1/20\n",
      "48/48 - 5s - loss: 1.0177 - accuracy: 0.6953 - val_loss: 1.5328 - val_accuracy: 0.1055 - 5s/epoch - 108ms/step\n",
      "Epoch 2/20\n",
      "48/48 - 5s - loss: 1.0029 - accuracy: 0.7135 - val_loss: 1.5355 - val_accuracy: 0.1055 - 5s/epoch - 106ms/step\n",
      "Epoch 3/20\n",
      "48/48 - 5s - loss: 1.0018 - accuracy: 0.7161 - val_loss: 1.5381 - val_accuracy: 0.1016 - 5s/epoch - 107ms/step\n",
      "Epoch 4/20\n",
      "48/48 - 5s - loss: 1.0306 - accuracy: 0.6953 - val_loss: 1.5383 - val_accuracy: 0.1016 - 5s/epoch - 107ms/step\n",
      "Epoch 5/20\n",
      "48/48 - 5s - loss: 0.9886 - accuracy: 0.7057 - val_loss: 1.5374 - val_accuracy: 0.1055 - 5s/epoch - 107ms/step\n",
      "Epoch 6/20\n",
      "48/48 - 5s - loss: 0.9799 - accuracy: 0.7135 - val_loss: 1.5385 - val_accuracy: 0.1016 - 5s/epoch - 107ms/step\n",
      "Epoch 7/20\n",
      "48/48 - 5s - loss: 0.9653 - accuracy: 0.7240 - val_loss: 1.5419 - val_accuracy: 0.1016 - 5s/epoch - 107ms/step\n",
      "Epoch 8/20\n",
      "48/48 - 5s - loss: 0.9900 - accuracy: 0.7057 - val_loss: 1.5428 - val_accuracy: 0.1016 - 5s/epoch - 107ms/step\n",
      "Epoch 9/20\n",
      "48/48 - 5s - loss: 0.9917 - accuracy: 0.7344 - val_loss: 1.5484 - val_accuracy: 0.1016 - 5s/epoch - 107ms/step\n",
      "Epoch 10/20\n",
      "48/48 - 5s - loss: 0.9592 - accuracy: 0.7760 - val_loss: 1.5472 - val_accuracy: 0.1016 - 5s/epoch - 104ms/step\n",
      "Epoch 11/20\n",
      "48/48 - 5s - loss: 0.9420 - accuracy: 0.7578 - val_loss: 1.5529 - val_accuracy: 0.1016 - 5s/epoch - 106ms/step\n",
      "Epoch 12/20\n",
      "48/48 - 5s - loss: 0.9724 - accuracy: 0.7135 - val_loss: 1.5549 - val_accuracy: 0.1016 - 5s/epoch - 106ms/step\n",
      "Epoch 13/20\n",
      "48/48 - 5s - loss: 0.9224 - accuracy: 0.7578 - val_loss: 1.5562 - val_accuracy: 0.1016 - 5s/epoch - 107ms/step\n",
      "Epoch 14/20\n",
      "48/48 - 5s - loss: 0.9520 - accuracy: 0.7188 - val_loss: 1.5560 - val_accuracy: 0.1016 - 5s/epoch - 104ms/step\n",
      "Epoch 15/20\n",
      "48/48 - 5s - loss: 0.9367 - accuracy: 0.7708 - val_loss: 1.5584 - val_accuracy: 0.1016 - 5s/epoch - 105ms/step\n",
      "Epoch 16/20\n",
      "48/48 - 5s - loss: 0.9560 - accuracy: 0.7396 - val_loss: 1.5597 - val_accuracy: 0.1016 - 5s/epoch - 105ms/step\n",
      "Epoch 17/20\n",
      "48/48 - 5s - loss: 0.9414 - accuracy: 0.7448 - val_loss: 1.5571 - val_accuracy: 0.1016 - 5s/epoch - 105ms/step\n",
      "Epoch 18/20\n",
      "48/48 - 5s - loss: 0.9252 - accuracy: 0.7552 - val_loss: 1.5603 - val_accuracy: 0.1016 - 5s/epoch - 105ms/step\n",
      "Epoch 19/20\n",
      "48/48 - 5s - loss: 0.9001 - accuracy: 0.7760 - val_loss: 1.5654 - val_accuracy: 0.1016 - 5s/epoch - 105ms/step\n",
      "Epoch 20/20\n",
      "48/48 - 5s - loss: 0.9228 - accuracy: 0.7734 - val_loss: 1.5704 - val_accuracy: 0.0977 - 5s/epoch - 105ms/step\n",
      "Testing time (s) = 101.93054500001017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "model1.fit(x=train_dataset,y=train_dataset_label,batch_size=BATCH_SIZE, epochs=20, initial_epoch = 0, verbose=2,validation_split=0.40,shuffle=True)\n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b410fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 43ms/step - loss: 1.3947 - accuracy: 0.3875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3946599960327148, 0.38749998807907104]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_dataset,test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d16d61df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 37ms/step - loss: 1.0871 - accuracy: 0.5953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0870788097381592, 0.5953124761581421]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(train_dataset,train_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8132b8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  40  to  60\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "48/48 - 5s - loss: 0.9018 - accuracy: 0.7604 - val_loss: 1.5688 - val_accuracy: 0.0977 - 5s/epoch - 106ms/step\n",
      "Epoch 2/20\n",
      "48/48 - 5s - loss: 0.9001 - accuracy: 0.7786 - val_loss: 1.5700 - val_accuracy: 0.0977 - 5s/epoch - 106ms/step\n",
      "Epoch 3/20\n",
      "48/48 - 5s - loss: 0.9113 - accuracy: 0.7474 - val_loss: 1.5678 - val_accuracy: 0.0977 - 5s/epoch - 106ms/step\n",
      "Epoch 4/20\n",
      "48/48 - 5s - loss: 0.9367 - accuracy: 0.7630 - val_loss: 1.5711 - val_accuracy: 0.0977 - 5s/epoch - 107ms/step\n",
      "Epoch 5/20\n",
      "48/48 - 5s - loss: 0.9069 - accuracy: 0.7682 - val_loss: 1.5695 - val_accuracy: 0.0977 - 5s/epoch - 107ms/step\n",
      "Epoch 6/20\n",
      "48/48 - 5s - loss: 0.8803 - accuracy: 0.7917 - val_loss: 1.5755 - val_accuracy: 0.0977 - 5s/epoch - 106ms/step\n",
      "Epoch 7/20\n",
      "48/48 - 5s - loss: 0.8643 - accuracy: 0.7995 - val_loss: 1.5695 - val_accuracy: 0.0977 - 5s/epoch - 106ms/step\n",
      "Epoch 8/20\n",
      "48/48 - 5s - loss: 0.8820 - accuracy: 0.7786 - val_loss: 1.5775 - val_accuracy: 0.0977 - 5s/epoch - 106ms/step\n",
      "Epoch 9/20\n",
      "48/48 - 5s - loss: 0.8853 - accuracy: 0.7604 - val_loss: 1.5813 - val_accuracy: 0.0938 - 5s/epoch - 106ms/step\n",
      "Epoch 10/20\n",
      "48/48 - 5s - loss: 0.9079 - accuracy: 0.7682 - val_loss: 1.5822 - val_accuracy: 0.0977 - 5s/epoch - 106ms/step\n",
      "Epoch 11/20\n",
      "48/48 - 5s - loss: 0.8861 - accuracy: 0.7812 - val_loss: 1.5837 - val_accuracy: 0.0938 - 5s/epoch - 106ms/step\n",
      "Epoch 12/20\n",
      "48/48 - 5s - loss: 0.8954 - accuracy: 0.7604 - val_loss: 1.5890 - val_accuracy: 0.0898 - 5s/epoch - 107ms/step\n",
      "Epoch 13/20\n",
      "48/48 - 5s - loss: 0.8770 - accuracy: 0.7917 - val_loss: 1.5872 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 14/20\n",
      "48/48 - 5s - loss: 0.8831 - accuracy: 0.7891 - val_loss: 1.5959 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 15/20\n",
      "48/48 - 5s - loss: 0.8560 - accuracy: 0.8177 - val_loss: 1.5915 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 16/20\n",
      "48/48 - 5s - loss: 0.8661 - accuracy: 0.7917 - val_loss: 1.5928 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 17/20\n",
      "48/48 - 5s - loss: 0.8764 - accuracy: 0.7656 - val_loss: 1.5962 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 18/20\n",
      "48/48 - 5s - loss: 0.8518 - accuracy: 0.7839 - val_loss: 1.5971 - val_accuracy: 0.0898 - 5s/epoch - 107ms/step\n",
      "Epoch 19/20\n",
      "48/48 - 5s - loss: 0.8473 - accuracy: 0.8047 - val_loss: 1.5967 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 20/20\n",
      "48/48 - 5s - loss: 0.8669 - accuracy: 0.7604 - val_loss: 1.6032 - val_accuracy: 0.0898 - 5s/epoch - 107ms/step\n",
      "<keras.callbacks.History object at 0x000002564B1E2860>\n",
      "Testing time (s) = 102.14456470002187\n",
      "\n",
      "for testing\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.3989 - accuracy: 0.3875\n",
      "[1.3988771438598633, 0.38749998807907104]\n",
      "for training\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 1.0577 - accuracy: 0.6000\n",
      "[1.0577322244644165, 0.6000000238418579]\n",
      "epochs:  42  to  62\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "48/48 - 5s - loss: 0.8535 - accuracy: 0.8203 - val_loss: 1.6080 - val_accuracy: 0.0898 - 5s/epoch - 108ms/step\n",
      "Epoch 2/20\n",
      "48/48 - 5s - loss: 0.8242 - accuracy: 0.8229 - val_loss: 1.6065 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 3/20\n",
      "48/48 - 5s - loss: 0.8473 - accuracy: 0.7812 - val_loss: 1.6039 - val_accuracy: 0.0859 - 5s/epoch - 106ms/step\n",
      "Epoch 4/20\n",
      "48/48 - 5s - loss: 0.8481 - accuracy: 0.8073 - val_loss: 1.6066 - val_accuracy: 0.0859 - 5s/epoch - 106ms/step\n",
      "Epoch 5/20\n",
      "48/48 - 5s - loss: 0.8354 - accuracy: 0.7969 - val_loss: 1.6102 - val_accuracy: 0.0859 - 5s/epoch - 107ms/step\n",
      "Epoch 6/20\n",
      "48/48 - 5s - loss: 0.8230 - accuracy: 0.8177 - val_loss: 1.6072 - val_accuracy: 0.0859 - 5s/epoch - 106ms/step\n",
      "Epoch 7/20\n",
      "48/48 - 5s - loss: 0.8401 - accuracy: 0.7865 - val_loss: 1.6096 - val_accuracy: 0.0859 - 5s/epoch - 107ms/step\n",
      "Epoch 8/20\n",
      "48/48 - 5s - loss: 0.8280 - accuracy: 0.8021 - val_loss: 1.6096 - val_accuracy: 0.0859 - 5s/epoch - 106ms/step\n",
      "Epoch 9/20\n",
      "48/48 - 5s - loss: 0.8258 - accuracy: 0.8021 - val_loss: 1.6041 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 10/20\n",
      "48/48 - 5s - loss: 0.8129 - accuracy: 0.8229 - val_loss: 1.6056 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 11/20\n",
      "48/48 - 5s - loss: 0.8533 - accuracy: 0.7734 - val_loss: 1.6094 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 12/20\n",
      "48/48 - 5s - loss: 0.8177 - accuracy: 0.8255 - val_loss: 1.6147 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 13/20\n",
      "48/48 - 5s - loss: 0.8187 - accuracy: 0.8307 - val_loss: 1.6162 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 14/20\n",
      "48/48 - 5s - loss: 0.7979 - accuracy: 0.8490 - val_loss: 1.6137 - val_accuracy: 0.0898 - 5s/epoch - 107ms/step\n",
      "Epoch 15/20\n",
      "48/48 - 5s - loss: 0.8148 - accuracy: 0.8047 - val_loss: 1.6175 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 16/20\n",
      "48/48 - 5s - loss: 0.7999 - accuracy: 0.8516 - val_loss: 1.6193 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 17/20\n",
      "48/48 - 5s - loss: 0.7851 - accuracy: 0.8255 - val_loss: 1.6098 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 18/20\n",
      "48/48 - 5s - loss: 0.8064 - accuracy: 0.8359 - val_loss: 1.6155 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 19/20\n",
      "48/48 - 5s - loss: 0.8265 - accuracy: 0.7812 - val_loss: 1.6153 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 20/20\n",
      "48/48 - 5s - loss: 0.8588 - accuracy: 0.7839 - val_loss: 1.6162 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "<keras.callbacks.History object at 0x000002564B1E1C00>\n",
      "Testing time (s) = 102.17629499995383\n",
      "\n",
      "for testing\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.4062 - accuracy: 0.4000\n",
      "[1.4062244892120361, 0.4000000059604645]\n",
      "for training\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 1.0328 - accuracy: 0.6047\n",
      "[1.0327781438827515, 0.604687511920929]\n",
      "epochs:  44  to  64\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "48/48 - 5s - loss: 0.7813 - accuracy: 0.8359 - val_loss: 1.6243 - val_accuracy: 0.0898 - 5s/epoch - 113ms/step\n",
      "Epoch 2/20\n",
      "48/48 - 5s - loss: 0.8344 - accuracy: 0.7656 - val_loss: 1.6216 - val_accuracy: 0.0898 - 5s/epoch - 106ms/step\n",
      "Epoch 3/20\n",
      "48/48 - 5s - loss: 0.7888 - accuracy: 0.8099 - val_loss: 1.6246 - val_accuracy: 0.0898 - 5s/epoch - 109ms/step\n",
      "Epoch 4/20\n",
      "48/48 - 5s - loss: 0.7978 - accuracy: 0.8073 - val_loss: 1.6281 - val_accuracy: 0.0898 - 5s/epoch - 95ms/step\n",
      "Epoch 5/20\n",
      "48/48 - 5s - loss: 0.8001 - accuracy: 0.8099 - val_loss: 1.6273 - val_accuracy: 0.0859 - 5s/epoch - 109ms/step\n",
      "Epoch 6/20\n",
      "48/48 - 5s - loss: 0.8010 - accuracy: 0.8125 - val_loss: 1.6280 - val_accuracy: 0.0820 - 5s/epoch - 104ms/step\n",
      "Epoch 7/20\n",
      "48/48 - 5s - loss: 0.7865 - accuracy: 0.8464 - val_loss: 1.6296 - val_accuracy: 0.0820 - 5s/epoch - 108ms/step\n",
      "Epoch 8/20\n",
      "48/48 - 5s - loss: 0.7858 - accuracy: 0.8125 - val_loss: 1.6303 - val_accuracy: 0.0820 - 5s/epoch - 103ms/step\n",
      "Epoch 9/20\n",
      "48/48 - 5s - loss: 0.7721 - accuracy: 0.8307 - val_loss: 1.6341 - val_accuracy: 0.0781 - 5s/epoch - 106ms/step\n",
      "Epoch 10/20\n",
      "48/48 - 5s - loss: 0.7853 - accuracy: 0.8229 - val_loss: 1.6329 - val_accuracy: 0.0859 - 5s/epoch - 104ms/step\n",
      "Epoch 11/20\n",
      "48/48 - 5s - loss: 0.7856 - accuracy: 0.8125 - val_loss: 1.6384 - val_accuracy: 0.0820 - 5s/epoch - 106ms/step\n",
      "Epoch 12/20\n",
      "48/48 - 5s - loss: 0.7764 - accuracy: 0.8359 - val_loss: 1.6369 - val_accuracy: 0.0820 - 5s/epoch - 107ms/step\n",
      "Epoch 13/20\n",
      "48/48 - 5s - loss: 0.7410 - accuracy: 0.8646 - val_loss: 1.6364 - val_accuracy: 0.0820 - 5s/epoch - 108ms/step\n",
      "Epoch 14/20\n",
      "48/48 - 5s - loss: 0.7798 - accuracy: 0.8151 - val_loss: 1.6389 - val_accuracy: 0.0781 - 5s/epoch - 106ms/step\n",
      "Epoch 15/20\n",
      "48/48 - 5s - loss: 0.7600 - accuracy: 0.8464 - val_loss: 1.6420 - val_accuracy: 0.0781 - 5s/epoch - 106ms/step\n",
      "Epoch 16/20\n",
      "48/48 - 5s - loss: 0.7767 - accuracy: 0.8203 - val_loss: 1.6360 - val_accuracy: 0.0859 - 5s/epoch - 106ms/step\n",
      "Epoch 17/20\n",
      "48/48 - 5s - loss: 0.7513 - accuracy: 0.8568 - val_loss: 1.6369 - val_accuracy: 0.0859 - 5s/epoch - 106ms/step\n",
      "Epoch 18/20\n",
      "48/48 - 5s - loss: 0.7728 - accuracy: 0.8333 - val_loss: 1.6362 - val_accuracy: 0.0859 - 5s/epoch - 106ms/step\n",
      "Epoch 19/20\n",
      "48/48 - 5s - loss: 0.7956 - accuracy: 0.7943 - val_loss: 1.6445 - val_accuracy: 0.0859 - 5s/epoch - 106ms/step\n",
      "Epoch 20/20\n",
      "48/48 - 5s - loss: 0.8088 - accuracy: 0.8073 - val_loss: 1.6422 - val_accuracy: 0.0820 - 5s/epoch - 107ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x000002564DC0D990>\n",
      "Testing time (s) = 102.06342180003412\n",
      "\n",
      "for testing\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.4126 - accuracy: 0.3812\n",
      "[1.4126389026641846, 0.3812499940395355]\n",
      "for training\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 1.0199 - accuracy: 0.6125\n",
      "[1.0198969841003418, 0.612500011920929]\n",
      "epochs:  46  to  66\n",
      "Testing started\n",
      "Epoch 1/20\n",
      "48/48 - 5s - loss: 0.7809 - accuracy: 0.8203 - val_loss: 1.6423 - val_accuracy: 0.0859 - 5s/epoch - 108ms/step\n",
      "Epoch 2/20\n",
      "48/48 - 5s - loss: 0.7609 - accuracy: 0.8359 - val_loss: 1.6457 - val_accuracy: 0.0820 - 5s/epoch - 107ms/step\n",
      "Epoch 3/20\n",
      "48/48 - 5s - loss: 0.7507 - accuracy: 0.8411 - val_loss: 1.6517 - val_accuracy: 0.0820 - 5s/epoch - 103ms/step\n",
      "Epoch 4/20\n",
      "48/48 - 5s - loss: 0.7361 - accuracy: 0.8594 - val_loss: 1.6500 - val_accuracy: 0.0820 - 5s/epoch - 109ms/step\n",
      "Epoch 5/20\n",
      "48/48 - 5s - loss: 0.7685 - accuracy: 0.8333 - val_loss: 1.6541 - val_accuracy: 0.0820 - 5s/epoch - 110ms/step\n",
      "Epoch 6/20\n",
      "48/48 - 6s - loss: 0.7441 - accuracy: 0.8385 - val_loss: 1.6482 - val_accuracy: 0.0820 - 6s/epoch - 118ms/step\n",
      "Epoch 7/20\n",
      "48/48 - 6s - loss: 0.7417 - accuracy: 0.8438 - val_loss: 1.6505 - val_accuracy: 0.0820 - 6s/epoch - 120ms/step\n",
      "Epoch 8/20\n",
      "48/48 - 5s - loss: 0.7463 - accuracy: 0.8568 - val_loss: 1.6579 - val_accuracy: 0.0781 - 5s/epoch - 112ms/step\n",
      "Epoch 9/20\n",
      "48/48 - 6s - loss: 0.7438 - accuracy: 0.8464 - val_loss: 1.6531 - val_accuracy: 0.0820 - 6s/epoch - 116ms/step\n",
      "Epoch 10/20\n",
      "48/48 - 5s - loss: 0.7340 - accuracy: 0.8438 - val_loss: 1.6555 - val_accuracy: 0.0820 - 5s/epoch - 109ms/step\n",
      "Epoch 11/20\n",
      "48/48 - 5s - loss: 0.7632 - accuracy: 0.8333 - val_loss: 1.6524 - val_accuracy: 0.0820 - 5s/epoch - 103ms/step\n",
      "Epoch 12/20\n",
      "48/48 - 5s - loss: 0.7453 - accuracy: 0.8307 - val_loss: 1.6587 - val_accuracy: 0.0820 - 5s/epoch - 99ms/step\n",
      "Epoch 13/20\n",
      "48/48 - 5s - loss: 0.7338 - accuracy: 0.8411 - val_loss: 1.6636 - val_accuracy: 0.0820 - 5s/epoch - 100ms/step\n",
      "Epoch 14/20\n",
      "48/48 - 4s - loss: 0.7510 - accuracy: 0.8177 - val_loss: 1.6611 - val_accuracy: 0.0820 - 4s/epoch - 93ms/step\n",
      "Epoch 15/20\n",
      "48/48 - 5s - loss: 0.7598 - accuracy: 0.8411 - val_loss: 1.6652 - val_accuracy: 0.0820 - 5s/epoch - 94ms/step\n",
      "Epoch 16/20\n",
      "48/48 - 4s - loss: 0.7618 - accuracy: 0.8281 - val_loss: 1.6640 - val_accuracy: 0.0820 - 4s/epoch - 91ms/step\n",
      "Epoch 17/20\n",
      "48/48 - 5s - loss: 0.7484 - accuracy: 0.8255 - val_loss: 1.6644 - val_accuracy: 0.0820 - 5s/epoch - 102ms/step\n",
      "Epoch 18/20\n",
      "48/48 - 4s - loss: 0.7054 - accuracy: 0.8776 - val_loss: 1.6616 - val_accuracy: 0.0820 - 4s/epoch - 93ms/step\n",
      "Epoch 19/20\n",
      "48/48 - 4s - loss: 0.7124 - accuracy: 0.8307 - val_loss: 1.6651 - val_accuracy: 0.0820 - 4s/epoch - 93ms/step\n",
      "Epoch 20/20\n",
      "48/48 - 5s - loss: 0.7112 - accuracy: 0.8490 - val_loss: 1.6627 - val_accuracy: 0.0820 - 5s/epoch - 99ms/step\n",
      "<keras.callbacks.History object at 0x000002564DC4FA30>\n",
      "Testing time (s) = 99.88877839996712\n",
      "\n",
      "for testing\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.4209 - accuracy: 0.3875\n",
      "[1.4209365844726562, 0.38749998807907104]\n",
      "for training\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 1.0080 - accuracy: 0.6141\n",
      "[1.0080468654632568, 0.614062488079071]\n"
     ]
    }
   ],
   "source": [
    "for x in range(4):\n",
    "    print(\"epochs: \",40+2*x,\" to \",60+2*x)\n",
    "    tic = start_timer()\n",
    "    print(model1.fit(x=train_dataset,y=train_dataset_label,batch_size=BATCH_SIZE, epochs=20, initial_epoch = 0, verbose=2,validation_split=0.40,shuffle=True))\n",
    "    toc = end_timer()\n",
    "    show_time(tic,toc)\n",
    "    print(\"for testing\")\n",
    "    print(model1.evaluate(test_dataset,test_dataset_label))\n",
    "    print(\"for training\")\n",
    "    print(model1.evaluate(train_dataset,train_dataset_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
