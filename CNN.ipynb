{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb661222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spectral in c:\\users\\ganga\\anaconda3\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ganga\\anaconda3\\lib\\site-packages (from spectral) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python scikit-learn scikit-image matplotlib spectral keras_tuner vis\n",
    "# !pip install tensorflow numpy pandas\n",
    "# !pip install spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b605089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "from math import inf as inf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/nitintyagi/wheat data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\mvl\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Constants\n",
    "TESTING = False\n",
    "\n",
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.90\n",
    "IMAGE_COUNT = int(400/4)\n",
    "NUM_VARIETIES = 4\n",
    "NUM_OF_BANDS = 15\n",
    "FIRST_BAND = 21\n",
    "LAST_BAND = 149\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "ACTIVATION_TYPE =  [\"relu\", \"tanh\",\"sigmoid\"]\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "\n",
    "LEARNING_RATE_BASE = 0.0001\n",
    "MIN_LEARNING_RATE_BASE = LEARNING_RATE_BASE/10\n",
    "\n",
    "FACTOR = 3\n",
    "NUM_MODELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479b1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_file_name():\n",
    "    return \"NumVar_\"+str(NUM_VARIETIES)+\"_ImageCount_\"+str(IMAGE_COUNT)+\"_Factor_\"+str(FACTOR)+\"_MinLR_\"+str(MIN_LEARNING_RATE_BASE)+\"_LR_\"+str(LEARNING_RATE_BASE)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_NumOfBands_\"+str(NUM_OF_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)+\"_BatchSize_\"+str(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5e32422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactPathHDR(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil.hdr\"\n",
    "\n",
    "def exactPathBIL(variety,file):\n",
    "    return DATA_DIRECTORY+variety+SLASH+file+\".bil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10991a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROI(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    threshold = threshold_otsu(img_band)\n",
    "    roi=[]\n",
    "    for x in range(img_band.shape[0]):\n",
    "        a=[]\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if img_band[x][y]>threshold:\n",
    "                a.append(1)\n",
    "            else:\n",
    "                a.append(0)\n",
    "        roi.append(a)\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f92ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns range for x and y from where we have to crop images\n",
    "def getRangeXandY(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    roi = getROI(img,band_number)\n",
    "    xmin = inf\n",
    "    xmax = 0\n",
    "    ymin = inf\n",
    "    ymax = 0\n",
    "    for x in range(img_band.shape[0]):\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if roi[x][y]==1:\n",
    "                if x<xmin:\n",
    "                    xmin=x\n",
    "                if x>xmax:\n",
    "                    xmax=x\n",
    "                if y<ymin:\n",
    "                    ymin=y\n",
    "                if y>ymax:\n",
    "                    ymax=y\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09705166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedImage(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    new_img = img[xmin:xmax, ymin:ymax, :]\n",
    "    return new_img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97d1f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedROI(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    roi = np.array(getROI(img,band_number))\n",
    "    roi = roi[xmin:xmax, ymin:ymax]\n",
    "    return roi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "318efc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsefulImage(img,band_number):\n",
    "    crop_img = getCroppedImage(img,band_number)\n",
    "    crop_roi = getCroppedROI(img,band_number)\n",
    "    for x in range(crop_img.shape[2]):\n",
    "        band = crop_img[:,:,x]\n",
    "        crop_img[:,:,x] = band*crop_roi\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad2376a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    layers.RandomRotation(factor=(-0.1, 0.1)),\n",
    "    layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1,0.1)),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=None)\n",
    "])\n",
    "\n",
    "def getAugumentedImage(img,band_number):\n",
    "    new_img = getUsefulImage(img,band_number)\n",
    "    augmented_image = data_augmentation(new_img) \n",
    "    return augmented_image\n",
    "\n",
    "def checkAugumentedImage(augmented_image):\n",
    "    aug_band = augmented_image[:,:,0]\n",
    "    filled_area_ratio = (np.count_nonzero(aug_band))/(aug_band.shape[0]*aug_band.shape[1])\n",
    "    if filled_area_ratio > FILLED_AREA_RATIO :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad47ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensional Reduction Method\n",
    "def DL_Method(HSI, numComponents = NUM_OF_BANDS):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    n_batches = 10\n",
    "    inc_pca = IncrementalPCA(n_components=numComponents)\n",
    "    for X_batch in np.array_split(RHSI, n_batches):\n",
    "        inc_pca.partial_fit(X_batch)\n",
    "    X_ipca = inc_pca.transform(RHSI)\n",
    "    RHSI = np.reshape(X_ipca, (HSI.shape[0],HSI.shape[1], numComponents))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20b64642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for all file names in varities\n",
    "FILES = []\n",
    "MAX_FILE_NUM = 4\n",
    "for x in range(1,MAX_FILE_NUM+1):\n",
    "    FILES.append(\"B_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a072b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all images\n",
    "images = []\n",
    "images_label = []\n",
    "for v in VARIETIES:\n",
    "    for f in FILES:\n",
    "        try:\n",
    "            img = envi.open(exactPathHDR(v,f),exactPathBIL(v,f))\n",
    "            images.append(img)\n",
    "            images_label.append(v)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2493d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "train_dataset_label = []\n",
    "test_dataset = []\n",
    "test_dataset_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c910c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Testing time (s) = 4482.4309612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "for index, img in enumerate(images):\n",
    "    count = 0\n",
    "    label = images_label[index]\n",
    "    while count<IMAGE_COUNT:\n",
    "        aug_img = getAugumentedImage(img,BAND_NUMBER)\n",
    "        \n",
    "        if checkAugumentedImage(aug_img):\n",
    "            aug_img = DL_Method(aug_img[:,:,FIRST_BAND:LAST_BAND+1])\n",
    "            if count%5 == 0:\n",
    "                test_dataset.append(aug_img)\n",
    "                test_dataset_label.append(label)\n",
    "            else:\n",
    "                train_dataset.append(aug_img)\n",
    "                train_dataset_label.append(label)\n",
    "            count+=1  \n",
    "            \n",
    "    if TESTING:\n",
    "        break\n",
    "        \n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb9af0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.array(train_dataset)\n",
    "train_dataset_label = np.array([VARIETIES_CODE[label] for label in train_dataset_label])\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array([VARIETIES_CODE[label] for label in test_dataset_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d65e88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for index,data in enumerate(test_dataset):\n",
    "#     imshow(data)\n",
    "    print(test_dataset_label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fc54f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for index,data in enumerate(train_dataset):\n",
    "#     imshow(data)\n",
    "    print(train_dataset_label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import math, sys, pdb, os\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from keras import activations\n",
    "import vis\n",
    "# from vis.visualization import visualize_saliency, overlay\n",
    "# from vis.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ce22266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hyperparam_string(learning_rate_base, batch_size, kernel_size, dropout_rate, num_training,\n",
    "                           num_nodes_fc, activation_type):\n",
    "    hparam = \"\"\n",
    "    hparam += str(num_nodes_fc) + \"nodes_\" + str(learning_rate_base) + \"lr_\" + str(batch_size) + \"batch_\" + str(\n",
    "        kernel_size) + \"kernel_\" + str(dropout_rate) + \"drop_\" + str(\n",
    "        num_training) + \"train_\" + activation_type\n",
    "\n",
    "    return hparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fd4a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.clim(0,sum(cm[0,:]))\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d67d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_K_classification_accuracy(y_predicted, y_true, K=1):\n",
    "\n",
    "    num_samples = y_predicted.shape[0]\n",
    "    num_classes = y_predicted.shape[1]\n",
    "\n",
    "    if K > num_classes:\n",
    "        sys.exit(1)\n",
    "\n",
    "    temp = np.zeros((num_samples,))\n",
    "\n",
    "    for idx in range(num_samples):\n",
    "        curr_predicted = np.argsort(y_predicted[idx,:])\n",
    "        curr_predicted = curr_predicted[::-1] # descending\n",
    "\n",
    "        if y_true[idx] in curr_predicted[:K]:\n",
    "            temp[idx] = 1\n",
    "\n",
    "    return 100.0 * np.sum(temp)/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "351725d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    x_orig = x\n",
    "\n",
    "    # Batch norm\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 1x1 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D, kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 3x3 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D, kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation       \n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 1x1 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D*4, kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Skip connection\n",
    "    if int(x.shape[3]) != int(x_orig.shape[3]):\n",
    "        x_orig = Conv2D(int(x.shape[3]), kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x_orig)\n",
    "\n",
    "    # Activation      \n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "#     x = Add()([x, x_orig])\n",
    "\n",
    "    # Dropout\n",
    "    return Dropout(dropout_rate)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0731a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBlock_ResNet2D(x, num_layers, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    for idx_layer in range(num_layers):\n",
    "        x = conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45bd16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth_rate: number of filters for each normal convolution ('k' in the paper)\n",
    "def ResNet2D_classifier(data_num_rows, data_num_cols, num_classes, kernel_size=3, num_layers_each_block=[6, 12, 24, 16],\n",
    "                        num_chan_per_block = [64,128,256,512], activation_type=['relu'], dropout_rate=0.0, num_input_chans=1, num_nodes_fc=64):\n",
    "\n",
    "    input_data = Input(shape=(data_num_rows, data_num_cols, num_input_chans))\n",
    "\n",
    "    # Input layer: Conv2D -> activation\n",
    "    x = Conv2D(num_chan_per_block[0], kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(input_data)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "\n",
    "    #  Blocks & Downsampling Layers\n",
    "    for idx_block in range(len(num_layers_each_block)):\n",
    "        x = createBlock_ResNet2D(x, num_layers_each_block[idx_block], kernel_size, activation_type, dropout_rate,\n",
    "                                 num_chan_per_block[idx_block])\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if idx_block != len(num_layers_each_block)-1:\n",
    "            x = Conv2D(num_chan_per_block[idx_block]*2, kernel_size, strides = 2, activation=None, use_bias=True, padding='valid',\n",
    "                   kernel_initializer='truncated_normal')(x)\n",
    "        else:\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(units=num_nodes_fc, activation=None, kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    output_data = Dense(units=num_classes, activation='softmax', kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    return Model(inputs=input_data, outputs=output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f40895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataset,dataset_label,normalization_type):\n",
    "    print(\"--------------Make Predictions--------------\")    \n",
    "    x = np.array(dataset)\n",
    "    labels = np.array(dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x = normalizeDataWholeSeed(x,normalization_type=normalization_type)\n",
    "    \n",
    "    num = x.shape[0]\n",
    "\n",
    "    tic = start_timer()\n",
    "    labels_predicted = model.predict(x)\n",
    "    toc = end_timer()\n",
    "    show_time(tic,toc)\n",
    "    \n",
    "    print(labels_predicted)\n",
    "    print(\"--------\")\n",
    "    # Classification accuracy\n",
    "    labels_integer_format = labels\n",
    "    labels_predicted_integer_format = np.argmax(labels_predicted, axis=1)\n",
    "\n",
    "    acc_top2 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=2)\n",
    "    acc_top1 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=1)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "    print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e4c541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,normalization_type):\n",
    "    evaluate(model,train_dataset,train_dataset_label,normalization_type)\n",
    "    \n",
    "    evaluate(model,test_dataset,test_dataset_label,normalization_type)\n",
    "    \n",
    "    \n",
    "    # Precision, Recall, F1\n",
    "#     macro_avg = np.asarray(\n",
    "#         precision_recall_fscore_support(labels_test_integer_format, labels_predicted_test_integer_format,\n",
    "#                                         average='macro'))\n",
    "#     macro_avg_precision = macro_avg[0]\n",
    "#     macro_avg_recall = macro_avg[1]\n",
    "#     macro_avg_fscore = macro_avg[2]\n",
    "\n",
    "#     print('Top-1 accuracy (%) = ' + str(acc_top1) + '\\n')\n",
    "#     print('Top-2 accuracy (%) = ' + str(acc_top2) + '\\n')\n",
    "#     print('Macro-avg precision = ' + str(macro_avg_precision) + '\\n')\n",
    "#     print('Macro-avg recall = ' + str(macro_avg_recall) + '\\n')\n",
    "#     print('Macro-avg f-score = ' + str(macro_avg_fscore) + '\\n')\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Compute Saliency Maps--------------\")\n",
    "#     results_test_dir = os.path.join(results_dir, 'test')\n",
    "#     if not os.path.exists(results_test_dir):\n",
    "#         os.makedirs(results_test_dir)\n",
    "\n",
    "#     # Swap softmax with linear\n",
    "#     model.layers[-1].activation = activations.linear\n",
    "#     model = utils.apply_modifications(model)\n",
    "\n",
    "#     for idx_wheat in range(num_test):\n",
    "\n",
    "#         grads = visualize_saliency(model, layer_idx=-1, filter_indices=np.argmax(labels_test[idx_wheat, :], axis=0),\n",
    "#                                    seed_input=x_test[idx_wheat], backprop_modifier=None)\n",
    "\n",
    "#         ss_img = np.sqrt(np.sum(abs(x_test[idx_wheat, :, :, :]) ** 2, axis=2))\n",
    "#         ss_img /= np.max(ss_img)\n",
    "\n",
    "#         plt.figure(1)\n",
    "#         plt.subplot(3, 1, 1)\n",
    "#         plt.imshow(ss_img, cmap='gray')\n",
    "#         plt.clim(0, 1)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         plt.subplot(3, 1, 2)\n",
    "#         plt.imshow((grads * np.uint8(255)).astype('uint8'), cmap='jet')\n",
    "#         plt.clim(0, 255)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * np.uint8(255))\n",
    "\n",
    "#         plt.subplot(3, 1, 3)\n",
    "#         ss_img = cv2.cvtColor((ss_img * np.uint8(255)).astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "#         plt.imshow(overlay(jet_heatmap, ss_img, alpha=0.3))\n",
    "#         plt.clim(0, 255)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         plt.savefig(os.path.join(results_test_dir, str(idx_wheat+1) + '.png'))\n",
    "#         plt.clf()\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Save the information--------------\")\n",
    "\n",
    "#     # Write some information to files\n",
    "#     f = open(os.path.join(results_test_dir, 'testing_info.txt'), 'w')\n",
    "#     f.write(\"Wheat types = \" + str(wheat_types) + \"\\n\")\n",
    "#     f.write(\"Confusion matrix \\n\")\n",
    "#     f.write(str(confusion_matrix_results) + \"\\n\")\n",
    "#     f.write(\"Normalization type = \" + str(normalization_type) + \"\\n\")\n",
    "#     f.write(\"# test samples = %d \\n\" % (num_test))\n",
    "#     f.write(\"Top-1 test accuracy = %f \\n\" % (acc_top1))\n",
    "#     f.write(\"Top-2 test accuracy = %f \\n\" % (acc_top2))\n",
    "#     f.write(\"Macro-avg precision = %f \\n\" % (macro_avg_precision))\n",
    "#     f.write(\"Macro-avg recall = %f \\n\" % (macro_avg_recall))\n",
    "#     f.write(\"Macro-avg f-score = %f \\n\" % (macro_avg_fscore))\n",
    "#     f.write(\"Test time (s) = \" + str(test_time) + \"\\n\")\n",
    "#     f.close()\n",
    "\n",
    "#     # Save confusion matrices\n",
    "#     plt.figure(1)\n",
    "#     plot_confusion_matrix(confusion_matrix_results, classes=wheat_types, normalize=False, title='Confusion matrix')\n",
    "#     plt.savefig(os.path.join(results_test_dir,'confusionMatrix.png'))\n",
    "#     plt.clf()\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Save the information for the training phase--------------\")\n",
    "    \n",
    "#     import pandas as pd\n",
    "    \n",
    "#     # Save the trained model\n",
    "#     model.save_weights(os.path.join(results_dir, 'trainedResNetB_weights.h5'))\n",
    "    \n",
    "#     # Extract the training loss   \n",
    "#     training_loss = hist.history['loss']\n",
    "\n",
    "#     # Save the training loss\n",
    "#     df = pd.DataFrame(data={'training loss': training_loss},index=np.arange(num_epochs)+1)\n",
    "#     df.to_csv(os.path.join(results_dir,'training_loss.csv'))\n",
    "    \n",
    "#     # Save the training loss as a figure\n",
    "#     plt.figure(1)\n",
    "#     plt.title('Loss')\n",
    "#     plt.plot(training_loss, color='b',label='Training')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.savefig(os.path.join(results_dir,'training_loss.png'))\n",
    "#     plt.clf()   \n",
    "    \n",
    "#     # Write a file with general information\n",
    "#     f = open(os.path.join(results_dir,'training_info.txt'),'w')\n",
    "#     f.write(hparams + '\\n')\n",
    "#     f.write('Wheat types = ' + str(wheat_types)+'\\n')\n",
    "#     f.write('Training time (s) = %f \\n' %(training_time))\n",
    "#     f.write('Normalization type = ' + str(normalization_type)+ '\\n')\n",
    "#     f.write('# epochs = ' + str(num_epochs) + '\\n')\n",
    "#     f.write('# training samples = %d \\n' %(num_training))\n",
    "#     f.close()\n",
    "    \n",
    "#     print(\"--------------Done--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6797662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndTrainResNetB():\n",
    "    \n",
    "    learning_rate_base = LEARNING_RATE_BASE\n",
    "    kernel_size = 3\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    batch_size = BATCH_SIZE\n",
    "    dropout_rate = 0.15 \n",
    "    activation_type = 'relu'\n",
    "    num_nodes_fc = 512\n",
    "    wheat_types =  VARIETIES\n",
    "    normalization_type = 'max'\n",
    "    num_layers_each_block = [1, 1, 0, 0]\n",
    "    num_chan_per_block = [128, 256, 256, 256]\n",
    "    N_classes = len(wheat_types)\n",
    "    \n",
    "    ############ Load data ############\n",
    "    print(\"--------------Load Data--------------\")\n",
    "\n",
    "    # Load training data and their corresponding labels\n",
    "    x_training = np.array(train_dataset)\n",
    "    labels_training = np.array(train_dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_training = normalizeDataWholeSeed(x_training,normalization_type=normalization_type)\n",
    "    \n",
    "    # Extract some information\n",
    "    num_training = x_training.shape[0]\n",
    "    N_spatial = x_training.shape[1:3]\n",
    "    N_bands = x_training.shape[3]\n",
    "    \n",
    "    print('#training = %d' %(num_training))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "    \n",
    "    \n",
    "    ############ Prepare the path for saving the models/stats ############\n",
    "#     print(\"--------------Prepare a path for saving the models/stats--------------\")\n",
    "    \n",
    "#     hparams = make_hyperparam_string(learning_rate_base, batch_size, kernel_size, dropout_rate,\n",
    "#                                      num_training, num_nodes_fc, activation_type)\n",
    "#     print('Saving the model to...')\n",
    "    \n",
    "#     results_dir = os.path.join('./results/',hparams)\n",
    "    \n",
    "#     if not os.path.exists(results_dir):\n",
    "#         os.makedirs(results_dir)\n",
    "#     print(results_dir)\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Create a model ############\n",
    "    print(\"--------------Create a model--------------\")\n",
    "    \n",
    "    # Generate a model\n",
    "    model = ResNet2D_classifier(data_num_rows=N_spatial[0], data_num_cols=N_spatial[1], num_classes=N_classes,\n",
    "                                kernel_size=kernel_size, num_layers_each_block=num_layers_each_block,\n",
    "                                num_chan_per_block=num_chan_per_block, activation_type=activation_type,\n",
    "                                dropout_rate=dropout_rate, num_input_chans=N_bands, num_nodes_fc=num_nodes_fc)\n",
    "\n",
    "    # Compile the model\n",
    "    adam_opt = Adam(learning_rate=LEARNING_RATE_BASE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "\n",
    "    # Create a Tensorboard callback\n",
    "#     tbCallBack = TensorBoard(log_dir=results_dir, histogram_freq=0, write_graph=False, write_images=False)\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Train the model ############\n",
    "    print(\"--------------Begin training the model--------------\")\n",
    "\n",
    "#     tic = timeit.default_timer()\n",
    "    \n",
    "    # Train the model\n",
    "#     hist = model.fit(x=x_training,y=labels_training,batch_size=batch_size,  epochs = num_epochs, initial_epoch = 0, verbose=2, callbacks = [tbCallBack],validation_split=0.15,shuffle=True)\n",
    "\n",
    "#     toc = timeit.default_timer()\n",
    "#     training_time = toc-tic\n",
    "#     print(\"Total training time = \" + str(training_time))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72a8706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "#training = 1280\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n",
      "--------------Done--------------\n",
      "--------------Begin training the model--------------\n",
      "--------------Done--------------\n"
     ]
    }
   ],
   "source": [
    "model = createAndTrainResNetB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e61e02cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Epoch 1/40\n",
      "128/128 - 121s - loss: 1.6253 - accuracy: 0.3135 - val_loss: 0.7005 - val_accuracy: 1.0000 - 121s/epoch - 947ms/step\n",
      "Epoch 2/40\n",
      "128/128 - 94s - loss: 1.3971 - accuracy: 0.3770 - val_loss: 0.6833 - val_accuracy: 0.6250 - 94s/epoch - 738ms/step\n",
      "Epoch 3/40\n",
      "128/128 - 80s - loss: 1.2325 - accuracy: 0.4600 - val_loss: 0.8350 - val_accuracy: 0.3945 - 80s/epoch - 628ms/step\n",
      "Epoch 4/40\n",
      "128/128 - 81s - loss: 1.1512 - accuracy: 0.5088 - val_loss: 0.8530 - val_accuracy: 0.4531 - 81s/epoch - 634ms/step\n",
      "Epoch 5/40\n",
      "128/128 - 84s - loss: 1.1187 - accuracy: 0.5332 - val_loss: 0.8775 - val_accuracy: 0.5078 - 84s/epoch - 654ms/step\n",
      "Epoch 6/40\n",
      "128/128 - 82s - loss: 1.0751 - accuracy: 0.5420 - val_loss: 0.8514 - val_accuracy: 0.5820 - 82s/epoch - 643ms/step\n",
      "Epoch 7/40\n",
      "128/128 - 83s - loss: 1.0550 - accuracy: 0.5498 - val_loss: 0.9067 - val_accuracy: 0.5508 - 83s/epoch - 652ms/step\n",
      "Epoch 8/40\n",
      "128/128 - 83s - loss: 1.0313 - accuracy: 0.5723 - val_loss: 0.8938 - val_accuracy: 0.5781 - 83s/epoch - 651ms/step\n",
      "Epoch 9/40\n",
      "128/128 - 83s - loss: 1.0106 - accuracy: 0.5840 - val_loss: 0.9502 - val_accuracy: 0.5273 - 83s/epoch - 645ms/step\n",
      "Epoch 10/40\n",
      "128/128 - 83s - loss: 0.9755 - accuracy: 0.5986 - val_loss: 0.9241 - val_accuracy: 0.5508 - 83s/epoch - 652ms/step\n",
      "Epoch 11/40\n",
      "128/128 - 83s - loss: 0.9291 - accuracy: 0.6143 - val_loss: 0.9018 - val_accuracy: 0.5625 - 83s/epoch - 650ms/step\n",
      "Epoch 12/40\n",
      "128/128 - 84s - loss: 0.9155 - accuracy: 0.6309 - val_loss: 0.8937 - val_accuracy: 0.5742 - 84s/epoch - 653ms/step\n",
      "Epoch 13/40\n",
      "128/128 - 84s - loss: 0.9454 - accuracy: 0.6387 - val_loss: 0.8788 - val_accuracy: 0.5781 - 84s/epoch - 660ms/step\n",
      "Epoch 14/40\n",
      "128/128 - 82s - loss: 0.9047 - accuracy: 0.6289 - val_loss: 0.8398 - val_accuracy: 0.6094 - 82s/epoch - 642ms/step\n",
      "Epoch 15/40\n",
      "128/128 - 87s - loss: 0.8646 - accuracy: 0.6387 - val_loss: 0.8772 - val_accuracy: 0.5742 - 87s/epoch - 678ms/step\n",
      "Epoch 16/40\n",
      "128/128 - 89s - loss: 0.8589 - accuracy: 0.6533 - val_loss: 0.8709 - val_accuracy: 0.5859 - 89s/epoch - 699ms/step\n",
      "Epoch 17/40\n",
      "128/128 - 84s - loss: 0.8074 - accuracy: 0.6963 - val_loss: 0.8176 - val_accuracy: 0.6289 - 84s/epoch - 654ms/step\n",
      "Epoch 18/40\n",
      "128/128 - 90s - loss: 0.8407 - accuracy: 0.6484 - val_loss: 0.8290 - val_accuracy: 0.6133 - 90s/epoch - 705ms/step\n",
      "Epoch 19/40\n",
      "128/128 - 94s - loss: 0.8142 - accuracy: 0.6836 - val_loss: 0.8333 - val_accuracy: 0.5977 - 94s/epoch - 735ms/step\n",
      "Epoch 20/40\n",
      "128/128 - 109s - loss: 0.8425 - accuracy: 0.6650 - val_loss: 0.8132 - val_accuracy: 0.6172 - 109s/epoch - 852ms/step\n",
      "Epoch 21/40\n",
      "128/128 - 105s - loss: 0.8069 - accuracy: 0.6963 - val_loss: 0.8359 - val_accuracy: 0.5938 - 105s/epoch - 823ms/step\n",
      "Epoch 22/40\n",
      "128/128 - 106s - loss: 0.7744 - accuracy: 0.6885 - val_loss: 0.8301 - val_accuracy: 0.6016 - 106s/epoch - 830ms/step\n",
      "Epoch 23/40\n",
      "128/128 - 105s - loss: 0.7671 - accuracy: 0.6992 - val_loss: 0.8032 - val_accuracy: 0.6250 - 105s/epoch - 822ms/step\n",
      "Epoch 24/40\n",
      "128/128 - 105s - loss: 0.7495 - accuracy: 0.6992 - val_loss: 0.8331 - val_accuracy: 0.5859 - 105s/epoch - 819ms/step\n",
      "Epoch 25/40\n",
      "128/128 - 109s - loss: 0.7538 - accuracy: 0.7139 - val_loss: 0.8213 - val_accuracy: 0.6055 - 109s/epoch - 855ms/step\n",
      "Epoch 26/40\n",
      "128/128 - 101s - loss: 0.7865 - accuracy: 0.7070 - val_loss: 0.8226 - val_accuracy: 0.6055 - 101s/epoch - 788ms/step\n",
      "Epoch 27/40\n",
      "128/128 - 104s - loss: 0.7605 - accuracy: 0.7109 - val_loss: 0.8147 - val_accuracy: 0.6133 - 104s/epoch - 810ms/step\n",
      "Epoch 28/40\n",
      "128/128 - 104s - loss: 0.7479 - accuracy: 0.7178 - val_loss: 0.8271 - val_accuracy: 0.6055 - 104s/epoch - 811ms/step\n",
      "Epoch 29/40\n",
      "128/128 - 104s - loss: 0.7423 - accuracy: 0.7207 - val_loss: 0.8395 - val_accuracy: 0.5977 - 104s/epoch - 811ms/step\n",
      "Epoch 30/40\n",
      "128/128 - 108s - loss: 0.7323 - accuracy: 0.7217 - val_loss: 0.8186 - val_accuracy: 0.6133 - 108s/epoch - 840ms/step\n",
      "Epoch 31/40\n",
      "128/128 - 112s - loss: 0.7151 - accuracy: 0.7305 - val_loss: 0.8236 - val_accuracy: 0.6055 - 112s/epoch - 873ms/step\n",
      "Epoch 32/40\n",
      "128/128 - 112s - loss: 0.7446 - accuracy: 0.7168 - val_loss: 0.8094 - val_accuracy: 0.6133 - 112s/epoch - 872ms/step\n",
      "Epoch 33/40\n",
      "128/128 - 108s - loss: 0.7075 - accuracy: 0.7334 - val_loss: 0.8386 - val_accuracy: 0.6016 - 108s/epoch - 840ms/step\n",
      "Epoch 34/40\n",
      "128/128 - 124s - loss: 0.7064 - accuracy: 0.7461 - val_loss: 0.7987 - val_accuracy: 0.6211 - 124s/epoch - 972ms/step\n",
      "Epoch 35/40\n",
      "128/128 - 117s - loss: 0.6955 - accuracy: 0.7354 - val_loss: 0.8000 - val_accuracy: 0.6367 - 117s/epoch - 913ms/step\n",
      "Epoch 36/40\n",
      "128/128 - 115s - loss: 0.7014 - accuracy: 0.7236 - val_loss: 0.8098 - val_accuracy: 0.6211 - 115s/epoch - 898ms/step\n",
      "Epoch 37/40\n",
      "128/128 - 119s - loss: 0.7099 - accuracy: 0.7207 - val_loss: 0.7883 - val_accuracy: 0.6328 - 119s/epoch - 927ms/step\n",
      "Epoch 38/40\n",
      "128/128 - 133s - loss: 0.6946 - accuracy: 0.7393 - val_loss: 0.7713 - val_accuracy: 0.6523 - 133s/epoch - 1s/step\n",
      "Epoch 39/40\n",
      "128/128 - 117s - loss: 0.6975 - accuracy: 0.7354 - val_loss: 0.7729 - val_accuracy: 0.6484 - 117s/epoch - 911ms/step\n",
      "Epoch 40/40\n",
      "128/128 - 110s - loss: 0.6718 - accuracy: 0.7451 - val_loss: 0.7764 - val_accuracy: 0.6562 - 110s/epoch - 859ms/step\n",
      "Testing time (s) = 3991.7509411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "model.fit(x=train_dataset,y=train_dataset_label,batch_size=BATCH_SIZE, epochs=40, initial_epoch = 0, verbose=2,validation_split=0.20,shuffle=True)\n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9faf1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 392ms/step - loss: 1.3709 - accuracy: 0.5031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3708915710449219, 0.503125011920929]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset,test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eea3d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 23s 563ms/step - loss: 0.5590 - accuracy: 0.7930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5590478181838989, 0.79296875]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_dataset,train_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4b161d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "#training = 640\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n",
      "--------------Done--------------\n",
      "--------------Begin training the model--------------\n",
      "--------------Done--------------\n"
     ]
    }
   ],
   "source": [
    "model = createAndTrainResNetB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4fc49294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started\n",
      "Epoch 1/40\n",
      "48/48 - 27s - loss: 1.7449 - accuracy: 0.2370 - val_loss: 1.3808 - val_accuracy: 0.2539 - 27s/epoch - 555ms/step\n",
      "Epoch 2/40\n",
      "48/48 - 22s - loss: 1.4506 - accuracy: 0.3932 - val_loss: 1.3688 - val_accuracy: 0.2266 - 22s/epoch - 448ms/step\n",
      "Epoch 3/40\n",
      "48/48 - 22s - loss: 1.2645 - accuracy: 0.4453 - val_loss: 1.4015 - val_accuracy: 0.1680 - 22s/epoch - 465ms/step\n",
      "Epoch 4/40\n",
      "48/48 - 22s - loss: 1.1415 - accuracy: 0.5469 - val_loss: 1.4351 - val_accuracy: 0.1250 - 22s/epoch - 460ms/step\n",
      "Epoch 5/40\n",
      "48/48 - 22s - loss: 1.1228 - accuracy: 0.5495 - val_loss: 1.4650 - val_accuracy: 0.1289 - 22s/epoch - 457ms/step\n",
      "Epoch 6/40\n",
      "48/48 - 22s - loss: 0.9469 - accuracy: 0.6328 - val_loss: 1.5645 - val_accuracy: 0.1055 - 22s/epoch - 469ms/step\n",
      "Epoch 7/40\n",
      "48/48 - 22s - loss: 0.9173 - accuracy: 0.6328 - val_loss: 1.6428 - val_accuracy: 0.0820 - 22s/epoch - 458ms/step\n",
      "Epoch 8/40\n",
      "48/48 - 22s - loss: 0.8884 - accuracy: 0.6719 - val_loss: 1.7056 - val_accuracy: 0.0859 - 22s/epoch - 456ms/step\n",
      "Epoch 9/40\n",
      "48/48 - 22s - loss: 0.7852 - accuracy: 0.7057 - val_loss: 1.7755 - val_accuracy: 0.0898 - 22s/epoch - 457ms/step\n",
      "Epoch 10/40\n",
      "48/48 - 22s - loss: 0.7891 - accuracy: 0.7318 - val_loss: 1.8042 - val_accuracy: 0.0898 - 22s/epoch - 458ms/step\n",
      "Epoch 11/40\n",
      "48/48 - 22s - loss: 0.7870 - accuracy: 0.7031 - val_loss: 1.8109 - val_accuracy: 0.1094 - 22s/epoch - 460ms/step\n",
      "Epoch 12/40\n",
      "48/48 - 22s - loss: 0.6879 - accuracy: 0.7630 - val_loss: 1.8546 - val_accuracy: 0.0977 - 22s/epoch - 458ms/step\n",
      "Epoch 13/40\n",
      "48/48 - 22s - loss: 0.6352 - accuracy: 0.7891 - val_loss: 1.8367 - val_accuracy: 0.0977 - 22s/epoch - 457ms/step\n",
      "Epoch 14/40\n",
      "48/48 - 22s - loss: 0.6699 - accuracy: 0.7839 - val_loss: 1.8623 - val_accuracy: 0.0977 - 22s/epoch - 464ms/step\n",
      "Epoch 15/40\n",
      "48/48 - 22s - loss: 0.6320 - accuracy: 0.7812 - val_loss: 1.8994 - val_accuracy: 0.0938 - 22s/epoch - 458ms/step\n",
      "Epoch 16/40\n",
      "48/48 - 22s - loss: 0.6056 - accuracy: 0.7917 - val_loss: 1.9052 - val_accuracy: 0.0938 - 22s/epoch - 461ms/step\n",
      "Epoch 17/40\n",
      "48/48 - 22s - loss: 0.5741 - accuracy: 0.8047 - val_loss: 1.9151 - val_accuracy: 0.0938 - 22s/epoch - 459ms/step\n",
      "Epoch 18/40\n",
      "48/48 - 22s - loss: 0.5388 - accuracy: 0.8203 - val_loss: 1.9055 - val_accuracy: 0.1055 - 22s/epoch - 456ms/step\n",
      "Epoch 19/40\n",
      "48/48 - 22s - loss: 0.5605 - accuracy: 0.8099 - val_loss: 1.9383 - val_accuracy: 0.0977 - 22s/epoch - 463ms/step\n",
      "Epoch 20/40\n",
      "48/48 - 23s - loss: 0.5285 - accuracy: 0.8151 - val_loss: 1.9811 - val_accuracy: 0.0977 - 23s/epoch - 477ms/step\n",
      "Epoch 21/40\n",
      "48/48 - 22s - loss: 0.5094 - accuracy: 0.8464 - val_loss: 1.9837 - val_accuracy: 0.1016 - 22s/epoch - 459ms/step\n",
      "Epoch 22/40\n",
      "48/48 - 22s - loss: 0.5237 - accuracy: 0.8307 - val_loss: 2.0105 - val_accuracy: 0.0977 - 22s/epoch - 460ms/step\n",
      "Epoch 23/40\n",
      "48/48 - 22s - loss: 0.5177 - accuracy: 0.8385 - val_loss: 2.0206 - val_accuracy: 0.1016 - 22s/epoch - 460ms/step\n",
      "Epoch 24/40\n",
      "48/48 - 22s - loss: 0.5113 - accuracy: 0.8464 - val_loss: 2.0258 - val_accuracy: 0.0977 - 22s/epoch - 460ms/step\n",
      "Epoch 25/40\n",
      "48/48 - 22s - loss: 0.4874 - accuracy: 0.8359 - val_loss: 2.0460 - val_accuracy: 0.0977 - 22s/epoch - 459ms/step\n",
      "Epoch 26/40\n",
      "48/48 - 22s - loss: 0.4327 - accuracy: 0.8646 - val_loss: 2.0677 - val_accuracy: 0.0938 - 22s/epoch - 458ms/step\n",
      "Epoch 27/40\n",
      "48/48 - 22s - loss: 0.4636 - accuracy: 0.8594 - val_loss: 2.0969 - val_accuracy: 0.0938 - 22s/epoch - 468ms/step\n",
      "Epoch 28/40\n",
      "48/48 - 23s - loss: 0.4105 - accuracy: 0.8672 - val_loss: 2.1233 - val_accuracy: 0.0898 - 23s/epoch - 480ms/step\n",
      "Epoch 29/40\n",
      "48/48 - 22s - loss: 0.4452 - accuracy: 0.8646 - val_loss: 2.1247 - val_accuracy: 0.0859 - 22s/epoch - 460ms/step\n",
      "Epoch 30/40\n",
      "48/48 - 22s - loss: 0.4048 - accuracy: 0.8672 - val_loss: 2.1568 - val_accuracy: 0.0859 - 22s/epoch - 458ms/step\n",
      "Epoch 31/40\n",
      "48/48 - 22s - loss: 0.4374 - accuracy: 0.8646 - val_loss: 2.1507 - val_accuracy: 0.0977 - 22s/epoch - 459ms/step\n",
      "Epoch 32/40\n",
      "48/48 - 22s - loss: 0.3398 - accuracy: 0.9062 - val_loss: 2.1490 - val_accuracy: 0.0938 - 22s/epoch - 458ms/step\n",
      "Epoch 33/40\n",
      "48/48 - 22s - loss: 0.3355 - accuracy: 0.9010 - val_loss: 2.1536 - val_accuracy: 0.0938 - 22s/epoch - 464ms/step\n",
      "Epoch 34/40\n",
      "48/48 - 22s - loss: 0.4036 - accuracy: 0.8698 - val_loss: 2.1654 - val_accuracy: 0.0938 - 22s/epoch - 458ms/step\n",
      "Epoch 35/40\n",
      "48/48 - 22s - loss: 0.3792 - accuracy: 0.8906 - val_loss: 2.1862 - val_accuracy: 0.0977 - 22s/epoch - 458ms/step\n",
      "Epoch 36/40\n",
      "48/48 - 22s - loss: 0.3520 - accuracy: 0.8958 - val_loss: 2.1714 - val_accuracy: 0.0938 - 22s/epoch - 460ms/step\n",
      "Epoch 37/40\n",
      "48/48 - 22s - loss: 0.2739 - accuracy: 0.9401 - val_loss: 2.1897 - val_accuracy: 0.0977 - 22s/epoch - 457ms/step\n",
      "Epoch 38/40\n",
      "48/48 - 22s - loss: 0.3243 - accuracy: 0.9089 - val_loss: 2.2327 - val_accuracy: 0.0977 - 22s/epoch - 460ms/step\n",
      "Epoch 39/40\n",
      "48/48 - 22s - loss: 0.3803 - accuracy: 0.8776 - val_loss: 2.2256 - val_accuracy: 0.0938 - 22s/epoch - 460ms/step\n",
      "Epoch 40/40\n",
      "48/48 - 22s - loss: 0.3338 - accuracy: 0.9167 - val_loss: 2.2462 - val_accuracy: 0.0977 - 22s/epoch - 459ms/step\n",
      "Testing time (s) = 888.744230500015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = start_timer()\n",
    "model.fit(x=train_dataset,y=train_dataset_label,batch_size=BATCH_SIZE, epochs=40, initial_epoch = 0, verbose=2,validation_split=0.40,shuffle=True)\n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1080cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 204ms/step - loss: 1.8504 - accuracy: 0.3250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8503806591033936, 0.32499998807907104]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset,test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9d2e2785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 221ms/step - loss: 0.9358 - accuracy: 0.6391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9358184933662415, 0.6390625238418579]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_dataset,train_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "beb7c306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c924b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "tuner.results_summary(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "RESULT_FILE_NAME = dt_string+\"_\"+result_file_name()+\".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join('./result_summary')\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./result_summary/\"+RESULT_FILE_NAME,'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d76079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
