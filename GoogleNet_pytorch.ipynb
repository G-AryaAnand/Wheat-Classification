{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52912966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, timeit\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from math import inf as inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10614a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd26930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "SLASH = \"\"\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"/home/ishu_g.iitr/wheat/data/BULK/\"\n",
    "    SLASH = \"/\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\mvl\\wheat\\data\\BULK\\\\\"\n",
    "    SLASH=\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.9\n",
    "TOTAL_IMAGE_COUNT = 8\n",
    "IMAGE_COUNT = int(TOTAL_IMAGE_COUNT/4)\n",
    "NUM_VARIETIES = 4\n",
    "\n",
    "IMAGE_WIDTH = 30\n",
    "IMAGE_HEIGHT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "066f0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION_TYPE =  \"relu\"\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE_BASE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f32e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 1\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e3a1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    " \n",
    "class feature_extraction_method(Enum):\n",
    "    none = 0\n",
    "    pca_loading = 1\n",
    "    lda = 2\n",
    "    ipca = 3\n",
    "\n",
    "FEAT_EXT = 0\n",
    "FEATURE_EXTRACTION = feature_extraction_method(FEAT_EXT).name\n",
    "\n",
    "NUM_OF_BANDS = 3\n",
    "if FEATURE_EXTRACTION == \"pca_loading\" or FEATURE_EXTRACTION == \"ipca\":\n",
    "    NUM_OF_BANDS = 8\n",
    "elif FEATURE_EXTRACTION == \"lda\":\n",
    "    NUM_OF_BANDS = 3\n",
    "    assert NUM_OF_BANDS <= min(NUM_VARIETIES-1,168),\"NUM_OF_BANDS is greater.\"\n",
    "\n",
    "\n",
    "REMOVE_NOISY_BANDS = False\n",
    "FIRST_BAND = 15\n",
    "LAST_BAND = 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e61072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    print(\"Testing started\")\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def end_timer():\n",
    "    return timeit.default_timer()\n",
    "\n",
    "def show_time(tic,toc): \n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72409e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(variety):\n",
    "    name = \"./dataset/\"+str(variety).zfill(3)+\"_IC_\"+str(TOTAL_IMAGE_COUNT).zfill(5)+\"_FilledArea_\"+str(FILLED_AREA_RATIO)+\"_BandNo_\"+str(BAND_NUMBER)+\"_ImageHeight_\"+str(IMAGE_HEIGHT)+\"_ImageWidth_\"+str(IMAGE_WIDTH)\n",
    "    if FILT != 0:\n",
    "        name+=\"_FILTER_\"+str(FILTER)\n",
    "    if FEAT_EXT !=0:\n",
    "        name+=\"_FeatureExtraction_\"+str(FEATURE_EXTRACTION)+\"_NumOfBands_\"+str(NUM_OF_BANDS)\n",
    "    if REMOVE_NOISY_BANDS:\n",
    "        name+=\"_REMOVE_NOISY_BANDS_\"+str(REMOVE_NOISY_BANDS)+\"_FB_\"+str(FIRST_BAND)+\"_LB_\"+str(LAST_BAND)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce9dd572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DBW 187', 'DBW222', 'HD 3086', 'PBW 291']\n"
     ]
    }
   ],
   "source": [
    "print(VARIETIES[:NUM_VARIETIES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e74afa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  0\n",
      "idx:  1\n",
      "idx:  2\n",
      "idx:  3\n"
     ]
    }
   ],
   "source": [
    "train_dataset = []\n",
    "train_dataset_label = []\n",
    "test_dataset=[]\n",
    "test_dataset_label = []\n",
    "\n",
    "for idx, v in enumerate(VARIETIES):\n",
    "    print(\"idx: \",idx)\n",
    "    if idx >= NUM_VARIETIES:\n",
    "        break\n",
    "    train_dataset= train_dataset + np.load(dataset_file_name(v)+\"_train_dataset.npy\").tolist()\n",
    "    train_dataset_label = train_dataset_label + np.load(dataset_file_name(v)+\"_train_dataset_label.npy\").tolist()\n",
    "    test_dataset = test_dataset + np.load(dataset_file_name(v)+\"_test_dataset.npy\").tolist()\n",
    "    test_dataset_label = test_dataset_label + np.load(dataset_file_name(v)+\"_test_dataset_label.npy\").tolist()\n",
    "    \n",
    "train_dataset = np.array(train_dataset)\n",
    "train_dataset_label = np.array(train_dataset_label)\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array(test_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c752599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# from nn import layers, models, losses, Module, Activation, Dense,  GlobalAveragePooling2d,\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d, MaxPool2d,  Flatten,AvgPool2d, Dropout\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d48cd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:])       \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "948287a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_fts, out_fts, k, s, p='same'):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.convolution = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_fts, out_channels=out_fts, kernel_size=(k, k), stride=(s, s), padding=p),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        x = self.convolution(input_img)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fe3ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceConvBlock(nn.Module):\n",
    "    def __init__(self, in_fts, out_fts_1, out_fts_2, k, p='same'):\n",
    "        super(ReduceConvBlock, self).__init__()\n",
    "        self.redConv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_fts, out_channels=out_fts_1, kernel_size=(1, 1), stride=(1, 1),padding = p),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_fts_1, out_channels=out_fts_2, kernel_size=(k, k), stride=(1, 1), padding=p),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        x = self.redConv(input_img)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af2d6745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, curr_in_fts, f_1x1, f_3x3_r, f_3x3, f_5x5_r, f_5x5, f_pool_proj):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        self.conv1 = ConvBlock(curr_in_fts, f_1x1, 1, 1, 0)\n",
    "        self.conv2 = ReduceConvBlock(curr_in_fts, f_3x3_r, f_3x3, 3, 1)\n",
    "        self.conv3 = ReduceConvBlock(curr_in_fts, f_5x5_r, f_5x5, 5, 2)\n",
    "\n",
    "        self.pool_proj = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=(1, 1), stride=(1, 1)),\n",
    "            nn.Conv2d(in_channels=curr_in_fts, out_channels=f_pool_proj, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        out1 = self.conv1(input_img)\n",
    "        out2 = self.conv2(input_img)\n",
    "        out3 = self.conv3(input_img)\n",
    "        out4 = self.pool_proj(input_img)\n",
    "\n",
    "        x = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bab7cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxClassifier(nn.Module):\n",
    "    def __init__(self, in_fts, num_classes):\n",
    "        super(AuxClassifier, self).__init__()\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(5, 5), stride=(3, 3))\n",
    "        self.conv = nn.Conv2d(in_channels=in_fts, out_channels=128, kernel_size=(1, 1), stride=(1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(4 * 4 * 128, 1024)\n",
    "        self.dropout = nn.Dropout(p=0.7)\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        N = input_img.shape[0]\n",
    "        x = self.avgpool(input_img)\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.reshape(N, -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7917b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGoogleNet(nn.Module):\n",
    "    def __init__(self, in_fts=3, num_class=1000):\n",
    "        print(\"in_fts: \",in_fts)\n",
    "        super(MyGoogleNet, self).__init__()\n",
    "        self.conv1 = ConvBlock(in_fts, 64, 7, 2, 3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            ConvBlock(64, 64, 1, 1, 0),\n",
    "            ConvBlock(64, 192, 3, 1, 1)\n",
    "        )\n",
    "#                                     curr_in_fts, f_1x1, f_3x3_r, f_3x3, f_5x5_r, f_5x5, f_pool_proj\n",
    "        self.inception_3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception_3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.inception_4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception_4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception_4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception_4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception_4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception_5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception_5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.aux_classifier1 = AuxClassifier(512, num_class)\n",
    "        self.aux_classifier2 = AuxClassifier(528, num_class)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(1024 * 7 * 7, num_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        print(\"size: \",input_img.shape)\n",
    "        N = input_img.shape[0]\n",
    "        x = self.conv1(input_img)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.inception_3a(x)\n",
    "        x = self.inception_3b(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.inception_4a(x)\n",
    "        out1 = self.aux_classifier1(x)\n",
    "        x = self.inception_4b(x)\n",
    "        x = self.inception_4c(x)\n",
    "        x = self.inception_4d(x)\n",
    "        out2 = self.aux_classifier2(x)\n",
    "        x = self.inception_4e(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.inception_5a(x)\n",
    "        x = self.inception_5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(N, -1)\n",
    "        x = self.classifier(x)\n",
    "        if self.training == True:\n",
    "            return [x, out1, out2]\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43d8a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoogleNetModel(data_num_rows, data_num_cols, num_input_chans=1, num_classes=NUM_VARIETIES, activation_type='relu', dropout_rate=0.0):\n",
    "\n",
    "    inp = Input(shape=(data_num_rows, data_num_cols, num_input_chans))\n",
    "    input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=train_dataset.shape[1:])(inp)\n",
    "    x = Conv2d(64,  7, strides=2, padding='same', activation=activation_type)(input_tensor)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = Conv2d(64,  1, strides=1, padding='same', activation=activation_type)(x)\n",
    "    x = Conv2d(192, 3, strides=1, padding='same', activation=activation_type)(x)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = inception(x, filters_1x1=64 , filters_3x3_reduce=96 , filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool=32)\n",
    "    x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool=64)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = inception(x, filters_1x1=192, filters_3x3_reduce=96 , filters_3x3=208, filters_5x5_reduce=16, filters_5x5=48, filters_pool=64)\n",
    "    \n",
    "    aux1 = auxiliary_classifier(x,num_classes)\n",
    "    \n",
    "    x = inception(x, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
    "    x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=256, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
    "    x = inception(x, filters_1x1=112, filters_3x3_reduce=144, filters_3x3=288, filters_5x5_reduce=32, filters_5x5=64, filters_pool=64)\n",
    "    \n",
    "    aux2 = auxiliary_classifier(x,num_classes)\n",
    "    \n",
    "    x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
    "    x = MaxPooling2D(3, strides=2)(x)\n",
    "    x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
    "    x = inception(x, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384, filters_5x5_reduce=48, filters_5x5=128, filters_pool=128)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs = inp, outputs = [out, aux1, aux2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3528776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGoogleNetModel():\n",
    "    learning_rate_base = LEARNING_RATE_BASE\n",
    "    activation_type = ACTIVATION_TYPE\n",
    "    wheat_types =  VARIETIES\n",
    "    num_classes = len(wheat_types)\n",
    "#     dropout_rate = 0.4\n",
    "    print(\"--------------Load Data--------------\")\n",
    "\n",
    "    x_training = np.array(train_dataset)\n",
    "    labels_training = np.array(train_dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_training = normalizeDataWholeSeed(x_training)\n",
    "    \n",
    "    # Extract some information\n",
    "    num_train = x_training.shape[0]\n",
    "    N_spatial = x_training.shape[1:3]\n",
    "    N_channel = x_training.shape[3]\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "    \n",
    "    ############ Create a model ############\n",
    "    print(\"--------------Create a model--------------\")\n",
    "    \n",
    "    # Generate a model\n",
    "#     model = GoogleNetModel(data_num_rows = N_spatial[0], \n",
    "#                            data_num_cols = N_spatial[1],\n",
    "#                            num_input_chans = N_channel, \n",
    "#                            num_classes = num_classes,\n",
    "#                            activation_type = activation_type,\n",
    "#                            dropout_rate = dropout_rate)\n",
    "    model = MyGoogleNet(N_channel,num_classes)\n",
    "    # Compile the model\n",
    "#     adam_opt = Adam(lr=LEARNING_RATE_BASE, betas = (0.9,0.999), eps=1e-08, decay=0.01)\n",
    "#     torch.compile(model,optimizer=adam_opt, loss=[losses.sparse_categorical_crossentropy,losses.sparse_categorical_crossentropy,losses.sparse_categorical_crossentropy],loss_weights=[1, 0.3, 0.3],metrics=['accuracy'])\n",
    "    print(\"---------Completed---------\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be0c2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9df49795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n",
      "in_fts:  168\n",
      "---------Completed---------\n"
     ]
    }
   ],
   "source": [
    "model = getGoogleNetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da26dbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 30, 30, 168)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39c42ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  torch.Size([2, 16, 168, 30, 30])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchsummary\\torchsummary.py:140\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 140\u001b[0m         _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)(\u001b[38;5;241m*\u001b[39mx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [56], line 33\u001b[0m, in \u001b[0;36mMyGoogleNet.forward\u001b[1;34m(self, input_img)\u001b[0m\n\u001b[0;32m     32\u001b[0m N \u001b[38;5;241m=\u001b[39m input_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool1(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn [20], line 10\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[1;34m(self, input_img)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_img):\n\u001b[1;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 16, 168, 30, 30]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m----> 2\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m168\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchsummary\\torchsummary.py:143\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    142\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchsummary. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(executed_layers)\n\u001b[0;32m    146\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (16, 168, 30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5df8cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    if i%5==0:\n",
    "        x_val.append(train_dataset[i])\n",
    "        y_val.append(train_dataset_label[i])\n",
    "    else:\n",
    "        x_train.append(train_dataset[i])\n",
    "        y_train.append(train_dataset_label[i])\n",
    "        \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train = [y_train,y_train,y_train]\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "y_val = [y_val,y_val,y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e30efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = start_timer()\n",
    "for x in range(EPOCHS):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    model.fit(x_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, validation_data=(x_val, y_val), shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    print(\"for testing\")\n",
    "    print(model.evaluate(test_dataset,test_dataset_label))\n",
    "    print(\"for training\")\n",
    "    print(model.evaluate(train_dataset,train_dataset_label))\n",
    "toc = end_timer()\n",
    "show_time(tic,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','dense_4_loss','dense_1_loss','dense_3_loss','dense_4_accuracy','dense_1_accuracy','dense_3_accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','dense_4_loss','dense_1_loss','dense_3_loss','dense_4_accuracy','dense_1_accuracy','dense_3_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(train_eva_df,'Model Train Loss','Epoch','Loss',['loss'],['train_loss'])\n",
    "plot_graph(test_eva_df,'Model Test Loss','Epoch','Loss',['loss'],['test_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1626ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(train_eva_df,'Model Train Accuracy','Epoch','Dense Accuracy',['dense_4_accuracy', 'dense_1_accuracy', 'dense_3_accuracy'])\n",
    "plot_graph(test_eva_df,'Model Test Accuracy','Epoch','Dense Accuracy',['dense_4_accuracy', 'dense_1_accuracy', 'dense_3_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae448b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(train_eva_df,'Model Train Loss','Epoch','Dense Loss',['dense_4_loss', 'dense_1_loss', 'dense_3_loss'])\n",
    "plot_graph(test_eva_df,'Model Test Loss','Epoch','Dense Loss',['dense_4_loss', 'dense_1_loss', 'dense_3_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(history_dataframe,'Model Loss','Epoch','Loss',['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(history_dataframe,'Model Train Accuracy','Epoch','Dense Accuracy',['dense_4_accuracy', 'dense_1_accuracy', 'dense_3_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70409bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(history_dataframe,'Model Train Loss','Epoch','Dense Loss',['dense_4_loss', 'dense_1_loss', 'dense_3_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332856c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(history_dataframe,'Model Val Accuracy','Epoch','Validation Accuracy',['val_dense_4_accuracy', 'val_dense_1_accuracy', 'val_dense_3_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(history_dataframe,'Model Val Loss','Epoch','Validation Loss',['val_dense_4_loss', 'val_dense_1_loss', 'val_dense_3_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
