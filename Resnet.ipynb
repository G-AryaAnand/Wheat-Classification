{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b605089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cc1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras import layers as layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c004aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "from math import inf as inf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9300cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi as envi\n",
    "from spectral import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee790ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3717a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd26930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f72da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "DATA_DIRECTORY = \"\"\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DATA_DIRECTORY = \"\\mnt\\\\\"\n",
    "elif platform == \"win32\":\n",
    "    DATA_DIRECTORY = \"D:\\mvl\\wheat\\data\\BULK\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5979451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Constants\n",
    "TESTING = False\n",
    "\n",
    "#Constants\n",
    "BAND_NUMBER = 60\n",
    "FILLED_AREA_RATIO = 0.85\n",
    "IMAGE_COUNT = 20\n",
    "NUM_VARIETIES = 4\n",
    "NUM_OF_BANDS = 20\n",
    "FIRST_BAND = 21\n",
    "LAST_BAND = 149\n",
    "\n",
    "IMAGE_WIDTH = 40\n",
    "IMAGE_HEIGHT = 40\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "ACTIVATION_TYPE =  [\"relu\", \"tanh\",\"sigmoid\"]\n",
    "BATCH_SIZE = 2*NUM_VARIETIES\n",
    "\n",
    "LEARNING_RATE_BASE = 0.0001\n",
    "MIN_LEARNING_RATE_BASE = LEARNING_RATE_BASE/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5e32422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactPathHDR(variety,file):\n",
    "    return DATA_DIRECTORY+variety+\"\\\\\"+file+\".bil.hdr\"\n",
    "\n",
    "def exactPathBIL(variety,file):\n",
    "    return DATA_DIRECTORY+variety+\"\\\\\"+file+\".bil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10991a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROI(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    threshold = threshold_otsu(img_band)\n",
    "    roi=[]\n",
    "    for x in range(img_band.shape[0]):\n",
    "        a=[]\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if img_band[x][y]>threshold:\n",
    "                a.append(1)\n",
    "            else:\n",
    "                a.append(0)\n",
    "        roi.append(a)\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f92ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns range for x and y from where we have to crop images\n",
    "def getRangeXandY(img,band_number):\n",
    "    img_band = img.read_band(band_number)\n",
    "    roi = getROI(img,band_number)\n",
    "    xmin = inf\n",
    "    xmax = 0\n",
    "    ymin = inf\n",
    "    ymax = 0\n",
    "    for x in range(img_band.shape[0]):\n",
    "        for y in range(img_band.shape[1]):\n",
    "            if roi[x][y]==1:\n",
    "                if x<xmin:\n",
    "                    xmin=x\n",
    "                if x>xmax:\n",
    "                    xmax=x\n",
    "                if y<ymin:\n",
    "                    ymin=y\n",
    "                if y>ymax:\n",
    "                    ymax=y\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09705166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedImage(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    new_img = img[xmin:xmax, ymin:ymax, :]\n",
    "    return new_img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d1f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCroppedROI(img,band_number):\n",
    "    xmin, xmax, ymin, ymax = getRangeXandY(img,band_number)\n",
    "    roi = np.array(getROI(img,band_number))\n",
    "    roi = roi[xmin:xmax, ymin:ymax]\n",
    "    return roi   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "318efc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsefulImage(img,band_number):\n",
    "    crop_img = getCroppedImage(img,band_number)\n",
    "    crop_roi = getCroppedROI(img,band_number)\n",
    "    for x in range(crop_img.shape[2]):\n",
    "        band = crop_img[:,:,x]\n",
    "        crop_img[:,:,x] = band*crop_roi\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad2376a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "    layers.RandomRotation(factor=(-0.1, 0.1)),\n",
    "    layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1,0.1)),\n",
    "    layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=None)\n",
    "])\n",
    "\n",
    "def getAugumentedImage(img,band_number):\n",
    "    new_img = getUsefulImage(img,band_number)\n",
    "    augmented_image = data_augmentation(new_img) \n",
    "    return augmented_image\n",
    "\n",
    "def checkAugumentedImage(augmented_image):\n",
    "    aug_band = augmented_image[:,:,0]\n",
    "    filled_area_ratio = (np.count_nonzero(aug_band))/(aug_band.shape[0]*aug_band.shape[1])\n",
    "    if filled_area_ratio > FILLED_AREA_RATIO :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad47ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensional Reduction Method\n",
    "def DL_Method(HSI, numComponents = NUM_OF_BANDS):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    n_batches = 10\n",
    "    inc_pca = IncrementalPCA(n_components=numComponents)\n",
    "    for X_batch in np.array_split(RHSI, n_batches):\n",
    "        inc_pca.partial_fit(X_batch)\n",
    "    X_ipca = inc_pca.transform(RHSI)\n",
    "    RHSI = np.reshape(X_ipca, (HSI.shape[0],HSI.shape[1], numComponents))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e16e403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for All varieties\n",
    "VARIETIES = []\n",
    "VARIETIES_CODE = {}\n",
    "\n",
    "for name in os.listdir(DATA_DIRECTORY):\n",
    "    if (name.endswith(\".hdr\") or name.endswith(\".bil\")):\n",
    "        continue\n",
    "    VARIETIES_CODE[name] = len(VARIETIES)\n",
    "    VARIETIES.append(name)\n",
    "    if len(VARIETIES)==NUM_VARIETIES:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b64642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for all file names in varities\n",
    "FILES = []\n",
    "MAX_FILE_NUM = 4\n",
    "for x in range(1,MAX_FILE_NUM+1):\n",
    "    FILES.append(\"B_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a072b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all images\n",
    "images = []\n",
    "images_label = []\n",
    "for v in VARIETIES:\n",
    "    for f in FILES:\n",
    "        try:\n",
    "            img = envi.open(exactPathHDR(v,f),exactPathBIL(v,f))\n",
    "            images.append(img)\n",
    "            images_label.append(v)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c910c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "train_dataset_label = []\n",
    "test_dataset = []\n",
    "test_dataset_label = []\n",
    "\n",
    "for index, img in enumerate(images):\n",
    "    count = 0\n",
    "    label = images_label[index]\n",
    "    while count<IMAGE_COUNT:\n",
    "        aug_img = getAugumentedImage(img,BAND_NUMBER)\n",
    "        \n",
    "        if checkAugumentedImage(aug_img):\n",
    "            aug_img = DL_Method(aug_img[:,:,FIRST_BAND:LAST_BAND+1])\n",
    "            if count%5 == 0:\n",
    "                test_dataset.append(aug_img)\n",
    "                test_dataset_label.append(label)\n",
    "            else:\n",
    "                train_dataset.append(aug_img)\n",
    "                train_dataset_label.append(label)\n",
    "            count+=1  \n",
    "            \n",
    "    if TESTING:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb9af0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.array(train_dataset)\n",
    "train_dataset_label = np.array([VARIETIES_CODE[label] for label in train_dataset_label])\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_dataset_label = np.array([VARIETIES_CODE[label] for label in test_dataset_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d65e88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for index,data in enumerate(test_dataset):\n",
    "#     imshow(data)\n",
    "    print(test_dataset_label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fc54f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for index,data in enumerate(train_dataset):\n",
    "#     imshow(data)\n",
    "    print(train_dataset_label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e6c0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import math, sys, pdb, os\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Conv2DTranspose, Flatten, Dense, Conv1D, AveragePooling2D, LeakyReLU, PReLU, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os, pdb, timeit\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from keras import activations\n",
    "import vis\n",
    "# from vis.visualization import visualize_saliency, overlay\n",
    "# from vis.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f98cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataWholeSeed(data,normalization_type='max'):\n",
    "    \n",
    "    if normalization_type == 'max':\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/np.max(abs(data[idx,:,:,:]))\n",
    "            \n",
    "    elif normalization_type == 'l2norm':\n",
    "        from numpy import linalg as LA\n",
    "        for idx in range(data.shape[0]):\n",
    "            data[idx,:,:,:] = data[idx,:,:,:]/LA.norm(data[idx,:,:,:]) # L2-norm by default        \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ce22266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hyperparam_string(learning_rate_base, batch_size, kernel_size, dropout_rate, num_training,\n",
    "                           num_nodes_fc, activation_type):\n",
    "    hparam = \"\"\n",
    "    hparam += str(num_nodes_fc) + \"nodes_\" + str(learning_rate_base) + \"lr_\" + str(batch_size) + \"batch_\" + str(\n",
    "        kernel_size) + \"kernel_\" + str(dropout_rate) + \"drop_\" + str(\n",
    "        num_training) + \"train_\" + activation_type\n",
    "\n",
    "    return hparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd4a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.clim(0,sum(cm[0,:]))\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d67d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_K_classification_accuracy(y_predicted, y_true, K=1):\n",
    "\n",
    "    num_samples = y_predicted.shape[0]\n",
    "    num_classes = y_predicted.shape[1]\n",
    "\n",
    "    if K > num_classes:\n",
    "        sys.exit(1)\n",
    "\n",
    "    temp = np.zeros((num_samples,))\n",
    "\n",
    "    for idx in range(num_samples):\n",
    "        curr_predicted = np.argsort(y_predicted[idx,:])\n",
    "        curr_predicted = curr_predicted[::-1] # descending\n",
    "\n",
    "        if y_true[idx] in curr_predicted[:K]:\n",
    "            temp[idx] = 1\n",
    "\n",
    "    return 100.0 * np.sum(temp)/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "351725d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    x_orig = x\n",
    "\n",
    "    # Batch norm\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 1x1 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D, kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 3x3 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D, kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation       \n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 1x1 Conv2D\n",
    "    x = Conv2D(num_filters_first_conv1D*4, kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Skip connection\n",
    "    if int(x.shape[3]) != int(x_orig.shape[3]):\n",
    "        x_orig = Conv2D(int(x.shape[3]), kernel_size=1, activation=None, use_bias=False, padding='same',\n",
    "               kernel_initializer='truncated_normal')(x_orig)\n",
    "\n",
    "    # Activation      \n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = Add()([x, x_orig])\n",
    "\n",
    "    # Dropout\n",
    "    return Dropout(dropout_rate)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0731a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBlock_ResNet2D(hp,index,x, num_layers, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D):\n",
    "\n",
    "    for idx_layer in range(hp.Int('layers'+str(index),int(num_layers/4),num_layers)):\n",
    "        x = conv2D_ResNet(x, kernel_size, activation_type, dropout_rate, num_filters_first_conv1D)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45bd16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth_rate: number of filters for each normal convolution ('k' in the paper)\n",
    "def ResNet2D_classifier(hp,data_num_rows, data_num_cols, num_classes, kernel_size=3, num_layers_each_block=[6, 12, 24, 16],\n",
    "                        num_chan_per_block = [64,128,256,512], activation_type=['relu'], dropout_rate=0.0, num_input_chans=1, num_nodes_fc=64):\n",
    "\n",
    "    input_data = Input(shape=(data_num_rows, data_num_cols, num_input_chans))\n",
    "\n",
    "    # Input layer: Conv2D -> activation\n",
    "    x = Conv2D(num_chan_per_block[0], kernel_size, activation=None, use_bias=True, padding='same',\n",
    "               kernel_initializer='truncated_normal')(input_data)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "\n",
    "    #  Blocks & Downsampling Layers\n",
    "    for idx_block in range(len(num_layers_each_block)):\n",
    "        x = createBlock_ResNet2D(hp,idx_block,x, num_layers_each_block[idx_block], kernel_size, activation_type, dropout_rate,\n",
    "                                 num_chan_per_block[idx_block])\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if idx_block != len(num_layers_each_block)-1:\n",
    "            x = Conv2D(num_chan_per_block[idx_block]*2, kernel_size, strides = 2, activation=None, use_bias=True, padding='valid',\n",
    "                   kernel_initializer='truncated_normal')(x)\n",
    "        else:\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(units=num_nodes_fc, activation=None, kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    # Activation\n",
    "    x = Activation(activation_type)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    output_data = Dense(units=num_classes, activation='softmax', kernel_initializer='truncated_normal')(x)\n",
    "\n",
    "    return Model(inputs=input_data, outputs=output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f40895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,dataset,dataset_label,normalization_type):\n",
    "    print(\"--------------Make Predictions--------------\")    \n",
    "    x = np.array(dataset)\n",
    "    labels = np.array(dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x = normalizeDataWholeSeed(x,normalization_type=normalization_type)\n",
    "    \n",
    "    num = x.shape[0]\n",
    "\n",
    "    print(\"Testing started\")\n",
    "    tic = timeit.default_timer()\n",
    "    labels_predicted = model.predict(x)\n",
    "    toc = timeit.default_timer()\n",
    "    test_time = toc - tic\n",
    "    print('Testing time (s) = ' + str(test_time) + '\\n')\n",
    "    \n",
    "    print(labels_predicted)\n",
    "    print(\"--------\")\n",
    "    # Classification accuracy\n",
    "    labels_integer_format = labels\n",
    "    labels_predicted_integer_format = np.argmax(labels_predicted, axis=1)\n",
    "\n",
    "    acc_top2 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=2)\n",
    "    acc_top1 = top_K_classification_accuracy(labels_predicted, labels_integer_format, K=1)\n",
    "    \n",
    "    # Confusion matrices\n",
    "    confusion_matrix_results = confusion_matrix(labels_integer_format, labels_predicted_integer_format)\n",
    "    print(\"Confusion matrix = \")\n",
    "    print(confusion_matrix_results)\n",
    "    print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e4c541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,normalization_type):\n",
    "    evaluate(model,train_dataset,train_dataset_label,normalization_type)\n",
    "    \n",
    "    evaluate(model,test_dataset,test_dataset_label,normalization_type)\n",
    "    \n",
    "    \n",
    "    # Precision, Recall, F1\n",
    "#     macro_avg = np.asarray(\n",
    "#         precision_recall_fscore_support(labels_test_integer_format, labels_predicted_test_integer_format,\n",
    "#                                         average='macro'))\n",
    "#     macro_avg_precision = macro_avg[0]\n",
    "#     macro_avg_recall = macro_avg[1]\n",
    "#     macro_avg_fscore = macro_avg[2]\n",
    "\n",
    "#     print('Top-1 accuracy (%) = ' + str(acc_top1) + '\\n')\n",
    "#     print('Top-2 accuracy (%) = ' + str(acc_top2) + '\\n')\n",
    "#     print('Macro-avg precision = ' + str(macro_avg_precision) + '\\n')\n",
    "#     print('Macro-avg recall = ' + str(macro_avg_recall) + '\\n')\n",
    "#     print('Macro-avg f-score = ' + str(macro_avg_fscore) + '\\n')\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Compute Saliency Maps--------------\")\n",
    "#     results_test_dir = os.path.join(results_dir, 'test')\n",
    "#     if not os.path.exists(results_test_dir):\n",
    "#         os.makedirs(results_test_dir)\n",
    "\n",
    "#     # Swap softmax with linear\n",
    "#     model.layers[-1].activation = activations.linear\n",
    "#     model = utils.apply_modifications(model)\n",
    "\n",
    "#     for idx_wheat in range(num_test):\n",
    "\n",
    "#         grads = visualize_saliency(model, layer_idx=-1, filter_indices=np.argmax(labels_test[idx_wheat, :], axis=0),\n",
    "#                                    seed_input=x_test[idx_wheat], backprop_modifier=None)\n",
    "\n",
    "#         ss_img = np.sqrt(np.sum(abs(x_test[idx_wheat, :, :, :]) ** 2, axis=2))\n",
    "#         ss_img /= np.max(ss_img)\n",
    "\n",
    "#         plt.figure(1)\n",
    "#         plt.subplot(3, 1, 1)\n",
    "#         plt.imshow(ss_img, cmap='gray')\n",
    "#         plt.clim(0, 1)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         plt.subplot(3, 1, 2)\n",
    "#         plt.imshow((grads * np.uint8(255)).astype('uint8'), cmap='jet')\n",
    "#         plt.clim(0, 255)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * np.uint8(255))\n",
    "\n",
    "#         plt.subplot(3, 1, 3)\n",
    "#         ss_img = cv2.cvtColor((ss_img * np.uint8(255)).astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "#         plt.imshow(overlay(jet_heatmap, ss_img, alpha=0.3))\n",
    "#         plt.clim(0, 255)\n",
    "#         plt.axis('off')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#         plt.savefig(os.path.join(results_test_dir, str(idx_wheat+1) + '.png'))\n",
    "#         plt.clf()\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Save the information--------------\")\n",
    "\n",
    "#     # Write some information to files\n",
    "#     f = open(os.path.join(results_test_dir, 'testing_info.txt'), 'w')\n",
    "#     f.write(\"Wheat types = \" + str(wheat_types) + \"\\n\")\n",
    "#     f.write(\"Confusion matrix \\n\")\n",
    "#     f.write(str(confusion_matrix_results) + \"\\n\")\n",
    "#     f.write(\"Normalization type = \" + str(normalization_type) + \"\\n\")\n",
    "#     f.write(\"# test samples = %d \\n\" % (num_test))\n",
    "#     f.write(\"Top-1 test accuracy = %f \\n\" % (acc_top1))\n",
    "#     f.write(\"Top-2 test accuracy = %f \\n\" % (acc_top2))\n",
    "#     f.write(\"Macro-avg precision = %f \\n\" % (macro_avg_precision))\n",
    "#     f.write(\"Macro-avg recall = %f \\n\" % (macro_avg_recall))\n",
    "#     f.write(\"Macro-avg f-score = %f \\n\" % (macro_avg_fscore))\n",
    "#     f.write(\"Test time (s) = \" + str(test_time) + \"\\n\")\n",
    "#     f.close()\n",
    "\n",
    "#     # Save confusion matrices\n",
    "#     plt.figure(1)\n",
    "#     plot_confusion_matrix(confusion_matrix_results, classes=wheat_types, normalize=False, title='Confusion matrix')\n",
    "#     plt.savefig(os.path.join(results_test_dir,'confusionMatrix.png'))\n",
    "#     plt.clf()\n",
    "\n",
    "#     print(\"--------------Done--------------\")\n",
    "\n",
    "#     print(\"--------------Save the information for the training phase--------------\")\n",
    "    \n",
    "#     import pandas as pd\n",
    "    \n",
    "#     # Save the trained model\n",
    "#     model.save_weights(os.path.join(results_dir, 'trainedResNetB_weights.h5'))\n",
    "    \n",
    "#     # Extract the training loss   \n",
    "#     training_loss = hist.history['loss']\n",
    "\n",
    "#     # Save the training loss\n",
    "#     df = pd.DataFrame(data={'training loss': training_loss},index=np.arange(num_epochs)+1)\n",
    "#     df.to_csv(os.path.join(results_dir,'training_loss.csv'))\n",
    "    \n",
    "#     # Save the training loss as a figure\n",
    "#     plt.figure(1)\n",
    "#     plt.title('Loss')\n",
    "#     plt.plot(training_loss, color='b',label='Training')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.savefig(os.path.join(results_dir,'training_loss.png'))\n",
    "#     plt.clf()   \n",
    "    \n",
    "#     # Write a file with general information\n",
    "#     f = open(os.path.join(results_dir,'training_info.txt'),'w')\n",
    "#     f.write(hparams + '\\n')\n",
    "#     f.write('Wheat types = ' + str(wheat_types)+'\\n')\n",
    "#     f.write('Training time (s) = %f \\n' %(training_time))\n",
    "#     f.write('Normalization type = ' + str(normalization_type)+ '\\n')\n",
    "#     f.write('# epochs = ' + str(num_epochs) + '\\n')\n",
    "#     f.write('# training samples = %d \\n' %(num_training))\n",
    "#     f.close()\n",
    "    \n",
    "#     print(\"--------------Done--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6797662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndTrainResNetB(hp):\n",
    "    \n",
    "    learning_rate_base = LEARNING_RATE_BASE\n",
    "    kernel_size = 3\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    batch_size = BATCH_SIZE\n",
    "    dropout_rate = 0.15 \n",
    "    activation_type = hp.Choice('act',ACTIVATION_TYPE)\n",
    "    num_nodes_fc = 512\n",
    "    wheat_types =  VARIETIES\n",
    "    normalization_type = 'max'\n",
    "    num_layers_each_block = [8, 8, 12, 8]\n",
    "    num_chan_per_block = [128, 128, 256, 256]\n",
    "    N_classes = len(wheat_types)\n",
    "    \n",
    "    ############ Load data ############\n",
    "    print(\"--------------Load Data--------------\")\n",
    "\n",
    "    # Load training data and their corresponding labels\n",
    "    x_training = np.array(train_dataset)\n",
    "    labels_training = np.array(train_dataset_label)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_training = normalizeDataWholeSeed(x_training,normalization_type=normalization_type)\n",
    "    \n",
    "    # Extract some information\n",
    "    num_training = x_training.shape[0]\n",
    "    N_spatial = x_training.shape[1:3]\n",
    "    N_bands = x_training.shape[3]\n",
    "    \n",
    "    print('#training = %d' %(num_training))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "    \n",
    "    \n",
    "    ############ Prepare the path for saving the models/stats ############\n",
    "    print(\"--------------Prepare a path for saving the models/stats--------------\")\n",
    "    \n",
    "    hparams = make_hyperparam_string(learning_rate_base, batch_size, kernel_size, dropout_rate,\n",
    "                                     num_training, num_nodes_fc, activation_type)\n",
    "    print('Saving the model to...')\n",
    "    \n",
    "    results_dir = os.path.join('./results/',hparams)\n",
    "    \n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    print(results_dir)\n",
    "\n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Create a model ############\n",
    "    print(\"--------------Create a model--------------\")\n",
    "    \n",
    "    # Generate a model\n",
    "    model = ResNet2D_classifier(hp=hp,data_num_rows=N_spatial[0], data_num_cols=N_spatial[1], num_classes=N_classes,\n",
    "                                kernel_size=kernel_size, num_layers_each_block=num_layers_each_block,\n",
    "                                num_chan_per_block=num_chan_per_block, activation_type=activation_type,\n",
    "                                dropout_rate=dropout_rate, num_input_chans=N_bands, num_nodes_fc=num_nodes_fc)\n",
    "\n",
    "    # Compile the model\n",
    "    adam_opt = Adam(learning_rate=hp.Float(\"lr\", min_value=MIN_LEARNING_RATE_BASE, max_value=learning_rate_base, sampling=\"log\"), beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.01)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "\n",
    "    # Create a Tensorboard callback\n",
    "    tbCallBack = TensorBoard(log_dir=results_dir, histogram_freq=0, write_graph=False, write_images=False)\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    ############ Train the model ############\n",
    "    print(\"--------------Begin training the model--------------\")\n",
    "\n",
    "    tic = timeit.default_timer()\n",
    "    \n",
    "    # Train the model\n",
    "#     hist = model.fit(x=x_training,y=labels_training,batch_size=batch_size,  epochs = num_epochs, initial_epoch = 0, verbose=2, callbacks = [tbCallBack],validation_split=0.15,shuffle=True)\n",
    "\n",
    "#     toc = timeit.default_timer()\n",
    "#     training_time = toc-tic\n",
    "#     print(\"Total training time = \" + str(training_time))\n",
    "    \n",
    "    print(\"--------------Done--------------\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "922e0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = kt.HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0ab0625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Load Data--------------\n",
      "#training = 256\n",
      "--------------Done--------------\n",
      "--------------Prepare a path for saving the models/stats--------------\n",
      "Saving the model to...\n",
      "./results/512nodes_0.0001lr_8batch_3kernel_0.15drop_256train_relu\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n",
      "--------------Done--------------\n",
      "--------------Begin training the model--------------\n",
      "--------------Done--------------\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    hypermodel=createAndTrainResNetB,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs = 100,\n",
    "    factor=5,\n",
    "    hyperband_iterations=1,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d46fab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "act (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "layers0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 1, 'sampling': None}\n",
      "layers1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 1, 'sampling': None}\n",
      "layers2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 12, 'step': 1, 'sampling': None}\n",
      "layers3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 1, 'sampling': None}\n",
      "lr (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.0001, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155e9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [01h 07m 28s]\n",
      "val_accuracy: 0.5384615659713745\n",
      "\n",
      "Best val_accuracy So Far: 0.5384615659713745\n",
      "Total elapsed time: 01h 07m 28s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "tanh              |relu              |act\n",
      "7                 |5                 |layers0\n",
      "8                 |2                 |layers1\n",
      "3                 |8                 |layers2\n",
      "6                 |6                 |layers3\n",
      "1.0749e-05        |1.9494e-05        |lr\n",
      "4                 |4                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "--------------Load Data--------------\n",
      "#training = 256\n",
      "--------------Done--------------\n",
      "--------------Prepare a path for saving the models/stats--------------\n",
      "Saving the model to...\n",
      "./results/512nodes_0.0001lr_8batch_3kernel_0.15drop_256train_tanh\n",
      "--------------Done--------------\n",
      "--------------Create a model--------------\n",
      "--------------Done--------------\n",
      "--------------Begin training the model--------------\n",
      "--------------Done--------------\n",
      "Epoch 1/4\n",
      "7/7 [==============================] - 4347s 642s/step - loss: 1.7403 - accuracy: 0.2488 - val_loss: 1.5086 - val_accuracy: 0.2051\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 3442s 468s/step - loss: 1.7209 - accuracy: 0.2258 - val_loss: 1.4225 - val_accuracy: 0.2308\n",
      "Epoch 3/4\n",
      "3/7 [===========>..................] - ETA: 38:58 - loss: 1.6537 - accuracy: 0.2708"
     ]
    }
   ],
   "source": [
    "tuner.search(train_dataset,train_dataset_label , epochs=2, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c924b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffab419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
